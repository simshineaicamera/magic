I1011 15:06:37.276388 38966 caffe.cpp:218] Using GPUs 1
I1011 15:06:37.303825 38966 caffe.cpp:223] GPU 1: TITAN Xp
I1011 15:06:38.726047 38966 solver.cpp:58] Initializing solver from parameters: 
train_net: "yolo_lite/train.prototxt"
test_net: "yolo_lite/test.prototxt"
test_iter: 4952
test_interval: 1000
base_lr: 0.0005
display: 10
max_iter: 120000
lr_policy: "multistep"
gamma: 0.2
weight_decay: 4e-06
snapshot: 1000
snapshot_prefix: "snapshot/yolov3_lite_deploy"
solver_mode: GPU
device_id: 1
debug_info: false
train_state {
  level: 0
  stage: ""
}
snapshot_after_train: true
test_initialization: false
average_loss: 10
stepvalue: 80000
stepvalue: 100000
iter_size: 1
type: "RMSProp"
show_per_class_result: true
stagelr: 1e-06
stagelr: 1e-05
stagelr: 0.0001
stagelr: 0.001
stagelr: 0.0001
stagelr: 1e-05
stageiter: 50
stageiter: 100
stageiter: 200
stageiter: 80000
stageiter: 100000
stageiter: 120000
eval_type: "detection"
ap_version: "11point"
I1011 15:06:38.726248 38966 solver.cpp:105] Creating training net from train_net file: yolo_lite/train.prototxt
I1011 15:06:38.727409 38966 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: yolo_lite/train.prototxt
I1011 15:06:38.727424 38966 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I1011 15:06:38.728597 38966 net.cpp:53] Initializing net from parameters: 
name: "MobileNetV2"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.007843
    mirror: true
    mean_value: 127.5
    mean_value: 127.5
    mean_value: 127.5
    resize_param {
      prob: 0.2
      resize_mode: WARP
      height: 416
      width: 416
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: LANCZOS4
    }
    resize_param {
      prob: 0.2
      resize_mode: WARP
      height: 384
      width: 384
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: LANCZOS4
    }
    resize_param {
      prob: 0.2
      resize_mode: WARP
      height: 352
      width: 352
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: LANCZOS4
    }
    resize_param {
      prob: 0.2
      resize_mode: WARP
      height: 320
      width: 320
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: LANCZOS4
    }
    resize_param {
      prob: 0.2
      resize_mode: WARP
      height: 288
      width: 288
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: LANCZOS4
    }
    emit_constraint {
      emit_type: CENTER
    }
    distort_param {
      brightness_prob: 0.5
      brightness_delta: 32
      contrast_prob: 0.5
      contrast_lower: 0.5
      contrast_upper: 1.5
      hue_prob: 0.5
      hue_delta: 18
      saturation_prob: 0.5
      saturation_lower: 0.5
      saturation_upper: 1.5
      random_order_prob: 0
    }
    expand_param {
      prob: 0.5
      max_expand_ratio: 4
    }
  }
  data_param {
    source: "trainval_lmdb"
    batch_size: 20
    backend: LMDB
  }
  annotated_data_param {
    label_map_file: "labelmap.prototxt"
    yolo_data_type: 1
    yolo_data_jitter: 0.7
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "DepthwiseConvolution"
  bottom: "conv1"
  top: "conv2"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  convolution_param {
    num_output: 15
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 87
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "DepthwiseConvolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 87
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 87
    stride: 2
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm5"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale5"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "conv5"
  top: "conv6"
  convolution_param {
    num_output: 22
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm6"
  type: "BatchNorm"
  bottom: "conv6"
  top: "conv6"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale6"
  type: "Scale"
  bottom: "conv6"
  top: "conv6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7"
  convolution_param {
    num_output: 130
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm7"
  type: "BatchNorm"
  bottom: "conv7"
  top: "conv7"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale7"
  type: "Scale"
  bottom: "conv7"
  top: "conv7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv8"
  type: "DepthwiseConvolution"
  bottom: "conv7"
  top: "conv8"
  convolution_param {
    num_output: 130
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 130
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm8"
  type: "BatchNorm"
  bottom: "conv8"
  top: "conv8"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale8"
  type: "Scale"
  bottom: "conv8"
  top: "conv8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv9"
  type: "Convolution"
  bottom: "conv8"
  top: "conv9"
  convolution_param {
    num_output: 22
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm9"
  type: "BatchNorm"
  bottom: "conv9"
  top: "conv9"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale9"
  type: "Scale"
  bottom: "conv9"
  top: "conv9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1"
  type: "Eltwise"
  bottom: "conv6"
  bottom: "conv9"
  top: "add1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv10"
  type: "Convolution"
  bottom: "add1"
  top: "conv10"
  convolution_param {
    num_output: 130
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm10"
  type: "BatchNorm"
  bottom: "conv10"
  top: "conv10"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale10"
  type: "Scale"
  bottom: "conv10"
  top: "conv10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "conv11"
  type: "DepthwiseConvolution"
  bottom: "conv10"
  top: "conv11"
  convolution_param {
    num_output: 130
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 130
    stride: 2
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu8"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv13"
  type: "Convolution"
  bottom: "conv12"
  top: "conv13"
  convolution_param {
    num_output: 173
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm13"
  type: "BatchNorm"
  bottom: "conv13"
  top: "conv13"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale13"
  type: "Scale"
  bottom: "conv13"
  top: "conv13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu9"
  type: "ReLU"
  bottom: "conv13"
  top: "conv13"
}
layer {
  name: "conv14"
  type: "DepthwiseConvolution"
  bottom: "conv13"
  top: "conv14"
  convolution_param {
    num_output: 173
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 173
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm14"
  type: "BatchNorm"
  bottom: "conv14"
  top: "conv14"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale14"
  type: "Scale"
  bottom: "conv14"
  top: "conv14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu10"
  type: "ReLU"
  bottom: "conv14"
  top: "conv14"
}
layer {
  name: "conv15"
  type: "Convolution"
  bottom: "conv14"
  top: "conv15"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm15"
  type: "BatchNorm"
  bottom: "conv15"
  top: "conv15"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale15"
  type: "Scale"
  bottom: "conv15"
  top: "conv15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add2"
  type: "Eltwise"
  bottom: "conv12"
  bottom: "conv15"
  top: "add2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv16"
  type: "Convolution"
  bottom: "add2"
  top: "conv16"
  convolution_param {
    num_output: 173
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm16"
  type: "BatchNorm"
  bottom: "conv16"
  top: "conv16"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale16"
  type: "Scale"
  bottom: "conv16"
  top: "conv16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu11"
  type: "ReLU"
  bottom: "conv16"
  top: "conv16"
}
layer {
  name: "conv17"
  type: "DepthwiseConvolution"
  bottom: "conv16"
  top: "conv17"
  convolution_param {
    num_output: 173
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 173
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm17"
  type: "BatchNorm"
  bottom: "conv17"
  top: "conv17"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale17"
  type: "Scale"
  bottom: "conv17"
  top: "conv17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu12"
  type: "ReLU"
  bottom: "conv17"
  top: "conv17"
}
layer {
  name: "conv18"
  type: "Convolution"
  bottom: "conv17"
  top: "conv18"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm18"
  type: "BatchNorm"
  bottom: "conv18"
  top: "conv18"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale18"
  type: "Scale"
  bottom: "conv18"
  top: "conv18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add3"
  type: "Eltwise"
  bottom: "add2"
  bottom: "conv18"
  top: "add3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv19"
  type: "Convolution"
  bottom: "add3"
  top: "conv19"
  convolution_param {
    num_output: 173
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm19"
  type: "BatchNorm"
  bottom: "conv19"
  top: "conv19"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale19"
  type: "Scale"
  bottom: "conv19"
  top: "conv19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu13"
  type: "ReLU"
  bottom: "conv19"
  top: "conv19"
}
layer {
  name: "conv20"
  type: "DepthwiseConvolution"
  bottom: "conv19"
  top: "conv20"
  convolution_param {
    num_output: 173
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 173
    stride: 2
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm20"
  type: "BatchNorm"
  bottom: "conv20"
  top: "conv20"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale20"
  type: "Scale"
  bottom: "conv20"
  top: "conv20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu14"
  type: "ReLU"
  bottom: "conv20"
  top: "conv20"
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "conv20"
  top: "conv21"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm21"
  type: "BatchNorm"
  bottom: "conv21"
  top: "conv21"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale21"
  type: "Scale"
  bottom: "conv21"
  top: "conv21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  convolution_param {
    num_output: 346
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm22"
  type: "BatchNorm"
  bottom: "conv22"
  top: "conv22"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale22"
  type: "Scale"
  bottom: "conv22"
  top: "conv22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu15"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "conv23"
  type: "DepthwiseConvolution"
  bottom: "conv22"
  top: "conv23"
  convolution_param {
    num_output: 346
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 346
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm23"
  type: "BatchNorm"
  bottom: "conv23"
  top: "conv23"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale23"
  type: "Scale"
  bottom: "conv23"
  top: "conv23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu16"
  type: "ReLU"
  bottom: "conv23"
  top: "conv23"
}
layer {
  name: "conv24"
  type: "Convolution"
  bottom: "conv23"
  top: "conv24"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm24"
  type: "BatchNorm"
  bottom: "conv24"
  top: "conv24"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale24"
  type: "Scale"
  bottom: "conv24"
  top: "conv24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add4"
  type: "Eltwise"
  bottom: "conv21"
  bottom: "conv24"
  top: "add4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv25"
  type: "Convolution"
  bottom: "add4"
  top: "conv25"
  convolution_param {
    num_output: 327
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm25"
  type: "BatchNorm"
  bottom: "conv25"
  top: "conv25"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale25"
  type: "Scale"
  bottom: "conv25"
  top: "conv25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu17"
  type: "ReLU"
  bottom: "conv25"
  top: "conv25"
}
layer {
  name: "conv26"
  type: "DepthwiseConvolution"
  bottom: "conv25"
  top: "conv26"
  convolution_param {
    num_output: 327
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 327
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm26"
  type: "BatchNorm"
  bottom: "conv26"
  top: "conv26"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale26"
  type: "Scale"
  bottom: "conv26"
  top: "conv26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu18"
  type: "ReLU"
  bottom: "conv26"
  top: "conv26"
}
layer {
  name: "conv27"
  type: "Convolution"
  bottom: "conv26"
  top: "conv27"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm27"
  type: "BatchNorm"
  bottom: "conv27"
  top: "conv27"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale27"
  type: "Scale"
  bottom: "conv27"
  top: "conv27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add5"
  type: "Eltwise"
  bottom: "add4"
  bottom: "conv27"
  top: "add5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv28"
  type: "Convolution"
  bottom: "add5"
  top: "conv28"
  convolution_param {
    num_output: 327
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm28"
  type: "BatchNorm"
  bottom: "conv28"
  top: "conv28"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale28"
  type: "Scale"
  bottom: "conv28"
  top: "conv28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu19"
  type: "ReLU"
  bottom: "conv28"
  top: "conv28"
}
layer {
  name: "conv29"
  type: "DepthwiseConvolution"
  bottom: "conv28"
  top: "conv29"
  convolution_param {
    num_output: 327
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 327
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm29"
  type: "BatchNorm"
  bottom: "conv29"
  top: "conv29"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale29"
  type: "Scale"
  bottom: "conv29"
  top: "conv29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu20"
  type: "ReLU"
  bottom: "conv29"
  top: "conv29"
}
layer {
  name: "conv30"
  type: "Convolution"
  bottom: "conv29"
  top: "conv30"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm30"
  type: "BatchNorm"
  bottom: "conv30"
  top: "conv30"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale30"
  type: "Scale"
  bottom: "conv30"
  top: "conv30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add6"
  type: "Eltwise"
  bottom: "add5"
  bottom: "conv30"
  top: "add6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "add6"
  top: "conv31"
  convolution_param {
    num_output: 327
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm31"
  type: "BatchNorm"
  bottom: "conv31"
  top: "conv31"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale31"
  type: "Scale"
  bottom: "conv31"
  top: "conv31"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
}
layer {
  name: "conv32"
  type: "DepthwiseConvolution"
  bottom: "conv31"
  top: "conv32"
  convolution_param {
    num_output: 327
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 327
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm32"
  type: "BatchNorm"
  bottom: "conv32"
  top: "conv32"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale32"
  type: "Scale"
  bottom: "conv32"
  top: "conv32"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "conv33"
  type: "Convolution"
  bottom: "conv32"
  top: "conv33"
  convolution_param {
    num_output: 87
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm33"
  type: "BatchNorm"
  bottom: "conv33"
  top: "conv33"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale33"
  type: "Scale"
  bottom: "conv33"
  top: "conv33"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv34"
  type: "Convolution"
  bottom: "conv33"
  top: "conv34"
  convolution_param {
    num_output: 461
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm34"
  type: "BatchNorm"
  bottom: "conv34"
  top: "conv34"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale34"
  type: "Scale"
  bottom: "conv34"
  top: "conv34"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu23"
  type: "ReLU"
  bottom: "conv34"
  top: "conv34"
}
layer {
  name: "conv35"
  type: "DepthwiseConvolution"
  bottom: "conv34"
  top: "conv35"
  convolution_param {
    num_output: 461
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 461
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm35"
  type: "BatchNorm"
  bottom: "conv35"
  top: "conv35"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale35"
  type: "Scale"
  bottom: "conv35"
  top: "conv35"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu24"
  type: "ReLU"
  bottom: "conv35"
  top: "conv35"
}
layer {
  name: "conv36"
  type: "Convolution"
  bottom: "conv35"
  top: "conv36"
  convolution_param {
    num_output: 87
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm36"
  type: "BatchNorm"
  bottom: "conv36"
  top: "conv36"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale36"
  type: "Scale"
  bottom: "conv36"
  top: "conv36"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add7"
  type: "Eltwise"
  bottom: "conv33"
  bottom: "conv36"
  top: "add7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv37"
  type: "Convolution"
  bottom: "add7"
  top: "conv37"
  convolution_param {
    num_output: 461
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm37"
  type: "BatchNorm"
  bottom: "conv37"
  top: "conv37"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale37"
  type: "Scale"
  bottom: "conv37"
  top: "conv37"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu25"
  type: "ReLU"
  bottom: "conv37"
  top: "conv37"
}
layer {
  name: "conv38"
  type: "DepthwiseConvolution"
  bottom: "conv37"
  top: "conv38"
  convolution_param {
    num_output: 461
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 461
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm38"
  type: "BatchNorm"
  bottom: "conv38"
  top: "conv38"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale38"
  type: "Scale"
  bottom: "conv38"
  top: "conv38"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu26"
  type: "ReLU"
  bottom: "conv38"
  top: "conv38"
}
layer {
  name: "conv39"
  type: "Convolution"
  bottom: "conv38"
  top: "conv39"
  convolution_param {
    num_output: 87
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm39"
  type: "BatchNorm"
  bottom: "conv39"
  top: "conv39"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale39"
  type: "Scale"
  bottom: "conv39"
  top: "conv39"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add8"
  type: "Eltwise"
  bottom: "add7"
  bottom: "conv39"
  top: "add8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv40"
  type: "Convolution"
  bottom: "add8"
  top: "conv40"
  convolution_param {
    num_output: 576
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm40"
  type: "BatchNorm"
  bottom: "conv40"
  top: "conv40"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale40"
  type: "Scale"
  bottom: "conv40"
  top: "conv40"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu27"
  type: "ReLU"
  bottom: "conv40"
  top: "conv40"
}
layer {
  name: "conv41"
  type: "DepthwiseConvolution"
  bottom: "conv40"
  top: "conv41"
  convolution_param {
    num_output: 576
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 576
    stride: 2
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm41"
  type: "BatchNorm"
  bottom: "conv41"
  top: "conv41"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale41"
  type: "Scale"
  bottom: "conv41"
  top: "conv41"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu28"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
}
layer {
  name: "conv42"
  type: "Convolution"
  bottom: "conv41"
  top: "conv42"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm42"
  type: "BatchNorm"
  bottom: "conv42"
  top: "conv42"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale42"
  type: "Scale"
  bottom: "conv42"
  top: "conv42"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv43"
  type: "Convolution"
  bottom: "conv42"
  top: "conv43"
  convolution_param {
    num_output: 768
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm43"
  type: "BatchNorm"
  bottom: "conv43"
  top: "conv43"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale43"
  type: "Scale"
  bottom: "conv43"
  top: "conv43"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu29"
  type: "ReLU"
  bottom: "conv43"
  top: "conv43"
}
layer {
  name: "conv44"
  type: "DepthwiseConvolution"
  bottom: "conv43"
  top: "conv44"
  convolution_param {
    num_output: 768
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 768
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm44"
  type: "BatchNorm"
  bottom: "conv44"
  top: "conv44"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale44"
  type: "Scale"
  bottom: "conv44"
  top: "conv44"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu30"
  type: "ReLU"
  bottom: "conv44"
  top: "conv44"
}
layer {
  name: "conv45"
  type: "Convolution"
  bottom: "conv44"
  top: "conv45"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm45"
  type: "BatchNorm"
  bottom: "conv45"
  top: "conv45"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale45"
  type: "Scale"
  bottom: "conv45"
  top: "conv45"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add9"
  type: "Eltwise"
  bottom: "conv42"
  bottom: "conv45"
  top: "add9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv46"
  type: "Convolution"
  bottom: "add9"
  top: "conv46"
  convolution_param {
    num_output: 768
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm46"
  type: "BatchNorm"
  bottom: "conv46"
  top: "conv46"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale46"
  type: "Scale"
  bottom: "conv46"
  top: "conv46"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv46"
  top: "conv46"
}
layer {
  name: "conv47"
  type: "DepthwiseConvolution"
  bottom: "conv46"
  top: "conv47"
  convolution_param {
    num_output: 768
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 768
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm47"
  type: "BatchNorm"
  bottom: "conv47"
  top: "conv47"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale47"
  type: "Scale"
  bottom: "conv47"
  top: "conv47"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv47"
  top: "con
I1011 15:06:38.729333 38966 layer_factory.hpp:77] Creating layer data
I1011 15:06:38.729547 38966 net.cpp:86] Creating Layer data
I1011 15:06:38.729564 38966 net.cpp:382] data -> data
I1011 15:06:38.729643 38966 net.cpp:382] data -> label
I1011 15:06:38.731667 38972 db_lmdb.cpp:35] Opened lmdb trainval_lmdb
I1011 15:06:38.735411 38966 annotated_data_layer.cpp:78] output data size: 20,3,416,416
I1011 15:06:38.844326 38966 net.cpp:124] Setting up data
I1011 15:06:38.844382 38966 net.cpp:131] Top shape: 20 3 416 416 (10383360)
I1011 15:06:38.844388 38966 net.cpp:131] Top shape: 20 1 300 5 (30000)
I1011 15:06:38.844391 38966 net.cpp:139] Memory required for data: 41653440
I1011 15:06:38.844405 38966 layer_factory.hpp:77] Creating layer label_data_1_split
I1011 15:06:38.844420 38966 net.cpp:86] Creating Layer label_data_1_split
I1011 15:06:38.844429 38966 net.cpp:408] label_data_1_split <- label
I1011 15:06:38.844456 38966 net.cpp:382] label_data_1_split -> label_data_1_split_0
I1011 15:06:38.844470 38966 net.cpp:382] label_data_1_split -> label_data_1_split_1
I1011 15:06:38.844518 38966 net.cpp:124] Setting up label_data_1_split
I1011 15:06:38.844527 38966 net.cpp:131] Top shape: 20 1 300 5 (30000)
I1011 15:06:38.844532 38966 net.cpp:131] Top shape: 20 1 300 5 (30000)
I1011 15:06:38.844535 38966 net.cpp:139] Memory required for data: 41893440
I1011 15:06:38.844538 38966 layer_factory.hpp:77] Creating layer conv1
I1011 15:06:38.844559 38966 net.cpp:86] Creating Layer conv1
I1011 15:06:38.844565 38966 net.cpp:408] conv1 <- data
I1011 15:06:38.844597 38966 net.cpp:382] conv1 -> conv1
I1011 15:06:38.844944 38966 net.cpp:124] Setting up conv1
I1011 15:06:38.844955 38966 net.cpp:131] Top shape: 20 32 208 208 (27688960)
I1011 15:06:38.844971 38966 net.cpp:139] Memory required for data: 152649280
I1011 15:06:38.844990 38966 layer_factory.hpp:77] Creating layer batch_norm1
I1011 15:06:38.844997 38966 net.cpp:86] Creating Layer batch_norm1
I1011 15:06:38.845002 38966 net.cpp:408] batch_norm1 <- conv1
I1011 15:06:38.845007 38966 net.cpp:369] batch_norm1 -> conv1 (in-place)
I1011 15:06:38.845284 38966 net.cpp:124] Setting up batch_norm1
I1011 15:06:38.845293 38966 net.cpp:131] Top shape: 20 32 208 208 (27688960)
I1011 15:06:38.845296 38966 net.cpp:139] Memory required for data: 263405120
I1011 15:06:38.845315 38966 layer_factory.hpp:77] Creating layer bn_scale1
I1011 15:06:38.845332 38966 net.cpp:86] Creating Layer bn_scale1
I1011 15:06:38.845336 38966 net.cpp:408] bn_scale1 <- conv1
I1011 15:06:38.845346 38966 net.cpp:369] bn_scale1 -> conv1 (in-place)
I1011 15:06:38.845398 38966 layer_factory.hpp:77] Creating layer bn_scale1
I1011 15:06:38.845592 38966 net.cpp:124] Setting up bn_scale1
I1011 15:06:38.845602 38966 net.cpp:131] Top shape: 20 32 208 208 (27688960)
I1011 15:06:38.845604 38966 net.cpp:139] Memory required for data: 374160960
I1011 15:06:38.845613 38966 layer_factory.hpp:77] Creating layer relu1
I1011 15:06:38.845619 38966 net.cpp:86] Creating Layer relu1
I1011 15:06:38.845623 38966 net.cpp:408] relu1 <- conv1
I1011 15:06:38.845628 38966 net.cpp:369] relu1 -> conv1 (in-place)
I1011 15:06:38.845634 38966 net.cpp:124] Setting up relu1
I1011 15:06:38.845638 38966 net.cpp:131] Top shape: 20 32 208 208 (27688960)
I1011 15:06:38.845641 38966 net.cpp:139] Memory required for data: 484916800
I1011 15:06:38.845644 38966 layer_factory.hpp:77] Creating layer conv2
I1011 15:06:38.845654 38966 net.cpp:86] Creating Layer conv2
I1011 15:06:38.845657 38966 net.cpp:408] conv2 <- conv1
I1011 15:06:38.845664 38966 net.cpp:382] conv2 -> conv2
I1011 15:06:38.845795 38966 net.cpp:124] Setting up conv2
I1011 15:06:38.845803 38966 net.cpp:131] Top shape: 20 32 208 208 (27688960)
I1011 15:06:38.845806 38966 net.cpp:139] Memory required for data: 595672640
I1011 15:06:38.845811 38966 layer_factory.hpp:77] Creating layer batch_norm2
I1011 15:06:38.845818 38966 net.cpp:86] Creating Layer batch_norm2
I1011 15:06:38.845821 38966 net.cpp:408] batch_norm2 <- conv2
I1011 15:06:38.845827 38966 net.cpp:369] batch_norm2 -> conv2 (in-place)
I1011 15:06:38.845990 38966 net.cpp:124] Setting up batch_norm2
I1011 15:06:38.845999 38966 net.cpp:131] Top shape: 20 32 208 208 (27688960)
I1011 15:06:38.846001 38966 net.cpp:139] Memory required for data: 706428480
I1011 15:06:38.846010 38966 layer_factory.hpp:77] Creating layer bn_scale2
I1011 15:06:38.846019 38966 net.cpp:86] Creating Layer bn_scale2
I1011 15:06:38.846022 38966 net.cpp:408] bn_scale2 <- conv2
I1011 15:06:38.846027 38966 net.cpp:369] bn_scale2 -> conv2 (in-place)
I1011 15:06:38.846058 38966 layer_factory.hpp:77] Creating layer bn_scale2
I1011 15:06:38.846208 38966 net.cpp:124] Setting up bn_scale2
I1011 15:06:38.846217 38966 net.cpp:131] Top shape: 20 32 208 208 (27688960)
I1011 15:06:38.846220 38966 net.cpp:139] Memory required for data: 817184320
I1011 15:06:38.846226 38966 layer_factory.hpp:77] Creating layer relu2
I1011 15:06:38.846232 38966 net.cpp:86] Creating Layer relu2
I1011 15:06:38.846236 38966 net.cpp:408] relu2 <- conv2
I1011 15:06:38.846241 38966 net.cpp:369] relu2 -> conv2 (in-place)
I1011 15:06:38.846246 38966 net.cpp:124] Setting up relu2
I1011 15:06:38.846251 38966 net.cpp:131] Top shape: 20 32 208 208 (27688960)
I1011 15:06:38.846253 38966 net.cpp:139] Memory required for data: 927940160
I1011 15:06:38.846256 38966 layer_factory.hpp:77] Creating layer conv3
I1011 15:06:38.846264 38966 net.cpp:86] Creating Layer conv3
I1011 15:06:38.846268 38966 net.cpp:408] conv3 <- conv2
I1011 15:06:38.846274 38966 net.cpp:382] conv3 -> conv3
I1011 15:06:38.846421 38966 net.cpp:124] Setting up conv3
I1011 15:06:38.846441 38966 net.cpp:131] Top shape: 20 15 208 208 (12979200)
I1011 15:06:38.846443 38966 net.cpp:139] Memory required for data: 979856960
I1011 15:06:38.846448 38966 layer_factory.hpp:77] Creating layer batch_norm3
I1011 15:06:38.846455 38966 net.cpp:86] Creating Layer batch_norm3
I1011 15:06:38.846458 38966 net.cpp:408] batch_norm3 <- conv3
I1011 15:06:38.846463 38966 net.cpp:369] batch_norm3 -> conv3 (in-place)
I1011 15:06:38.846653 38966 net.cpp:124] Setting up batch_norm3
I1011 15:06:38.846662 38966 net.cpp:131] Top shape: 20 15 208 208 (12979200)
I1011 15:06:38.846664 38966 net.cpp:139] Memory required for data: 1031773760
I1011 15:06:38.846670 38966 layer_factory.hpp:77] Creating layer bn_scale3
I1011 15:06:38.846676 38966 net.cpp:86] Creating Layer bn_scale3
I1011 15:06:38.846680 38966 net.cpp:408] bn_scale3 <- conv3
I1011 15:06:38.846685 38966 net.cpp:369] bn_scale3 -> conv3 (in-place)
I1011 15:06:38.846714 38966 layer_factory.hpp:77] Creating layer bn_scale3
I1011 15:06:38.847991 38966 net.cpp:124] Setting up bn_scale3
I1011 15:06:38.848017 38966 net.cpp:131] Top shape: 20 15 208 208 (12979200)
I1011 15:06:38.848021 38966 net.cpp:139] Memory required for data: 1083690560
I1011 15:06:38.848031 38966 layer_factory.hpp:77] Creating layer conv4
I1011 15:06:38.848040 38966 net.cpp:86] Creating Layer conv4
I1011 15:06:38.848044 38966 net.cpp:408] conv4 <- conv3
I1011 15:06:38.848052 38966 net.cpp:382] conv4 -> conv4
I1011 15:06:38.848237 38966 net.cpp:124] Setting up conv4
I1011 15:06:38.848245 38966 net.cpp:131] Top shape: 20 87 208 208 (75279360)
I1011 15:06:38.848249 38966 net.cpp:139] Memory required for data: 1384808000
I1011 15:06:38.848254 38966 layer_factory.hpp:77] Creating layer batch_norm4
I1011 15:06:38.848260 38966 net.cpp:86] Creating Layer batch_norm4
I1011 15:06:38.848263 38966 net.cpp:408] batch_norm4 <- conv4
I1011 15:06:38.848268 38966 net.cpp:369] batch_norm4 -> conv4 (in-place)
I1011 15:06:38.848423 38966 net.cpp:124] Setting up batch_norm4
I1011 15:06:38.848431 38966 net.cpp:131] Top shape: 20 87 208 208 (75279360)
I1011 15:06:38.848435 38966 net.cpp:139] Memory required for data: 1685925440
I1011 15:06:38.848443 38966 layer_factory.hpp:77] Creating layer bn_scale4
I1011 15:06:38.848448 38966 net.cpp:86] Creating Layer bn_scale4
I1011 15:06:38.848451 38966 net.cpp:408] bn_scale4 <- conv4
I1011 15:06:38.848457 38966 net.cpp:369] bn_scale4 -> conv4 (in-place)
I1011 15:06:38.848487 38966 layer_factory.hpp:77] Creating layer bn_scale4
I1011 15:06:38.848611 38966 net.cpp:124] Setting up bn_scale4
I1011 15:06:38.848620 38966 net.cpp:131] Top shape: 20 87 208 208 (75279360)
I1011 15:06:38.848623 38966 net.cpp:139] Memory required for data: 1987042880
I1011 15:06:38.848628 38966 layer_factory.hpp:77] Creating layer relu3
I1011 15:06:38.848636 38966 net.cpp:86] Creating Layer relu3
I1011 15:06:38.848639 38966 net.cpp:408] relu3 <- conv4
I1011 15:06:38.848645 38966 net.cpp:369] relu3 -> conv4 (in-place)
I1011 15:06:38.848650 38966 net.cpp:124] Setting up relu3
I1011 15:06:38.848654 38966 net.cpp:131] Top shape: 20 87 208 208 (75279360)
I1011 15:06:38.848657 38966 net.cpp:139] Memory required for data: 2288160320
I1011 15:06:38.848660 38966 layer_factory.hpp:77] Creating layer conv5
I1011 15:06:38.848667 38966 net.cpp:86] Creating Layer conv5
I1011 15:06:38.848671 38966 net.cpp:408] conv5 <- conv4
I1011 15:06:38.848676 38966 net.cpp:382] conv5 -> conv5
I1011 15:06:38.848819 38966 net.cpp:124] Setting up conv5
I1011 15:06:38.848826 38966 net.cpp:131] Top shape: 20 87 104 104 (18819840)
I1011 15:06:38.848829 38966 net.cpp:139] Memory required for data: 2363439680
I1011 15:06:38.848834 38966 layer_factory.hpp:77] Creating layer batch_norm5
I1011 15:06:38.848840 38966 net.cpp:86] Creating Layer batch_norm5
I1011 15:06:38.848845 38966 net.cpp:408] batch_norm5 <- conv5
I1011 15:06:38.848850 38966 net.cpp:369] batch_norm5 -> conv5 (in-place)
I1011 15:06:38.848994 38966 net.cpp:124] Setting up batch_norm5
I1011 15:06:38.849002 38966 net.cpp:131] Top shape: 20 87 104 104 (18819840)
I1011 15:06:38.849018 38966 net.cpp:139] Memory required for data: 2438719040
I1011 15:06:38.849026 38966 layer_factory.hpp:77] Creating layer bn_scale5
I1011 15:06:38.849032 38966 net.cpp:86] Creating Layer bn_scale5
I1011 15:06:38.849035 38966 net.cpp:408] bn_scale5 <- conv5
I1011 15:06:38.849041 38966 net.cpp:369] bn_scale5 -> conv5 (in-place)
I1011 15:06:38.849084 38966 layer_factory.hpp:77] Creating layer bn_scale5
I1011 15:06:38.849182 38966 net.cpp:124] Setting up bn_scale5
I1011 15:06:38.849190 38966 net.cpp:131] Top shape: 20 87 104 104 (18819840)
I1011 15:06:38.849195 38966 net.cpp:139] Memory required for data: 2513998400
I1011 15:06:38.849200 38966 layer_factory.hpp:77] Creating layer relu4
I1011 15:06:38.849205 38966 net.cpp:86] Creating Layer relu4
I1011 15:06:38.849210 38966 net.cpp:408] relu4 <- conv5
I1011 15:06:38.849215 38966 net.cpp:369] relu4 -> conv5 (in-place)
I1011 15:06:38.849220 38966 net.cpp:124] Setting up relu4
I1011 15:06:38.849223 38966 net.cpp:131] Top shape: 20 87 104 104 (18819840)
I1011 15:06:38.849227 38966 net.cpp:139] Memory required for data: 2589277760
I1011 15:06:38.849231 38966 layer_factory.hpp:77] Creating layer conv6
I1011 15:06:38.849238 38966 net.cpp:86] Creating Layer conv6
I1011 15:06:38.849241 38966 net.cpp:408] conv6 <- conv5
I1011 15:06:38.849247 38966 net.cpp:382] conv6 -> conv6
I1011 15:06:38.849404 38966 net.cpp:124] Setting up conv6
I1011 15:06:38.849412 38966 net.cpp:131] Top shape: 20 22 104 104 (4759040)
I1011 15:06:38.849416 38966 net.cpp:139] Memory required for data: 2608313920
I1011 15:06:38.849421 38966 layer_factory.hpp:77] Creating layer batch_norm6
I1011 15:06:38.849426 38966 net.cpp:86] Creating Layer batch_norm6
I1011 15:06:38.849429 38966 net.cpp:408] batch_norm6 <- conv6
I1011 15:06:38.849436 38966 net.cpp:369] batch_norm6 -> conv6 (in-place)
I1011 15:06:38.849582 38966 net.cpp:124] Setting up batch_norm6
I1011 15:06:38.849591 38966 net.cpp:131] Top shape: 20 22 104 104 (4759040)
I1011 15:06:38.849594 38966 net.cpp:139] Memory required for data: 2627350080
I1011 15:06:38.849604 38966 layer_factory.hpp:77] Creating layer bn_scale6
I1011 15:06:38.849611 38966 net.cpp:86] Creating Layer bn_scale6
I1011 15:06:38.849613 38966 net.cpp:408] bn_scale6 <- conv6
I1011 15:06:38.849619 38966 net.cpp:369] bn_scale6 -> conv6 (in-place)
I1011 15:06:38.849649 38966 layer_factory.hpp:77] Creating layer bn_scale6
I1011 15:06:38.849750 38966 net.cpp:124] Setting up bn_scale6
I1011 15:06:38.849758 38966 net.cpp:131] Top shape: 20 22 104 104 (4759040)
I1011 15:06:38.849761 38966 net.cpp:139] Memory required for data: 2646386240
I1011 15:06:38.849767 38966 layer_factory.hpp:77] Creating layer conv6_bn_scale6_0_split
I1011 15:06:38.849773 38966 net.cpp:86] Creating Layer conv6_bn_scale6_0_split
I1011 15:06:38.849777 38966 net.cpp:408] conv6_bn_scale6_0_split <- conv6
I1011 15:06:38.849782 38966 net.cpp:382] conv6_bn_scale6_0_split -> conv6_bn_scale6_0_split_0
I1011 15:06:38.849789 38966 net.cpp:382] conv6_bn_scale6_0_split -> conv6_bn_scale6_0_split_1
I1011 15:06:38.849817 38966 net.cpp:124] Setting up conv6_bn_scale6_0_split
I1011 15:06:38.849824 38966 net.cpp:131] Top shape: 20 22 104 104 (4759040)
I1011 15:06:38.849829 38966 net.cpp:131] Top shape: 20 22 104 104 (4759040)
I1011 15:06:38.849833 38966 net.cpp:139] Memory required for data: 2684458560
I1011 15:06:38.849835 38966 layer_factory.hpp:77] Creating layer conv7
I1011 15:06:38.849843 38966 net.cpp:86] Creating Layer conv7
I1011 15:06:38.849848 38966 net.cpp:408] conv7 <- conv6_bn_scale6_0_split_0
I1011 15:06:38.849853 38966 net.cpp:382] conv7 -> conv7
I1011 15:06:38.850024 38966 net.cpp:124] Setting up conv7
I1011 15:06:38.850033 38966 net.cpp:131] Top shape: 20 130 104 104 (28121600)
I1011 15:06:38.850035 38966 net.cpp:139] Memory required for data: 2796944960
I1011 15:06:38.850040 38966 layer_factory.hpp:77] Creating layer batch_norm7
I1011 15:06:38.850049 38966 net.cpp:86] Creating Layer batch_norm7
I1011 15:06:38.850054 38966 net.cpp:408] batch_norm7 <- conv7
I1011 15:06:38.850059 38966 net.cpp:369] batch_norm7 -> conv7 (in-place)
I1011 15:06:38.850219 38966 net.cpp:124] Setting up batch_norm7
I1011 15:06:38.850227 38966 net.cpp:131] Top shape: 20 130 104 104 (28121600)
I1011 15:06:38.850230 38966 net.cpp:139] Memory required for data: 2909431360
I1011 15:06:38.850237 38966 layer_factory.hpp:77] Creating layer bn_scale7
I1011 15:06:38.850244 38966 net.cpp:86] Creating Layer bn_scale7
I1011 15:06:38.850247 38966 net.cpp:408] bn_scale7 <- conv7
I1011 15:06:38.850255 38966 net.cpp:369] bn_scale7 -> conv7 (in-place)
I1011 15:06:38.850283 38966 layer_factory.hpp:77] Creating layer bn_scale7
I1011 15:06:38.850389 38966 net.cpp:124] Setting up bn_scale7
I1011 15:06:38.850396 38966 net.cpp:131] Top shape: 20 130 104 104 (28121600)
I1011 15:06:38.850400 38966 net.cpp:139] Memory required for data: 3021917760
I1011 15:06:38.850405 38966 layer_factory.hpp:77] Creating layer relu5
I1011 15:06:38.850410 38966 net.cpp:86] Creating Layer relu5
I1011 15:06:38.850414 38966 net.cpp:408] relu5 <- conv7
I1011 15:06:38.850420 38966 net.cpp:369] relu5 -> conv7 (in-place)
I1011 15:06:38.850426 38966 net.cpp:124] Setting up relu5
I1011 15:06:38.850430 38966 net.cpp:131] Top shape: 20 130 104 104 (28121600)
I1011 15:06:38.850433 38966 net.cpp:139] Memory required for data: 3134404160
I1011 15:06:38.850436 38966 layer_factory.hpp:77] Creating layer conv8
I1011 15:06:38.850445 38966 net.cpp:86] Creating Layer conv8
I1011 15:06:38.850448 38966 net.cpp:408] conv8 <- conv7
I1011 15:06:38.850455 38966 net.cpp:382] conv8 -> conv8
I1011 15:06:38.850607 38966 net.cpp:124] Setting up conv8
I1011 15:06:38.850616 38966 net.cpp:131] Top shape: 20 130 104 104 (28121600)
I1011 15:06:38.850620 38966 net.cpp:139] Memory required for data: 3246890560
I1011 15:06:38.850625 38966 layer_factory.hpp:77] Creating layer batch_norm8
I1011 15:06:38.850630 38966 net.cpp:86] Creating Layer batch_norm8
I1011 15:06:38.850633 38966 net.cpp:408] batch_norm8 <- conv8
I1011 15:06:38.850637 38966 net.cpp:369] batch_norm8 -> conv8 (in-place)
I1011 15:06:38.850790 38966 net.cpp:124] Setting up batch_norm8
I1011 15:06:38.850797 38966 net.cpp:131] Top shape: 20 130 104 104 (28121600)
I1011 15:06:38.850800 38966 net.cpp:139] Memory required for data: 3359376960
I1011 15:06:38.850807 38966 layer_factory.hpp:77] Creating layer bn_scale8
I1011 15:06:38.850816 38966 net.cpp:86] Creating Layer bn_scale8
I1011 15:06:38.850818 38966 net.cpp:408] bn_scale8 <- conv8
I1011 15:06:38.850823 38966 net.cpp:369] bn_scale8 -> conv8 (in-place)
I1011 15:06:38.850857 38966 layer_factory.hpp:77] Creating layer bn_scale8
I1011 15:06:38.856454 38966 net.cpp:124] Setting up bn_scale8
I1011 15:06:38.856465 38966 net.cpp:131] Top shape: 20 130 104 104 (28121600)
I1011 15:06:38.856480 38966 net.cpp:139] Memory required for data: 3471863360
I1011 15:06:38.856487 38966 layer_factory.hpp:77] Creating layer relu6
I1011 15:06:38.856496 38966 net.cpp:86] Creating Layer relu6
I1011 15:06:38.856500 38966 net.cpp:408] relu6 <- conv8
I1011 15:06:38.856505 38966 net.cpp:369] relu6 -> conv8 (in-place)
I1011 15:06:38.856510 38966 net.cpp:124] Setting up relu6
I1011 15:06:38.856515 38966 net.cpp:131] Top shape: 20 130 104 104 (28121600)
I1011 15:06:38.856518 38966 net.cpp:139] Memory required for data: 3584349760
I1011 15:06:38.856521 38966 layer_factory.hpp:77] Creating layer conv9
I1011 15:06:38.856530 38966 net.cpp:86] Creating Layer conv9
I1011 15:06:38.856534 38966 net.cpp:408] conv9 <- conv8
I1011 15:06:38.856539 38966 net.cpp:382] conv9 -> conv9
I1011 15:06:38.856712 38966 net.cpp:124] Setting up conv9
I1011 15:06:38.856720 38966 net.cpp:131] Top shape: 20 22 104 104 (4759040)
I1011 15:06:38.856724 38966 net.cpp:139] Memory required for data: 3603385920
I1011 15:06:38.856729 38966 layer_factory.hpp:77] Creating layer batch_norm9
I1011 15:06:38.856734 38966 net.cpp:86] Creating Layer batch_norm9
I1011 15:06:38.856739 38966 net.cpp:408] batch_norm9 <- conv9
I1011 15:06:38.856742 38966 net.cpp:369] batch_norm9 -> conv9 (in-place)
I1011 15:06:38.856904 38966 net.cpp:124] Setting up batch_norm9
I1011 15:06:38.856911 38966 net.cpp:131] Top shape: 20 22 104 104 (4759040)
I1011 15:06:38.856925 38966 net.cpp:139] Memory required for data: 3622422080
I1011 15:06:38.856932 38966 layer_factory.hpp:77] Creating layer bn_scale9
I1011 15:06:38.856940 38966 net.cpp:86] Creating Layer bn_scale9
I1011 15:06:38.856943 38966 net.cpp:408] bn_scale9 <- conv9
I1011 15:06:38.856948 38966 net.cpp:369] bn_scale9 -> conv9 (in-place)
I1011 15:06:38.856981 38966 layer_factory.hpp:77] Creating layer bn_scale9
I1011 15:06:38.857081 38966 net.cpp:124] Setting up bn_scale9
I1011 15:06:38.857089 38966 net.cpp:131] Top shape: 20 22 104 104 (4759040)
I1011 15:06:38.857092 38966 net.cpp:139] Memory required for data: 3641458240
I1011 15:06:38.857098 38966 layer_factory.hpp:77] Creating layer add1
I1011 15:06:38.857107 38966 net.cpp:86] Creating Layer add1
I1011 15:06:38.857110 38966 net.cpp:408] add1 <- conv6_bn_scale6_0_split_1
I1011 15:06:38.857115 38966 net.cpp:408] add1 <- conv9
I1011 15:06:38.857120 38966 net.cpp:382] add1 -> add1
I1011 15:06:38.857144 38966 net.cpp:124] Setting up add1
I1011 15:06:38.857151 38966 net.cpp:131] Top shape: 20 22 104 104 (4759040)
I1011 15:06:38.857154 38966 net.cpp:139] Memory required for data: 3660494400
I1011 15:06:38.857157 38966 layer_factory.hpp:77] Creating layer conv10
I1011 15:06:38.857167 38966 net.cpp:86] Creating Layer conv10
I1011 15:06:38.857170 38966 net.cpp:408] conv10 <- add1
I1011 15:06:38.857177 38966 net.cpp:382] conv10 -> conv10
I1011 15:06:38.857343 38966 net.cpp:124] Setting up conv10
I1011 15:06:38.857352 38966 net.cpp:131] Top shape: 20 130 104 104 (28121600)
I1011 15:06:38.857355 38966 net.cpp:139] Memory required for data: 3772980800
I1011 15:06:38.857359 38966 layer_factory.hpp:77] Creating layer batch_norm10
I1011 15:06:38.857367 38966 net.cpp:86] Creating Layer batch_norm10
I1011 15:06:38.857369 38966 net.cpp:408] batch_norm10 <- conv10
I1011 15:06:38.857374 38966 net.cpp:369] batch_norm10 -> conv10 (in-place)
I1011 15:06:38.857525 38966 net.cpp:124] Setting up batch_norm10
I1011 15:06:38.857533 38966 net.cpp:131] Top shape: 20 130 104 104 (28121600)
I1011 15:06:38.857537 38966 net.cpp:139] Memory required for data: 3885467200
I1011 15:06:38.857542 38966 layer_factory.hpp:77] Creating layer bn_scale10
I1011 15:06:38.857551 38966 net.cpp:86] Creating Layer bn_scale10
I1011 15:06:38.857554 38966 net.cpp:408] bn_scale10 <- conv10
I1011 15:06:38.857559 38966 net.cpp:369] bn_scale10 -> conv10 (in-place)
I1011 15:06:38.857589 38966 layer_factory.hpp:77] Creating layer bn_scale10
I1011 15:06:38.857687 38966 net.cpp:124] Setting up bn_scale10
I1011 15:06:38.857695 38966 net.cpp:131] Top shape: 20 130 104 104 (28121600)
I1011 15:06:38.857699 38966 net.cpp:139] Memory required for data: 3997953600
I1011 15:06:38.857704 38966 layer_factory.hpp:77] Creating layer relu7
I1011 15:06:38.857712 38966 net.cpp:86] Creating Layer relu7
I1011 15:06:38.857715 38966 net.cpp:408] relu7 <- conv10
I1011 15:06:38.857719 38966 net.cpp:369] relu7 -> conv10 (in-place)
I1011 15:06:38.857726 38966 net.cpp:124] Setting up relu7
I1011 15:06:38.857730 38966 net.cpp:131] Top shape: 20 130 104 104 (28121600)
I1011 15:06:38.857733 38966 net.cpp:139] Memory required for data: 4110440000
I1011 15:06:38.857736 38966 layer_factory.hpp:77] Creating layer conv11
I1011 15:06:38.857743 38966 net.cpp:86] Creating Layer conv11
I1011 15:06:38.857745 38966 net.cpp:408] conv11 <- conv10
I1011 15:06:38.857753 38966 net.cpp:382] conv11 -> conv11
I1011 15:06:38.857899 38966 net.cpp:124] Setting up conv11
I1011 15:06:38.857908 38966 net.cpp:131] Top shape: 20 130 52 52 (7030400)
I1011 15:06:38.857910 38966 net.cpp:139] Memory required for data: 4138561600
I1011 15:06:38.857914 38966 layer_factory.hpp:77] Creating layer batch_norm11
I1011 15:06:38.857921 38966 net.cpp:86] Creating Layer batch_norm11
I1011 15:06:38.857925 38966 net.cpp:408] batch_norm11 <- conv11
I1011 15:06:38.857929 38966 net.cpp:369] batch_norm11 -> conv11 (in-place)
I1011 15:06:38.858074 38966 net.cpp:124] Setting up batch_norm11
I1011 15:06:38.858081 38966 net.cpp:131] Top shape: 20 130 52 52 (7030400)
I1011 15:06:38.858096 38966 net.cpp:139] Memory required for data: 4166683200
I1011 15:06:38.858103 38966 layer_factory.hpp:77] Creating layer bn_scale11
I1011 15:06:38.858109 38966 net.cpp:86] Creating Layer bn_scale11
I1011 15:06:38.858112 38966 net.cpp:408] bn_scale11 <- conv11
I1011 15:06:38.858119 38966 net.cpp:369] bn_scale11 -> conv11 (in-place)
I1011 15:06:38.858150 38966 layer_factory.hpp:77] Creating layer bn_scale11
I1011 15:06:38.858240 38966 net.cpp:124] Setting up bn_scale11
I1011 15:06:38.858249 38966 net.cpp:131] Top shape: 20 130 52 52 (7030400)
I1011 15:06:38.858253 38966 net.cpp:139] Memory required for data: 4194804800
I1011 15:06:38.858266 38966 layer_factory.hpp:77] Creating layer relu8
I1011 15:06:38.858274 38966 net.cpp:86] Creating Layer relu8
I1011 15:06:38.858278 38966 net.cpp:408] relu8 <- conv11
I1011 15:06:38.858283 38966 net.cpp:369] relu8 -> conv11 (in-place)
I1011 15:06:38.858287 38966 net.cpp:124] Setting up relu8
I1011 15:06:38.858291 38966 net.cpp:131] Top shape: 20 130 52 52 (7030400)
I1011 15:06:38.858294 38966 net.cpp:139] Memory required for data: 4222926400
I1011 15:06:38.858297 38966 layer_factory.hpp:77] Creating layer conv12
I1011 15:06:38.858304 38966 net.cpp:86] Creating Layer conv12
I1011 15:06:38.858309 38966 net.cpp:408] conv12 <- conv11
I1011 15:06:38.858314 38966 net.cpp:382] conv12 -> conv12
I1011 15:06:38.858494 38966 net.cpp:124] Setting up conv12
I1011 15:06:38.858501 38966 net.cpp:131] Top shape: 20 32 52 52 (1730560)
I1011 15:06:38.858505 38966 net.cpp:139] Memory required for data: 4229848640
I1011 15:06:38.858508 38966 layer_factory.hpp:77] Creating layer batch_norm12
I1011 15:06:38.858513 38966 net.cpp:86] Creating Layer batch_norm12
I1011 15:06:38.858517 38966 net.cpp:408] batch_norm12 <- conv12
I1011 15:06:38.858521 38966 net.cpp:369] batch_norm12 -> conv12 (in-place)
I1011 15:06:38.858670 38966 net.cpp:124] Setting up batch_norm12
I1011 15:06:38.858678 38966 net.cpp:131] Top shape: 20 32 52 52 (1730560)
I1011 15:06:38.858681 38966 net.cpp:139] Memory required for data: 4236770880
I1011 15:06:38.858687 38966 layer_factory.hpp:77] Creating layer bn_scale12
I1011 15:06:38.858692 38966 net.cpp:86] Creating Layer bn_scale12
I1011 15:06:38.858695 38966 net.cpp:408] bn_scale12 <- conv12
I1011 15:06:38.858700 38966 net.cpp:369] bn_scale12 -> conv12 (in-place)
I1011 15:06:38.858731 38966 layer_factory.hpp:77] Creating layer bn_scale12
I1011 15:06:38.858826 38966 net.cpp:124] Setting up bn_scale12
I1011 15:06:38.858834 38966 net.cpp:131] Top shape: 20 32 52 52 (1730560)
I1011 15:06:38.858837 38966 net.cpp:139] Memory required for data: 4243693120
I1011 15:06:38.858842 38966 layer_factory.hpp:77] Creating layer conv12_bn_scale12_0_split
I1011 15:06:38.858848 38966 net.cpp:86] Creating Layer conv12_bn_scale12_0_split
I1011 15:06:38.858851 38966 net.cpp:408] conv12_bn_scale12_0_split <- conv12
I1011 15:06:38.858858 38966 net.cpp:382] conv12_bn_scale12_0_split -> conv12_bn_scale12_0_split_0
I1011 15:06:38.858865 38966 net.cpp:382] conv12_bn_scale12_0_split -> conv12_bn_scale12_0_split_1
I1011 15:06:38.858892 38966 net.cpp:124] Setting up conv12_bn_scale12_0_split
I1011 15:06:38.858899 38966 net.cpp:131] Top shape: 20 32 52 52 (1730560)
I1011 15:06:38.858903 38966 net.cpp:131] Top shape: 20 32 52 52 (1730560)
I1011 15:06:38.858906 38966 net.cpp:139] Memory required for data: 4257537600
I1011 15:06:38.858909 38966 layer_factory.hpp:77] Creating layer conv13
I1011 15:06:38.858919 38966 net.cpp:86] Creating Layer conv13
I1011 15:06:38.858922 38966 net.cpp:408] conv13 <- conv12_bn_scale12_0_split_0
I1011 15:06:38.858928 38966 net.cpp:382] conv13 -> conv13
I1011 15:06:38.859113 38966 net.cpp:124] Setting up conv13
I1011 15:06:38.859122 38966 net.cpp:131] Top shape: 20 173 52 52 (9355840)
I1011 15:06:38.859124 38966 net.cpp:139] Memory required for data: 4294960960
I1011 15:06:38.859129 38966 layer_factory.hpp:77] Creating layer batch_norm13
I1011 15:06:38.859136 38966 net.cpp:86] Creating Layer batch_norm13
I1011 15:06:38.859139 38966 net.cpp:408] batch_norm13 <- conv13
I1011 15:06:38.859153 38966 net.cpp:369] batch_norm13 -> conv13 (in-place)
I1011 15:06:38.859311 38966 net.cpp:124] Setting up batch_norm13
I1011 15:06:38.859321 38966 net.cpp:131] Top shape: 20 173 52 52 (9355840)
I1011 15:06:38.859325 38966 net.cpp:139] Memory required for data: 4332384320
I1011 15:06:38.859331 38966 layer_factory.hpp:77] Creating layer bn_scale13
I1011 15:06:38.859336 38966 net.cpp:86] Creating Layer bn_scale13
I1011 15:06:38.859340 38966 net.cpp:408] bn_scale13 <- conv13
I1011 15:06:38.859346 38966 net.cpp:369] bn_scale13 -> conv13 (in-place)
I1011 15:06:38.859375 38966 layer_factory.hpp:77] Creating layer bn_scale13
I1011 15:06:38.859467 38966 net.cpp:124] Setting up bn_scale13
I1011 15:06:38.859475 38966 net.cpp:131] Top shape: 20 173 52 52 (9355840)
I1011 15:06:38.859478 38966 net.cpp:139] Memory required for data: 4369807680
I1011 15:06:38.859483 38966 layer_factory.hpp:77] Creating layer relu9
I1011 15:06:38.859488 38966 net.cpp:86] Creating Layer relu9
I1011 15:06:38.859493 38966 net.cpp:408] relu9 <- conv13
I1011 15:06:38.859498 38966 net.cpp:369] relu9 -> conv13 (in-place)
I1011 15:06:38.859503 38966 net.cpp:124] Setting up relu9
I1011 15:06:38.859508 38966 net.cpp:131] Top shape: 20 173 52 52 (9355840)
I1011 15:06:38.859510 38966 net.cpp:139] Memory required for data: 4407231040
I1011 15:06:38.859513 38966 layer_factory.hpp:77] Creating layer conv14
I1011 15:06:38.859521 38966 net.cpp:86] Creating Layer conv14
I1011 15:06:38.859524 38966 net.cpp:408] conv14 <- conv13
I1011 15:06:38.859529 38966 net.cpp:382] conv14 -> conv14
I1011 15:06:38.859686 38966 net.cpp:124] Setting up conv14
I1011 15:06:38.859694 38966 net.cpp:131] Top shape: 20 173 52 52 (9355840)
I1011 15:06:38.859697 38966 net.cpp:139] Memory required for data: 4444654400
I1011 15:06:38.859701 38966 layer_factory.hpp:77] Creating layer batch_norm14
I1011 15:06:38.859707 38966 net.cpp:86] Creating Layer batch_norm14
I1011 15:06:38.859710 38966 net.cpp:408] batch_norm14 <- conv14
I1011 15:06:38.859714 38966 net.cpp:369] batch_norm14 -> conv14 (in-place)
I1011 15:06:38.859869 38966 net.cpp:124] Setting up batch_norm14
I1011 15:06:38.859877 38966 net.cpp:131] Top shape: 20 173 52 52 (9355840)
I1011 15:06:38.859880 38966 net.cpp:139] Memory required for data: 4482077760
I1011 15:06:38.859887 38966 layer_factory.hpp:77] Creating layer bn_scale14
I1011 15:06:38.859894 38966 net.cpp:86] Creating Layer bn_scale14
I1011 15:06:38.859897 38966 net.cpp:408] bn_scale14 <- conv14
I1011 15:06:38.859901 38966 net.cpp:369] bn_scale14 -> conv14 (in-place)
I1011 15:06:38.859935 38966 layer_factory.hpp:77] Creating layer bn_scale14
I1011 15:06:38.860031 38966 net.cpp:124] Setting up bn_scale14
I1011 15:06:38.860040 38966 net.cpp:131] Top shape: 20 173 52 52 (9355840)
I1011 15:06:38.860044 38966 net.cpp:139] Memory required for data: 4519501120
I1011 15:06:38.860049 38966 layer_factory.hpp:77] Creating layer relu10
I1011 15:06:38.860055 38966 net.cpp:86] Creating Layer relu10
I1011 15:06:38.860059 38966 net.cpp:408] relu10 <- conv14
I1011 15:06:38.860069 38966 net.cpp:369] relu10 -> conv14 (in-place)
I1011 15:06:38.860074 38966 net.cpp:124] Setting up relu10
I1011 15:06:38.860077 38966 net.cpp:131] Top shape: 20 173 52 52 (9355840)
I1011 15:06:38.860080 38966 net.cpp:139] Memory required for data: 4556924480
I1011 15:06:38.860083 38966 layer_factory.hpp:77] Creating layer conv15
I1011 15:06:38.860090 38966 net.cpp:86] Creating Layer conv15
I1011 15:06:38.860093 38966 net.cpp:408] conv15 <- conv14
I1011 15:06:38.860100 38966 net.cpp:382] conv15 -> conv15
I1011 15:06:38.860297 38966 net.cpp:124] Setting up conv15
I1011 15:06:38.860304 38966 net.cpp:131] Top shape: 20 32 52 52 (1730560)
I1011 15:06:38.860308 38966 net.cpp:139] Memory required for data: 4563846720
I1011 15:06:38.860312 38966 layer_factory.hpp:77] Creating layer batch_norm15
I1011 15:06:38.860319 38966 net.cpp:86] Creating Layer batch_norm15
I1011 15:06:38.860323 38966 net.cpp:408] batch_norm15 <- conv15
I1011 15:06:38.860327 38966 net.cpp:369] batch_norm15 -> conv15 (in-place)
I1011 15:06:38.860569 38966 net.cpp:124] Setting up batch_norm15
I1011 15:06:38.860587 38966 net.cpp:131] Top shape: 20 32 52 52 (1730560)
I1011 15:06:38.860591 38966 net.cpp:139] Memory required for data: 4570768960
I1011 15:06:38.860599 38966 layer_factory.hpp:77] Creating layer bn_scale15
I1011 15:06:38.860605 38966 net.cpp:86] Creating Layer bn_scale15
I1011 15:06:38.860608 38966 net.cpp:408] bn_scale15 <- conv15
I1011 15:06:38.860617 38966 net.cpp:369] bn_scale15 -> conv15 (in-place)
I1011 15:06:38.860652 38966 layer_factory.hpp:77] Creating layer bn_scale15
I1011 15:06:38.860787 38966 net.cpp:124] Setting up bn_scale15
I1011 15:06:38.860838 38966 net.cpp:131] Top shape: 20 32 52 52 (1730560)
I1011 15:06:38.860844 38966 net.cpp:139] Memory required for data: 4577691200
I1011 15:06:38.860850 38966 layer_factory.hpp:77] Creating layer add2
I1011 15:06:38.860857 38966 net.cpp:86] Creating Layer add2
I1011 15:06:38.860862 38966 net.cpp:408] add2 <- conv12_bn_scale12_0_split_1
I1011 15:06:38.860865 38966 net.cpp:408] add2 <- conv15
I1011 15:06:38.860870 38966 net.cpp:382] add2 -> add2
I1011 15:06:38.860894 38966 net.cpp:124] Setting up add2
I1011 15:06:38.860901 38966 net.cpp:131] Top shape: 20 32 52 52 (1730560)
I1011 15:06:38.860905 38966 net.cpp:139] Memory required for data: 4584613440
I1011 15:06:38.860909 38966 layer_factory.hpp:77] Creating layer add2_add2_0_split
I1011 15:06:38.860918 38966 net.cpp:86] Creating Layer add2_add2_0_split
I1011 15:06:38.860921 38966 net.cpp:408] add2_add2_0_split <- add2
I1011 15:06:38.860927 38966 net.cpp:382] add2_add2_0_split -> add2_add2_0_split_0
I1011 15:06:38.860934 38966 net.cpp:382] add2_add2_0_split -> add2_add2_0_split_1
I1011 15:06:38.860977 38966 net.cpp:124] Setting up add2_add2_0_split
I1011 15:06:38.860985 38966 net.cpp:131] Top shape: 20 32 52 52 (1730560)
I1011 15:06:38.860990 38966 net.cpp:131] Top shape: 20 32 52 52 (1730560)
I1011 15:06:38.860992 38966 net.cpp:139] Memory required for data: 4598457920
I1011 15:06:38.860996 38966 layer_factory.hpp:77] Creating layer conv16
I1011 15:06:38.861052 38966 net.cpp:86] Creating Layer conv16
I1011 15:06:38.861059 38966 net.cpp:408] conv16 <- add2_add2_0_split_0
I1011 15:06:38.861065 38966 net.cpp:382] conv16 -> conv16
I1011 15:06:38.861330 38966 net.cpp:124] Setting up conv16
I1011 15:06:38.861340 38966 net.cpp:131] Top shape: 20 173 52 52 (9355840)
I1011 15:06:38.861343 38966 net.cpp:139] Memory required for data: 4635881280
I1011 15:06:38.861349 38966 layer_factory.hpp:77] Creating layer batch_norm16
I1011 15:06:38.861356 38966 net.cpp:86] Creating Layer batch_norm16
I1011 15:06:38.861359 38966 net.cpp:408] batch_norm16 <- conv16
I1011 15:06:38.861364 38966 net.cpp:369] batch_norm16 -> conv16 (in-place)
I1011 15:06:38.861627 38966 net.cpp:124] Setting up batch_norm16
I1011 15:06:38.861639 38966 net.cpp:131] Top shape: 20 173 52 52 (9355840)
I1011 15:06:38.861644 38966 net.cpp:139] Memory required for data: 4673304640
I1011 15:06:38.861651 38966 layer_factory.hpp:77] Creating layer bn_scale16
I1011 15:06:38.861726 38966 net.cpp:86] Creating Layer bn_scale16
I1011 15:06:38.861732 38966 net.cpp:408] bn_scale16 <- conv16
I1011 15:06:38.861740 38966 net.cpp:369] bn_scale16 -> conv16 (in-place)
I1011 15:06:38.861781 38966 layer_factory.hpp:77] Creating layer bn_scale16
I1011 15:06:38.862053 38966 net.cpp:124] Setting up bn_scale16
I1011 15:06:38.862079 38966 net.cpp:131] Top shape: 20 173 52 52 (9355840)
I1011 15:06:38.862087 38966 net.cpp:139] Memory required for data: 4710728000
I1011 15:06:38.862104 38966 layer_factory.hpp:77] Creating layer relu11
I1011 15:06:38.862121 38966 net.cpp:86] Creating Layer relu11
I1011 15:06:38.862130 38966 net.cpp:408] relu11 <- conv16
I1011 15:06:38.862155 38966 net.cpp:369] relu11 -> conv16 (in-place)
I1011 15:06:38.862170 38966 net.cpp:124] Setting up relu11
I1011 15:06:38.862182 38966 net.cpp:131] Top shape: 20 173 52 52 (9355840)
I1011 15:06:38.862190 38966 net.cpp:139] Memory required for data: 4748151360
I1011 15:06:38.862200 38966 layer_factory.hpp:77] Creating layer conv17
I1011 15:06:38.862215 38966 net.cpp:86] Creating Layer conv17
I1011 15:06:38.862246 38966 net.cpp:408] conv17 <- conv16
I1011 15:06:38.862262 38966 net.cpp:382] conv17 -> conv17
I1011 15:06:38.862763 38966 net.cpp:124] Setting up conv17
I1011 15:06:38.862787 38966 net.cpp:131] Top shape: 20 173 52 52 (9355840)
I1011 15:06:38.862795 38966 net.cpp:139] Memory required for data: 4785574720
I1011 15:06:38.862807 38966 layer_factory.hpp:77] Creating layer batch_norm17
I1011 15:06:38.862821 38966 net.cpp:86] Creating Layer batch_norm17
I1011 15:06:38.862830 38966 net.cpp:408] batch_norm17 <- conv17
I1011 15:06:38.862843 38966 net.cpp:369] batch_norm17 -> conv17 (in-place)
I1011 15:06:38.863435 38966 net.cpp:124] Setting up batch_norm17
I1011 15:06:38.863476 38966 net.cpp:131] Top shape: 20 173 52 52 (9355840)
I1011 15:06:38.863484 38966 net.cpp:139] Memory required for data: 4822998080
I1011 15:06:38.863504 38966 layer_factory.hpp:77] Creating layer bn_scale17
I1011 15:06:38.863588 38966 net.cpp:86] Creating Layer bn_scale17
I1011 15:06:38.863613 38966 net.cpp:408] bn_scale17 <- conv17
I1011 15:06:38.863667 38966 net.cpp:369] bn_scale17 -> conv17 (in-place)
I1011 15:06:38.863835 38966 layer_factory.hpp:77] Creating layer bn_scale17
I1011 15:06:38.864154 38966 net.cpp:124] Setting up bn_scale17
I1011 15:06:38.864185 38966 net.cpp:131] Top shape: 20 173 52 52 (9355840)
I1011 15:06:38.864198 38966 net.cpp:139] Memory required for data: 4860421440
I1011 15:06:38.864221 38966 layer_factory.hpp:77] Creating layer relu12
I1011 15:06:38.864249 38966 net.cpp:86] Creating Layer relu12
I1011 15:06:38.864266 38966 net.cpp:408] relu12 <- conv17
I1011 15:06:38.864285 38966 net.cpp:369] relu12 -> conv17 (in-place)
I1011 15:06:38.864373 38966 net.cpp:124] Setting up relu12
I1011 15:06:38.864456 38966 net.cpp:131] Top shape: 20 173 52 52 (9355840)
I1011 15:06:38.864513 38966 net.cpp:139] Memory required for data: 4897844800
I1011 15:06:38.864569 38966 layer_factory.hpp:77] Creating layer conv18
I1011 15:06:38.864642 38966 net.cpp:86] Creating Layer conv18
I1011 15:06:38.864703 38966 net.cpp:408] conv18 <- conv17
I1011 15:06:38.864782 38966 net.cpp:382] conv18 -> conv18
I1011 15:06:38.865361 38966 net.cpp:124] Setting up conv18
I1011 15:06:38.865393 38966 net.cpp:131] Top shape: 20 32 52 52 (1730560)
I1011 15:06:38.865407 38966 net.cpp:139] Memory required for data: 4904767040
I1011 15:06:38.865427 38966 layer_factory.hpp:77] Creating layer batch_norm18
I1011 15:06:38.865450 38966 net.cpp:86] Creating Layer batch_norm18
I1011 15:06:38.865466 38966 net.cpp:408] batch_norm18 <- conv18
I1011 15:06:38.865494 38966 net.cpp:369] batch_norm18 -> conv18 (in-place)
I1011 15:06:38.865916 38966 net.cpp:124] Setting up batch_norm18
I1011 15:06:38.865938 38966 net.cpp:131] Top shape: 20 32 52 52 (1730560)
I1011 15:06:38.865948 38966 net.cpp:139] Memory required for data: 4911689280
I1011 15:06:38.865978 38966 layer_factory.hpp:77] Creating layer bn_scale18
I1011 15:06:38.866003 38966 net.cpp:86] Creating Layer bn_scale18
I1011 15:06:38.866021 38966 net.cpp:408] bn_scale18 <- conv18
I1011 15:06:38.866048 38966 net.cpp:369] bn_scale18 -> conv18 (in-place)
I1011 15:06:38.866173 38966 layer_factory.hpp:77] Creating layer bn_scale18
I1011 15:06:38.866442 38966 net.cpp:124] Setting up bn_scale18
I1011 15:06:38.866469 38966 net.cpp:131] Top shape: 20 32 52 52 (1730560)
I1011 15:06:38.866482 38966 net.cpp:139] Memory required for data: 4918611520
I1011 15:06:38.866508 38966 layer_factory.hpp:77] Creating layer add3
I1011 15:06:38.866533 38966 net.cpp:86] Creating Layer add3
I1011 15:06:38.866554 38966 net.cpp:408] add3 <- add2_add2_0_split_1
I1011 15:06:38.866575 38966 net.cpp:408] add3 <- conv18
I1011 15:06:38.866601 38966 net.cpp:382] add3 -> add3
I1011 15:06:38.866694 38966 net.cpp:124] Setting up add3
I1011 15:06:38.866716 38966 net.cpp:131] Top shape: 20 32 52 52 (1730560)
I1011 15:06:38.866727 38966 net.cpp:139] Memory required for data: 4925533760
I1011 15:06:38.866745 38966 layer_factory.hpp:77] Creating layer conv19
I1011 15:06:38.866783 38966 net.cpp:86] Creating Layer conv19
I1011 15:06:38.866842 38966 net.cpp:408] conv19 <- add3
I1011 15:06:38.866881 38966 net.cpp:382] conv19 -> conv19
I1011 15:06:38.867432 38966 net.cpp:124] Setting up conv19
I1011 15:06:38.867458 38966 net.cpp:131] Top shape: 20 173 52 52 (9355840)
I1011 15:06:38.867471 38966 net.cpp:139] Memory required for data: 4962957120
I1011 15:06:38.867493 38966 layer_factory.hpp:77] Creating layer batch_norm19
I1011 15:06:38.867519 38966 net.cpp:86] Creating Layer batch_norm19
I1011 15:06:38.867537 38966 net.cpp:408] batch_norm19 <- conv19
I1011 15:06:38.867568 38966 net.cpp:369] batch_norm19 -> conv19 (in-place)
I1011 15:06:38.869827 38966 net.cpp:124] Setting up batch_norm19
I1011 15:06:38.869863 38966 net.cpp:131] Top shape: 20 173 52 52 (9355840)
I1011 15:06:38.869877 38966 net.cpp:139] Memory required for data: 5000380480
I1011 15:06:38.869907 38966 layer_factory.hpp:77] Creating layer bn_scale19
I1011 15:06:38.869937 38966 net.cpp:86] Creating Layer bn_scale19
I1011 15:06:38.870007 38966 net.cpp:408] bn_scale19 <- conv19
I1011 15:06:38.870077 38966 net.cpp:369] bn_scale19 -> conv19 (in-place)
I1011 15:06:38.870251 38966 layer_factory.hpp:77] Creating layer bn_scale19
I1011 15:06:38.870568 38966 net.cpp:124] Setting up bn_scale19
I1011 15:06:38.870596 38966 net.cpp:131] Top shape: 20 173 52 52 (9355840)
I1011 15:06:38.870610 38966 net.cpp:139] Memory required for data: 5037803840
I1011 15:06:38.870635 38966 layer_factory.hpp:77] Creating layer relu13
I1011 15:06:38.870707 38966 net.cpp:86] Creating Layer relu13
I1011 15:06:38.870769 38966 net.cpp:408] relu13 <- conv19
I1011 15:06:38.870841 38966 net.cpp:369] relu13 -> conv19 (in-place)
I1011 15:06:38.870913 38966 net.cpp:124] Setting up relu13
I1011 15:06:38.870980 38966 net.cpp:131] Top shape: 20 173 52 52 (9355840)
I1011 15:06:38.871029 38966 net.cpp:139] Memory required for data: 5075227200
I1011 15:06:38.871084 38966 layer_factory.hpp:77] Creating layer conv20
I1011 15:06:38.871134 38966 net.cpp:86] Creating Layer conv20
I1011 15:06:38.871156 38966 net.cpp:408] conv20 <- conv19
I1011 15:06:38.871186 38966 net.cpp:382] conv20 -> conv20
I1011 15:06:38.871660 38966 net.cpp:124] Setting up conv20
I1011 15:06:38.871687 38966 net.cpp:131] Top shape: 20 173 26 26 (2338960)
I1011 15:06:38.871695 38966 net.cpp:139] Memory required for data: 5084583040
I1011 15:06:38.871711 38966 layer_factory.hpp:77] Creating layer batch_norm20
I1011 15:06:38.871739 38966 net.cpp:86] Creating Layer batch_norm20
I1011 15:06:38.871759 38966 net.cpp:408] batch_norm20 <- conv20
I1011 15:06:38.871779 38966 net.cpp:369] batch_norm20 -> conv20 (in-place)
I1011 15:06:38.872205 38966 net.cpp:124] Setting up batch_norm20
I1011 15:06:38.872226 38966 net.cpp:131] Top shape: 20 173 26 26 (2338960)
I1011 15:06:38.872233 38966 net.cpp:139] Memory required for data: 5093938880
I1011 15:06:38.872261 38966 layer_factory.hpp:77] Creating layer bn_scale20
I1011 15:06:38.872283 38966 net.cpp:86] Creating Layer bn_scale20
I1011 15:06:38.872296 38966 net.cpp:408] bn_scale20 <- conv20
I1011 15:06:38.872323 38966 net.cpp:369] bn_scale20 -> conv20 (in-place)
I1011 15:06:38.872443 38966 layer_factory.hpp:77] Creating layer bn_scale20
I1011 15:06:38.872704 38966 net.cpp:124] Setting up bn_scale20
I1011 15:06:38.872726 38966 net.cpp:131] Top shape: 20 173 26 26 (2338960)
I1011 15:06:38.872740 38966 net.cpp:139] Memory required for data: 5103294720
I1011 15:06:38.872767 38966 layer_factory.hpp:77] Creating layer relu14
I1011 15:06:38.872790 38966 net.cpp:86] Creating Layer relu14
I1011 15:06:38.872808 38966 net.cpp:408] relu14 <- conv20
I1011 15:06:38.872838 38966 net.cpp:369] relu14 -> conv20 (in-place)
I1011 15:06:38.872866 38966 net.cpp:124] Setting up relu14
I1011 15:06:38.872889 38966 net.cpp:131] Top shape: 20 173 26 26 (2338960)
I1011 15:06:38.872906 38966 net.cpp:139] Memory required for data: 5112650560
I1011 15:06:38.872925 38966 layer_factory.hpp:77] Creating layer conv21
I1011 15:06:38.872962 38966 net.cpp:86] Creating Layer conv21
I1011 15:06:38.872983 38966 net.cpp:408] conv21 <- conv20
I1011 15:06:38.873011 38966 net.cpp:382] conv21 -> conv21
I1011 15:06:38.873698 38966 net.cpp:124] Setting up conv21
I1011 15:06:38.873723 38966 net.cpp:131] Top shape: 20 64 26 26 (865280)
I1011 15:06:38.873736 38966 net.cpp:139] Memory required for data: 5116111680
I1011 15:06:38.873759 38966 layer_factory.hpp:77] Creating layer batch_norm21
I1011 15:06:38.873791 38966 net.cpp:86] Creating Layer batch_norm21
I1011 15:06:38.873808 38966 net.cpp:408] batch_norm21 <- conv21
I1011 15:06:38.873832 38966 net.cpp:369] batch_norm21 -> conv21 (in-place)
I1011 15:06:38.874230 38966 net.cpp:124] Setting up batch_norm21
I1011 15:06:38.874251 38966 net.cpp:131] Top shape: 20 64 26 26 (865280)
I1011 15:06:38.874265 38966 net.cpp:139] Memory required for data: 5119572800
I1011 15:06:38.874298 38966 layer_factory.hpp:77] Creating layer bn_scale21
I1011 15:06:38.874328 38966 net.cpp:86] Creating Layer bn_scale21
I1011 15:06:38.874349 38966 net.cpp:408] bn_scale21 <- conv21
I1011 15:06:38.874372 38966 net.cpp:369] bn_scale21 -> conv21 (in-place)
I1011 15:06:38.874495 38966 layer_factory.hpp:77] Creating layer bn_scale21
I1011 15:06:38.874758 38966 net.cpp:124] Setting up bn_scale21
I1011 15:06:38.874780 38966 net.cpp:131] Top shape: 20 64 26 26 (865280)
I1011 15:06:38.874794 38966 net.cpp:139] Memory required for data: 5123033920
I1011 15:06:38.874819 38966 layer_factory.hpp:77] Creating layer conv21_bn_scale21_0_split
I1011 15:06:38.874855 38966 net.cpp:86] Creating Layer conv21_bn_scale21_0_split
I1011 15:06:38.874876 38966 net.cpp:408] conv21_bn_scale21_0_split <- conv21
I1011 15:06:38.874907 38966 net.cpp:382] conv21_bn_scale21_0_split -> conv21_bn_scale21_0_split_0
I1011 15:06:38.874945 38966 net.cpp:382] conv21_bn_scale21_0_split -> conv21_bn_scale21_0_split_1
I1011 15:06:38.875063 38966 net.cpp:124] Setting up conv21_bn_scale21_0_split
I1011 15:06:38.875083 38966 net.cpp:131] Top shape: 20 64 26 26 (865280)
I1011 15:06:38.875103 38966 net.cpp:131] Top shape: 20 64 26 26 (865280)
I1011 15:06:38.875118 38966 net.cpp:139] Memory required for data: 5129956160
I1011 15:06:38.875136 38966 layer_factory.hpp:77] Creating layer conv22
I1011 15:06:38.875169 38966 net.cpp:86] Creating Layer conv22
I1011 15:06:38.875188 38966 net.cpp:408] conv22 <- conv21_bn_scale21_0_split_0
I1011 15:06:38.875233 38966 net.cpp:382] conv22 -> conv22
I1011 15:06:38.875805 38966 net.cpp:124] Setting up conv22
I1011 15:06:38.875818 38966 net.cpp:131] Top shape: 20 346 26 26 (4677920)
I1011 15:06:38.875823 38966 net.cpp:139] Memory required for data: 5148667840
I1011 15:06:38.875829 38966 layer_factory.hpp:77] Creating layer batch_norm22
I1011 15:06:38.875847 38966 net.cpp:86] Creating Layer batch_norm22
I1011 15:06:38.875857 38966 net.cpp:408] batch_norm22 <- conv22
I1011 15:06:38.875867 38966 net.cpp:369] batch_norm22 -> conv22 (in-place)
I1011 15:06:38.876076 38966 net.cpp:124] Setting up batch_norm22
I1011 15:06:38.876087 38966 net.cpp:131] Top shape: 20 346 26 26 (4677920)
I1011 15:06:38.876091 38966 net.cpp:139] Memory required for data: 5167379520
I1011 15:06:38.876123 38966 layer_factory.hpp:77] Creating layer bn_scale22
I1011 15:06:38.876138 38966 net.cpp:86] Creating Layer bn_scale22
I1011 15:06:38.876148 38966 net.cpp:408] bn_scale22 <- conv22
I1011 15:06:38.876160 38966 net.cpp:369] bn_scale22 -> conv22 (in-place)
I1011 15:06:38.876225 38966 layer_factory.hpp:77] Creating layer bn_scale22
I1011 15:06:38.876360 38966 net.cpp:124] Setting up bn_scale22
I1011 15:06:38.876372 38966 net.cpp:131] Top shape: 20 346 26 26 (4677920)
I1011 15:06:38.876376 38966 net.cpp:139] Memory required for data: 5186091200
I1011 15:06:38.876386 38966 layer_factory.hpp:77] Creating layer relu15
I1011 15:06:38.876401 38966 net.cpp:86] Creating Layer relu15
I1011 15:06:38.876411 38966 net.cpp:408] relu15 <- conv22
I1011 15:06:38.876420 38966 net.cpp:369] relu15 -> conv22 (in-place)
I1011 15:06:38.876432 38966 net.cpp:124] Setting up relu15
I1011 15:06:38.876443 38966 net.cpp:131] Top shape: 20 346 26 26 (4677920)
I1011 15:06:38.876452 38966 net.cpp:139] Memory required for data: 5204802880
I1011 15:06:38.876459 38966 layer_factory.hpp:77] Creating layer conv23
I1011 15:06:38.876497 38966 net.cpp:86] Creating Layer conv23
I1011 15:06:38.876510 38966 net.cpp:408] conv23 <- conv22
I1011 15:06:38.876529 38966 net.cpp:382] conv23 -> conv23
I1011 15:06:38.876771 38966 net.cpp:124] Setting up conv23
I1011 15:06:38.876783 38966 net.cpp:131] Top shape: 20 346 26 26 (4677920)
I1011 15:06:38.876786 38966 net.cpp:139] Memory required for data: 5223514560
I1011 15:06:38.876794 38966 layer_factory.hpp:77] Creating layer batch_norm23
I1011 15:06:38.876806 38966 net.cpp:86] Creating Layer batch_norm23
I1011 15:06:38.876816 38966 net.cpp:408] batch_norm23 <- conv23
I1011 15:06:38.876829 38966 net.cpp:369] batch_norm23 -> conv23 (in-place)
I1011 15:06:38.877036 38966 net.cpp:124] Setting up batch_norm23
I1011 15:06:38.877048 38966 net.cpp:131] Top shape: 20 346 26 26 (4677920)
I1011 15:06:38.877051 38966 net.cpp:139] Memory required for data: 5242226240
I1011 15:06:38.877064 38966 layer_factory.hpp:77] Creating layer bn_scale23
I1011 15:06:38.877075 38966 net.cpp:86] Creating Layer bn_scale23
I1011 15:06:38.877085 38966 net.cpp:408] bn_scale23 <- conv23
I1011 15:06:38.877097 38966 net.cpp:369] bn_scale23 -> conv23 (in-place)
I1011 15:06:38.877163 38966 layer_factory.hpp:77] Creating layer bn_scale23
I1011 15:06:38.877291 38966 net.cpp:124] Setting up bn_scale23
I1011 15:06:38.877302 38966 net.cpp:131] Top shape: 20 346 26 26 (4677920)
I1011 15:06:38.877306 38966 net.cpp:139] Memory required for data: 5260937920
I1011 15:06:38.877316 38966 layer_factory.hpp:77] Creating layer relu16
I1011 15:06:38.877331 38966 net.cpp:86] Creating Layer relu16
I1011 15:06:38.877341 38966 net.cpp:408] relu16 <- conv23
I1011 15:06:38.877351 38966 net.cpp:369] relu16 -> conv23 (in-place)
I1011 15:06:38.877363 38966 net.cpp:124] Setting up relu16
I1011 15:06:38.877375 38966 net.cpp:131] Top shape: 20 346 26 26 (4677920)
I1011 15:06:38.877383 38966 net.cpp:139] Memory required for data: 5279649600
I1011 15:06:38.877389 38966 layer_factory.hpp:77] Creating layer conv24
I1011 15:06:38.877411 38966 net.cpp:86] Creating Layer conv24
I1011 15:06:38.877423 38966 net.cpp:408] conv24 <- conv23
I1011 15:06:38.877442 38966 net.cpp:382] conv24 -> conv24
I1011 15:06:38.877892 38966 net.cpp:124] Setting up conv24
I1011 15:06:38.877905 38966 net.cpp:131] Top shape: 20 64 26 26 (865280)
I1011 15:06:38.877909 38966 net.cpp:139] Memory required for data: 5283110720
I1011 15:06:38.877918 38966 layer_factory.hpp:77] Creating layer batch_norm24
I1011 15:06:38.877933 38966 net.cpp:86] Creating Layer batch_norm24
I1011 15:06:38.877943 38966 net.cpp:408] batch_norm24 <- conv24
I1011 15:06:38.877952 38966 net.cpp:369] batch_norm24 -> conv24 (in-place)
I1011 15:06:38.878160 38966 net.cpp:124] Setting up batch_norm24
I1011 15:06:38.878171 38966 net.cpp:131] Top shape: 20 64 26 26 (865280)
I1011 15:06:38.878175 38966 net.cpp:139] Memory required for data: 5286571840
I1011 15:06:38.878188 38966 layer_factory.hpp:77] Creating layer bn_scale24
I1011 15:06:38.878201 38966 net.cpp:86] Creating Layer bn_scale24
I1011 15:06:38.878209 38966 net.cpp:408] bn_scale24 <- conv24
I1011 15:06:38.878224 38966 net.cpp:369] bn_scale24 -> conv24 (in-place)
I1011 15:06:38.878288 38966 layer_factory.hpp:77] Creating layer bn_scale24
I1011 15:06:38.878422 38966 net.cpp:124] Setting up bn_scale24
I1011 15:06:38.878433 38966 net.cpp:131] Top shape: 20 64 26 26 (865280)
I1011 15:06:38.878437 38966 net.cpp:139] Memory required for data: 5290032960
I1011 15:06:38.878448 38966 layer_factory.hpp:77] Creating layer add4
I1011 15:06:38.878459 38966 net.cpp:86] Creating Layer add4
I1011 15:06:38.878469 38966 net.cpp:408] add4 <- conv21_bn_scale21_0_split_1
I1011 15:06:38.878479 38966 net.cpp:408] add4 <- conv24
I1011 15:06:38.878497 38966 net.cpp:382] add4 -> add4
I1011 15:06:38.878543 38966 net.cpp:124] Setting up add4
I1011 15:06:38.878553 38966 net.cpp:131] Top shape: 20 64 26 26 (865280)
I1011 15:06:38.878557 38966 net.cpp:139] Memory required for data: 5293494080
I1011 15:06:38.878562 38966 layer_factory.hpp:77] Creating layer add4_add4_0_split
I1011 15:06:38.878592 38966 net.cpp:86] Creating Layer add4_add4_0_split
I1011 15:06:38.878603 38966 net.cpp:408] add4_add4_0_split <- add4
I1011 15:06:38.878621 38966 net.cpp:382] add4_add4_0_split -> add4_add4_0_split_0
I1011 15:06:38.878638 38966 net.cpp:382] add4_add4_0_split -> add4_add4_0_split_1
I1011 15:06:38.878693 38966 net.cpp:124] Setting up add4_add4_0_split
I1011 15:06:38.878702 38966 net.cpp:131] Top shape: 20 64 26 26 (865280)
I1011 15:06:38.878707 38966 net.cpp:131] Top shape: 20 64 26 26 (865280)
I1011 15:06:38.878713 38966 net.cpp:139] Memory required for data: 5300416320
I1011 15:06:38.878722 38966 layer_factory.hpp:77] Creating layer conv25
I1011 15:06:38.878743 38966 net.cpp:86] Creating Layer conv25
I1011 15:06:38.878753 38966 net.cpp:408] conv25 <- add4_add4_0_split_0
I1011 15:06:38.878769 38966 net.cpp:382] conv25 -> conv25
I1011 15:06:38.879209 38966 net.cpp:124] Setting up conv25
I1011 15:06:38.879221 38966 net.cpp:131] Top shape: 20 327 26 26 (4421040)
I1011 15:06:38.879225 38966 net.cpp:139] Memory required for data: 5318100480
I1011 15:06:38.879230 38966 layer_factory.hpp:77] Creating layer batch_norm25
I1011 15:06:38.879240 38966 net.cpp:86] Creating Layer batch_norm25
I1011 15:06:38.879245 38966 net.cpp:408] batch_norm25 <- conv25
I1011 15:06:38.879257 38966 net.cpp:369] batch_norm25 -> conv25 (in-place)
I1011 15:06:38.879451 38966 net.cpp:124] Setting up batch_norm25
I1011 15:06:38.879462 38966 net.cpp:131] Top shape: 20 327 26 26 (4421040)
I1011 15:06:38.879464 38966 net.cpp:139] Memory required for data: 5335784640
I1011 15:06:38.879472 38966 layer_factory.hpp:77] Creating layer bn_scale25
I1011 15:06:38.879482 38966 net.cpp:86] Creating Layer bn_scale25
I1011 15:06:38.879487 38966 net.cpp:408] bn_scale25 <- conv25
I1011 15:06:38.879493 38966 net.cpp:369] bn_scale25 -> conv25 (in-place)
I1011 15:06:38.879530 38966 layer_factory.hpp:77] Creating layer bn_scale25
I1011 15:06:38.879647 38966 net.cpp:124] Setting up bn_scale25
I1011 15:06:38.879655 38966 net.cpp:131] Top shape: 20 327 26 26 (4421040)
I1011 15:06:38.879659 38966 net.cpp:139] Memory required for data: 5353468800
I1011 15:06:38.879665 38966 layer_factory.hpp:77] Creating layer relu17
I1011 15:06:38.879673 38966 net.cpp:86] Creating Layer relu17
I1011 15:06:38.879678 38966 net.cpp:408] relu17 <- conv25
I1011 15:06:38.879683 38966 net.cpp:369] relu17 -> conv25 (in-place)
I1011 15:06:38.879691 38966 net.cpp:124] Setting up relu17
I1011 15:06:38.879695 38966 net.cpp:131] Top shape: 20 327 26 26 (4421040)
I1011 15:06:38.879699 38966 net.cpp:139] Memory required for data: 5371152960
I1011 15:06:38.879703 38966 layer_factory.hpp:77] Creating layer conv26
I1011 15:06:38.879709 38966 net.cpp:86] Creating Layer conv26
I1011 15:06:38.879714 38966 net.cpp:408] conv26 <- conv25
I1011 15:06:38.879721 38966 net.cpp:382] conv26 -> conv26
I1011 15:06:38.879928 38966 net.cpp:124] Setting up conv26
I1011 15:06:38.879937 38966 net.cpp:131] Top shape: 20 327 26 26 (4421040)
I1011 15:06:38.879941 38966 net.cpp:139] Memory required for data: 5388837120
I1011 15:06:38.879946 38966 layer_factory.hpp:77] Creating layer batch_norm26
I1011 15:06:38.879956 38966 net.cpp:86] Creating Layer batch_norm26
I1011 15:06:38.879959 38966 net.cpp:408] batch_norm26 <- conv26
I1011 15:06:38.879964 38966 net.cpp:369] batch_norm26 -> conv26 (in-place)
I1011 15:06:38.880143 38966 net.cpp:124] Setting up batch_norm26
I1011 15:06:38.880151 38966 net.cpp:131] Top shape: 20 327 26 26 (4421040)
I1011 15:06:38.880156 38966 net.cpp:139] Memory required for data: 5406521280
I1011 15:06:38.880163 38966 layer_factory.hpp:77] Creating layer bn_scale26
I1011 15:06:38.880169 38966 net.cpp:86] Creating Layer bn_scale26
I1011 15:06:38.880173 38966 net.cpp:408] bn_scale26 <- conv26
I1011 15:06:38.880180 38966 net.cpp:369] bn_scale26 -> conv26 (in-place)
I1011 15:06:38.880214 38966 layer_factory.hpp:77] Creating layer bn_scale26
I1011 15:06:38.880323 38966 net.cpp:124] Setting up bn_scale26
I1011 15:06:38.880334 38966 net.cpp:131] Top shape: 20 327 26 26 (4421040)
I1011 15:06:38.880352 38966 net.cpp:139] Memory required for data: 5424205440
I1011 15:06:38.880358 38966 layer_factory.hpp:77] Creating layer relu18
I1011 15:06:38.880364 38966 net.cpp:86] Creating Layer relu18
I1011 15:06:38.880368 38966 net.cpp:408] relu18 <- conv26
I1011 15:06:38.880374 38966 net.cpp:369] relu18 -> conv26 (in-place)
I1011 15:06:38.880380 38966 net.cpp:124] Setting up relu18
I1011 15:06:38.880385 38966 net.cpp:131] Top shape: 20 327 26 26 (4421040)
I1011 15:06:38.880388 38966 net.cpp:139] Memory required for data: 5441889600
I1011 15:06:38.880393 38966 layer_factory.hpp:77] Creating layer conv27
I1011 15:06:38.880403 38966 net.cpp:86] Creating Layer conv27
I1011 15:06:38.880409 38966 net.cpp:408] conv27 <- conv26
I1011 15:06:38.880416 38966 net.cpp:382] conv27 -> conv27
I1011 15:06:38.880836 38966 net.cpp:124] Setting up conv27
I1011 15:06:38.880844 38966 net.cpp:131] Top shape: 20 64 26 26 (865280)
I1011 15:06:38.880848 38966 net.cpp:139] Memory required for data: 5445350720
I1011 15:06:38.880853 38966 layer_factory.hpp:77] Creating layer batch_norm27
I1011 15:06:38.880861 38966 net.cpp:86] Creating Layer batch_norm27
I1011 15:06:38.880864 38966 net.cpp:408] batch_norm27 <- conv27
I1011 15:06:38.880869 38966 net.cpp:369] batch_norm27 -> conv27 (in-place)
I1011 15:06:38.881057 38966 net.cpp:124] Setting up batch_norm27
I1011 15:06:38.881067 38966 net.cpp:131] Top shape: 20 64 26 26 (865280)
I1011 15:06:38.881070 38966 net.cpp:139] Memory required for data: 5448811840
I1011 15:06:38.881078 38966 layer_factory.hpp:77] Creating layer bn_scale27
I1011 15:06:38.881088 38966 net.cpp:86] Creating Layer bn_scale27
I1011 15:06:38.881093 38966 net.cpp:408] bn_scale27 <- conv27
I1011 15:06:38.881098 38966 net.cpp:369] bn_scale27 -> conv27 (in-place)
I1011 15:06:38.881139 38966 layer_factory.hpp:77] Creating layer bn_scale27
I1011 15:06:38.881253 38966 net.cpp:124] Setting up bn_scale27
I1011 15:06:38.881261 38966 net.cpp:131] Top shape: 20 64 26 26 (865280)
I1011 15:06:38.881264 38966 net.cpp:139] Memory required for data: 5452272960
I1011 15:06:38.881271 38966 layer_factory.hpp:77] Creating layer add5
I1011 15:06:38.881280 38966 net.cpp:86] Creating Layer add5
I1011 15:06:38.881284 38966 net.cpp:408] add5 <- add4_add4_0_split_1
I1011 15:06:38.881289 38966 net.cpp:408] add5 <- conv27
I1011 15:06:38.881294 38966 net.cpp:382] add5 -> add5
I1011 15:06:38.881319 38966 net.cpp:124] Setting up add5
I1011 15:06:38.881326 38966 net.cpp:131] Top shape: 20 64 26 26 (865280)
I1011 15:06:38.881330 38966 net.cpp:139] Memory required for data: 5455734080
I1011 15:06:38.881335 38966 layer_factory.hpp:77] Creating layer add5_add5_0_split
I1011 15:06:38.881340 38966 net.cpp:86] Creating Layer add5_add5_0_split
I1011 15:06:38.881345 38966 net.cpp:408] add5_add5_0_split <- add5
I1011 15:06:38.881352 38966 net.cpp:382] add5_add5_0_split -> add5_add5_0_split_0
I1011 15:06:38.881359 38966 net.cpp:382] add5_add5_0_split -> add5_add5_0_split_1
I1011 15:06:38.881394 38966 net.cpp:124] Setting up add5_add5_0_split
I1011 15:06:38.881402 38966 net.cpp:131] Top shape: 20 64 26 26 (865280)
I1011 15:06:38.881407 38966 net.cpp:131] Top shape: 20 64 26 26 (865280)
I1011 15:06:38.881410 38966 net.cpp:139] Memory required for data: 5462656320
I1011 15:06:38.881413 38966 layer_factory.hpp:77] Creating layer conv28
I1011 15:06:38.881422 38966 net.cpp:86] Creating Layer conv28
I1011 15:06:38.881426 38966 net.cpp:408] conv28 <- add5_add5_0_split_0
I1011 15:06:38.881433 38966 net.cpp:382] conv28 -> conv28
I1011 15:06:38.881850 38966 net.cpp:124] Setting up conv28
I1011 15:06:38.881860 38966 net.cpp:131] Top shape: 20 327 26 26 (4421040)
I1011 15:06:38.881862 38966 net.cpp:139] Memory required for data: 5480340480
I1011 15:06:38.881868 38966 layer_factory.hpp:77] Creating layer batch_norm28
I1011 15:06:38.881875 38966 net.cpp:86] Creating Layer batch_norm28
I1011 15:06:38.881878 38966 net.cpp:408] batch_norm28 <- conv28
I1011 15:06:38.881887 38966 net.cpp:369] batch_norm28 -> conv28 (in-place)
I1011 15:06:38.882072 38966 net.cpp:124] Setting up batch_norm28
I1011 15:06:38.882091 38966 net.cpp:131] Top shape: 20 327 26 26 (4421040)
I1011 15:06:38.882095 38966 net.cpp:139] Memory required for data: 5498024640
I1011 15:06:38.882103 38966 layer_factory.hpp:77] Creating layer bn_scale28
I1011 15:06:38.882109 38966 net.cpp:86] Creating Layer bn_scale28
I1011 15:06:38.882114 38966 net.cpp:408] bn_scale28 <- conv28
I1011 15:06:38.882119 38966 net.cpp:369] bn_scale28 -> conv28 (in-place)
I1011 15:06:38.882158 38966 layer_factory.hpp:77] Creating layer bn_scale28
I1011 15:06:38.882269 38966 net.cpp:124] Setting up bn_scale28
I1011 15:06:38.882277 38966 net.cpp:131] Top shape: 20 327 26 26 (4421040)
I1011 15:06:38.882282 38966 net.cpp:139] Memory required for data: 5515708800
I1011 15:06:38.882287 38966 layer_factory.hpp:77] Creating layer relu19
I1011 15:06:38.882293 38966 net.cpp:86] Creating Layer relu19
I1011 15:06:38.882297 38966 net.cpp:408] relu19 <- conv28
I1011 15:06:38.882304 38966 net.cpp:369] relu19 -> conv28 (in-place)
I1011 15:06:38.882310 38966 net.cpp:124] Setting up relu19
I1011 15:06:38.882315 38966 net.cpp:131] Top shape: 20 327 26 26 (4421040)
I1011 15:06:38.882319 38966 net.cpp:139] Memory required for data: 5533392960
I1011 15:06:38.882323 38966 layer_factory.hpp:77] Creating layer conv29
I1011 15:06:38.882333 38966 net.cpp:86] Creating Layer conv29
I1011 15:06:38.882339 38966 net.cpp:408] conv29 <- conv28
I1011 15:06:38.882344 38966 net.cpp:382] conv29 -> conv29
I1011 15:06:38.882562 38966 net.cpp:124] Setting up conv29
I1011 15:06:38.882571 38966 net.cpp:131] Top shape: 20 327 26 26 (4421040)
I1011 15:06:38.882575 38966 net.cpp:139] Memory required for data: 5551077120
I1011 15:06:38.882580 38966 layer_factory.hpp:77] Creating layer batch_norm29
I1011 15:06:38.882591 38966 net.cpp:86] Creating Layer batch_norm29
I1011 15:06:38.882597 38966 net.cpp:408] batch_norm29 <- conv29
I1011 15:06:38.882602 38966 net.cpp:369] batch_norm29 -> conv29 (in-place)
I1011 15:06:38.882782 38966 net.cpp:124] Setting up batch_norm29
I1011 15:06:38.882791 38966 net.cpp:131] Top shape: 20 327 26 26 (4421040)
I1011 15:06:38.882793 38966 net.cpp:139] Memory required for data: 5568761280
I1011 15:06:38.882802 38966 layer_factory.hpp:77] Creating layer bn_scale29
I1011 15:06:38.882807 38966 net.cpp:86] Creating Layer bn_scale29
I1011 15:06:38.882812 38966 net.cpp:408] bn_scale29 <- conv29
I1011 15:06:38.882818 38966 net.cpp:369] bn_scale29 -> conv29 (in-place)
I1011 15:06:38.882854 38966 layer_factory.hpp:77] Creating layer bn_scale29
I1011 15:06:38.882966 38966 net.cpp:124] Setting up bn_scale29
I1011 15:06:38.882974 38966 net.cpp:131] Top shape: 20 327 26 26 (4421040)
I1011 15:06:38.882978 38966 net.cpp:139] Memory required for data: 5586445440
I1011 15:06:38.882984 38966 layer_factory.hpp:77] Creating layer relu20
I1011 15:06:38.882990 38966 net.cpp:86] Creating Layer relu20
I1011 15:06:38.882994 38966 net.cpp:408] relu20 <- conv29
I1011 15:06:38.883002 38966 net.cpp:369] relu20 -> conv29 (in-place)
I1011 15:06:38.883008 38966 net.cpp:124] Setting up relu20
I1011 15:06:38.883013 38966 net.cpp:131] Top shape: 20 327 26 26 (4421040)
I1011 15:06:38.883015 38966 net.cpp:139] Memory required for data: 5604129600
I1011 15:06:38.883019 38966 layer_factory.hpp:77] Creating layer conv30
I1011 15:06:38.883029 38966 net.cpp:86] Creating Layer conv30
I1011 15:06:38.883034 38966 net.cpp:408] conv30 <- conv29
I1011 15:06:38.883041 38966 net.cpp:382] conv30 -> conv30
I1011 15:06:38.883461 38966 net.cpp:124] Setting up conv30
I1011 15:06:38.883472 38966 net.cpp:131] Top shape: 20 64 26 26 (865280)
I1011 15:06:38.883476 38966 net.cpp:139] Memory required for data: 5607590720
I1011 15:06:38.883486 38966 layer_factory.hpp:77] Creating layer batch_norm30
I1011 15:06:38.883492 38966 net.cpp:86] Creating Layer batch_norm30
I1011 15:06:38.883497 38966 net.cpp:408] batch_norm30 <- conv30
I1011 15:06:38.883502 38966 net.cpp:369] batch_norm30 -> conv30 (in-place)
I1011 15:06:38.883692 38966 net.cpp:124] Setting up batch_norm30
I1011 15:06:38.883704 38966 net.cpp:131] Top shape: 20 64 26 26 (865280)
I1011 15:06:38.883725 38966 net.cpp:139] Memory required for data: 5611051840
I1011 15:06:38.883740 38966 layer_factory.hpp:77] Creating layer bn_scale30
I1011 15:06:38.883751 38966 net.cpp:86] Creating Layer bn_scale30
I1011 15:06:38.883759 38966 net.cpp:408] bn_scale30 <- conv30
I1011 15:06:38.883769 38966 net.cpp:369] bn_scale30 -> conv30 (in-place)
I1011 15:06:38.883831 38966 layer_factory.hpp:77] Creating layer bn_scale30
I1011 15:06:38.883970 38966 net.cpp:124] Setting up bn_scale30
I1011 15:06:38.883983 38966 net.cpp:131] Top shape: 20 64 26 26 (865280)
I1011 15:06:38.883989 38966 net.cpp:139] Memory required for data: 5614512960
I1011 15:06:38.884001 38966 layer_factory.hpp:77] Creating layer add6
I1011 15:06:38.884011 38966 net.cpp:86] Creating Layer add6
I1011 15:06:38.884018 38966 net.cpp:408] add6 <- add5_add5_0_split_1
I1011 15:06:38.884027 38966 net.cpp:408] add6 <- conv30
I1011 15:06:38.884045 38966 net.cpp:382] add6 -> add6
I1011 15:06:38.884083 38966 net.cpp:124] Setting up add6
I1011 15:06:38.884093 38966 net.cpp:131] Top shape: 20 64 26 26 (865280)
I1011 15:06:38.884099 38966 net.cpp:139] Memory required for data: 5617974080
I1011 15:06:38.884106 38966 layer_factory.hpp:77] Creating layer conv31
I1011 15:06:38.884124 38966 net.cpp:86] Creating Layer conv31
I1011 15:06:38.884131 38966 net.cpp:408] conv31 <- add6
I1011 15:06:38.884142 38966 net.cpp:382] conv31 -> conv31
I1011 15:06:38.884582 38966 net.cpp:124] Setting up conv31
I1011 15:06:38.884594 38966 net.cpp:131] Top shape: 20 327 26 26 (4421040)
I1011 15:06:38.884603 38966 net.cpp:139] Memory required for data: 5635658240
I1011 15:06:38.884613 38966 layer_factory.hpp:77] Creating layer batch_norm31
I1011 15:06:38.884622 38966 net.cpp:86] Creating Layer batch_norm31
I1011 15:06:38.884629 38966 net.cpp:408] batch_norm31 <- conv31
I1011 15:06:38.884639 38966 net.cpp:369] batch_norm31 -> conv31 (in-place)
I1011 15:06:38.884842 38966 net.cpp:124] Setting up batch_norm31
I1011 15:06:38.884855 38966 net.cpp:131] Top shape: 20 327 26 26 (4421040)
I1011 15:06:38.884860 38966 net.cpp:139] Memory required for data: 5653342400
I1011 15:06:38.884873 38966 layer_factory.hpp:77] Creating layer bn_scale31
I1011 15:06:38.884893 38966 net.cpp:86] Creating Layer bn_scale31
I1011 15:06:38.884902 38966 net.cpp:408] bn_scale31 <- conv31
I1011 15:06:38.884912 38966 net.cpp:369] bn_scale31 -> conv31 (in-place)
I1011 15:06:38.884964 38966 layer_factory.hpp:77] Creating layer bn_scale31
I1011 15:06:38.885092 38966 net.cpp:124] Setting up bn_scale31
I1011 15:06:38.885103 38966 net.cpp:131] Top shape: 20 327 26 26 (4421040)
I1011 15:06:38.885110 38966 net.cpp:139] Memory required for data: 5671026560
I1011 15:06:38.885121 38966 layer_factory.hpp:77] Creating layer relu21
I1011 15:06:38.885141 38966 net.cpp:86] Creating Layer relu21
I1011 15:06:38.885149 38966 net.cpp:408] relu21 <- conv31
I1011 15:06:38.885162 38966 net.cpp:369] relu21 -> conv31 (in-place)
I1011 15:06:38.885174 38966 net.cpp:124] Setting up relu21
I1011 15:06:38.885186 38966 net.cpp:131] Top shape: 20 327 26 26 (4421040)
I1011 15:06:38.885196 38966 net.cpp:139] Memory required for data: 5688710720
I1011 15:06:38.885203 38966 layer_factory.hpp:77] Creating layer conv32
I1011 15:06:38.885223 38966 net.cpp:86] Creating Layer conv32
I1011 15:06:38.885231 38966 net.cpp:408] conv32 <- conv31
I1011 15:06:38.885242 38966 net.cpp:382] conv32 -> conv32
I1011 15:06:38.885468 38966 net.cpp:124] Setting up conv32
I1011 15:06:38.885481 38966 net.cpp:131] Top shape: 20 327 26 26 (4421040)
I1011 15:06:38.885488 38966 net.cpp:139] Memory required for data: 5706394880
I1011 15:06:38.885499 38966 layer_factory.hpp:77] Creating layer batch_norm32
I1011 15:06:38.885514 38966 net.cpp:86] Creating Layer batch_norm32
I1011 15:06:38.885522 38966 net.cpp:408] batch_norm32 <- conv32
I1011 15:06:38.885531 38966 net.cpp:369] batch_norm32 -> conv32 (in-place)
I1011 15:06:38.885731 38966 net.cpp:124] Setting up batch_norm32
I1011 15:06:38.885743 38966 net.cpp:131] Top shape: 20 327 26 26 (4421040)
I1011 15:06:38.885749 38966 net.cpp:139] Memory required for data: 5724079040
I1011 15:06:38.885782 38966 layer_factory.hpp:77] Creating layer bn_scale32
I1011 15:06:38.885799 38966 net.cpp:86] Creating Layer bn_scale32
I1011 15:06:38.885809 38966 net.cpp:408] bn_scale32 <- conv32
I1011 15:06:38.885819 38966 net.cpp:369] bn_scale32 -> conv32 (in-place)
I1011 15:06:38.885871 38966 layer_factory.hpp:77] Creating layer bn_scale32
I1011 15:06:38.886000 38966 net.cpp:124] Setting up bn_scale32
I1011 15:06:38.886013 38966 net.cpp:131] Top shape: 20 327 26 26 (4421040)
I1011 15:06:38.886018 38966 net.cpp:139] Memory required for data: 5741763200
I1011 15:06:38.886029 38966 layer_factory.hpp:77] Creating layer relu22
I1011 15:06:38.886042 38966 net.cpp:86] Creating Layer relu22
I1011 15:06:38.886050 38966 net.cpp:408] relu22 <- conv32
I1011 15:06:38.886059 38966 net.cpp:369] relu22 -> conv32 (in-place)
I1011 15:06:38.886072 38966 net.cpp:124] Setting up relu22
I1011 15:06:38.886082 38966 net.cpp:131] Top shape: 20 327 26 26 (4421040)
I1011 15:06:38.886088 38966 net.cpp:139] Memory required for data: 5759447360
I1011 15:06:38.886095 38966 layer_factory.hpp:77] Creating layer conv33
I1011 15:06:38.886107 38966 net.cpp:86] Creating Layer conv33
I1011 15:06:38.886113 38966 net.cpp:408] conv33 <- conv32
I1011 15:06:38.886132 38966 net.cpp:382] conv33 -> conv33
I1011 15:06:38.886660 38966 net.cpp:124] Setting up conv33
I1011 15:06:38.886674 38966 net.cpp:131] Top shape: 20 87 26 26 (1176240)
I1011 15:06:38.886680 38966 net.cpp:139] Memory required for data: 5764152320
I1011 15:06:38.886689 38966 layer_factory.hpp:77] Creating layer batch_norm33
I1011 15:06:38.886700 38966 net.cpp:86] Creating Layer batch_norm33
I1011 15:06:38.886708 38966 net.cpp:408] batch_norm33 <- conv33
I1011 15:06:38.886721 38966 net.cpp:369] batch_norm33 -> conv33 (in-place)
I1011 15:06:38.886926 38966 net.cpp:124] Setting up batch_norm33
I1011 15:06:38.886940 38966 net.cpp:131] Top shape: 20 87 26 26 (1176240)
I1011 15:06:38.886945 38966 net.cpp:139] Memory required for data: 5768857280
I1011 15:06:38.886958 38966 layer_factory.hpp:77] Creating layer bn_scale33
I1011 15:06:38.886970 38966 net.cpp:86] Creating Layer bn_scale33
I1011 15:06:38.886976 38966 net.cpp:408] bn_scale33 <- conv33
I1011 15:06:38.886989 38966 net.cpp:369] bn_scale33 -> conv33 (in-place)
I1011 15:06:38.887044 38966 layer_factory.hpp:77] Creating layer bn_scale33
I1011 15:06:38.887176 38966 net.cpp:124] Setting up bn_scale33
I1011 15:06:38.887197 38966 net.cpp:131] Top shape: 20 87 26 26 (1176240)
I1011 15:06:38.887207 38966 net.cpp:139] Memory required for data: 5773562240
I1011 15:06:38.887217 38966 layer_factory.hpp:77] Creating layer conv33_bn_scale33_0_split
I1011 15:06:38.887228 38966 net.cpp:86] Creating Layer conv33_bn_scale33_0_split
I1011 15:06:38.887234 38966 net.cpp:408] conv33_bn_scale33_0_split <- conv33
I1011 15:06:38.887244 38966 net.cpp:382] conv33_bn_scale33_0_split -> conv33_bn_scale33_0_split_0
I1011 15:06:38.887269 38966 net.cpp:382] conv33_bn_scale33_0_split -> conv33_bn_scale33_0_split_1
I1011 15:06:38.887320 38966 net.cpp:124] Setting up conv33_bn_scale33_0_split
I1011 15:06:38.887331 38966 net.cpp:131] Top shape: 20 87 26 26 (1176240)
I1011 15:06:38.887339 38966 net.cpp:131] Top shape: 20 87 26 26 (1176240)
I1011 15:06:38.887346 38966 net.cpp:139] Memory required for data: 5782972160
I1011 15:06:38.887354 38966 layer_factory.hpp:77] Creating layer conv34
I1011 15:06:38.887375 38966 net.cpp:86] Creating Layer conv34
I1011 15:06:38.887383 38966 net.cpp:408] conv34 <- conv33_bn_scale33_0_split_0
I1011 15:06:38.887396 38966 net.cpp:382] conv34 -> conv34
I1011 15:06:38.888058 38966 net.cpp:124] Setting up conv34
I1011 15:06:38.888072 38966 net.cpp:131] Top shape: 20 461 26 26 (6232720)
I1011 15:06:38.888078 38966 net.cpp:139] Memory required for data: 5807903040
I1011 15:06:38.888087 38966 layer_factory.hpp:77] Creating layer batch_norm34
I1011 15:06:38.888100 38966 net.cpp:86] Creating Layer batch_norm34
I1011 15:06:38.888110 38966 net.cpp:408] batch_norm34 <- conv34
I1011 15:06:38.888120 38966 net.cpp:369] batch_norm34 -> conv34 (in-place)
I1011 15:06:38.888342 38966 net.cpp:124] Setting up batch_norm34
I1011 15:06:38.888355 38966 net.cpp:131] Top shape: 20 461 26 26 (6232720)
I1011 15:06:38.888362 38966 net.cpp:139] Memory required for data: 5832833920
I1011 15:06:38.888375 38966 layer_factory.hpp:77] Creating layer bn_scale34
I1011 15:06:38.888391 38966 net.cpp:86] Creating Layer bn_scale34
I1011 15:06:38.888401 38966 net.cpp:408] bn_scale34 <- conv34
I1011 15:06:38.888411 38966 net.cpp:369] bn_scale34 -> conv34 (in-place)
I1011 15:06:38.888468 38966 layer_factory.hpp:77] Creating layer bn_scale34
I1011 15:06:38.888597 38966 net.cpp:124] Setting up bn_scale34
I1011 15:06:38.888610 38966 net.cpp:131] Top shape: 20 461 26 26 (6232720)
I1011 15:06:38.888617 38966 net.cpp:139] Memory required for data: 5857764800
I1011 15:06:38.888628 38966 layer_factory.hpp:77] Creating layer relu23
I1011 15:06:38.888641 38966 net.cpp:86] Creating Layer relu23
I1011 15:06:38.888650 38966 net.cpp:408] relu23 <- conv34
I1011 15:06:38.888660 38966 net.cpp:369] relu23 -> conv34 (in-place)
I1011 15:06:38.888674 38966 net.cpp:124] Setting up relu23
I1011 15:06:38.888685 38966 net.cpp:131] Top shape: 20 461 26 26 (6232720)
I1011 15:06:38.888692 38966 net.cpp:139] Memory required for data: 5882695680
I1011 15:06:38.888700 38966 layer_factory.hpp:77] Creating layer conv35
I1011 15:06:38.888715 38966 net.cpp:86] Creating Layer conv35
I1011 15:06:38.888723 38966 net.cpp:408] conv35 <- conv34
I1011 15:06:38.888738 38966 net.cpp:382] conv35 -> conv35
I1011 15:06:38.888978 38966 net.cpp:124] Setting up conv35
I1011 15:06:38.888991 38966 net.cpp:131] Top shape: 20 461 26 26 (6232720)
I1011 15:06:38.888998 38966 net.cpp:139] Memory required for data: 5907626560
I1011 15:06:38.889008 38966 layer_factory.hpp:77] Creating layer batch_norm35
I1011 15:06:38.889020 38966 net.cpp:86] Creating Layer batch_norm35
I1011 15:06:38.889029 38966 net.cpp:408] batch_norm35 <- conv35
I1011 15:06:38.889044 38966 net.cpp:369] batch_norm35 -> conv35 (in-place)
I1011 15:06:38.889246 38966 net.cpp:124] Setting up batch_norm35
I1011 15:06:38.889258 38966 net.cpp:131] Top shape: 20 461 26 26 (6232720)
I1011 15:06:38.889264 38966 net.cpp:139] Memory required for data: 5932557440
I1011 15:06:38.889277 38966 layer_factory.hpp:77] Creating layer bn_scale35
I1011 15:06:38.889288 38966 net.cpp:86] Creating Layer bn_scale35
I1011 15:06:38.889297 38966 net.cpp:408] bn_scale35 <- conv35
I1011 15:06:38.889307 38966 net.cpp:369] bn_scale35 -> conv35 (in-place)
I1011 15:06:38.889355 38966 layer_factory.hpp:77] Creating layer bn_scale35
I1011 15:06:38.889484 38966 net.cpp:124] Setting up bn_scale35
I1011 15:06:38.889497 38966 net.cpp:131] Top shape: 20 461 26 26 (6232720)
I1011 15:06:38.889503 38966 net.cpp:139] Memory required for data: 5957488320
I1011 15:06:38.889514 38966 layer_factory.hpp:77] Creating layer relu24
I1011 15:06:38.889528 38966 net.cpp:86] Creating Layer relu24
I1011 15:06:38.889536 38966 net.cpp:408] relu24 <- conv35
I1011 15:06:38.889546 38966 net.cpp:369] relu24 -> conv35 (in-place)
I1011 15:06:38.889556 38966 net.cpp:124] Setting up relu24
I1011 15:06:38.889567 38966 net.cpp:131] Top shape: 20 461 26 26 (6232720)
I1011 15:06:38.889575 38966 net.cpp:139] Memory required for data: 5982419200
I1011 15:06:38.889580 38966 layer_factory.hpp:77] Creating layer conv36
I1011 15:06:38.889597 38966 net.cpp:86] Creating Layer conv36
I1011 15:06:38.889605 38966 net.cpp:408] conv36 <- conv35
I1011 15:06:38.889621 38966 net.cpp:382] conv36 -> conv36
I1011 15:06:38.890280 38966 net.cpp:124] Setting up conv36
I1011 15:06:38.890293 38966 net.cpp:131] Top shape: 20 87 26 26 (1176240)
I1011 15:06:38.890300 38966 net.cpp:139] Memory required for data: 5987124160
I1011 15:06:38.890308 38966 layer_factory.hpp:77] Creating layer batch_norm36
I1011 15:06:38.890324 38966 net.cpp:86] Creating Layer batch_norm36
I1011 15:06:38.890334 38966 net.cpp:408] batch_norm36 <- conv36
I1011 15:06:38.890344 38966 net.cpp:369] batch_norm36 -> conv36 (in-place)
I1011 15:06:38.890549 38966 net.cpp:124] Setting up batch_norm36
I1011 15:06:38.890573 38966 net.cpp:131] Top shape: 20 87 26 26 (1176240)
I1011 15:06:38.890579 38966 net.cpp:139] Memory required for data: 5991829120
I1011 15:06:38.890594 38966 layer_factory.hpp:77] Creating layer bn_scale36
I1011 15:06:38.890610 38966 net.cpp:86] Creating Layer bn_scale36
I1011 15:06:38.890620 38966 net.cpp:408] bn_scale36 <- conv36
I1011 15:06:38.890630 38966 net.cpp:369] bn_scale36 -> conv36 (in-place)
I1011 15:06:38.890681 38966 layer_factory.hpp:77] Creating layer bn_scale36
I1011 15:06:38.890813 38966 net.cpp:124] Setting up bn_scale36
I1011 15:06:38.890825 38966 net.cpp:131] Top shape: 20 87 26 26 (1176240)
I1011 15:06:38.890831 38966 net.cpp:139] Memory required for data: 5996534080
I1011 15:06:38.890843 38966 layer_factory.hpp:77] Creating layer add7
I1011 15:06:38.890857 38966 net.cpp:86] Creating Layer add7
I1011 15:06:38.890866 38966 net.cpp:408] add7 <- conv33_bn_scale33_0_split_1
I1011 15:06:38.890875 38966 net.cpp:408] add7 <- conv36
I1011 15:06:38.890887 38966 net.cpp:382] add7 -> add7
I1011 15:06:38.890923 38966 net.cpp:124] Setting up add7
I1011 15:06:38.890935 38966 net.cpp:131] Top shape: 20 87 26 26 (1176240)
I1011 15:06:38.890941 38966 net.cpp:139] Memory required for data: 6001239040
I1011 15:06:38.890949 38966 layer_factory.hpp:77] Creating layer add7_add7_0_split
I1011 15:06:38.890959 38966 net.cpp:86] Creating Layer add7_add7_0_split
I1011 15:06:38.890966 38966 net.cpp:408] add7_add7_0_split <- add7
I1011 15:06:38.890985 38966 net.cpp:382] add7_add7_0_split -> add7_add7_0_split_0
I1011 15:06:38.891000 38966 net.cpp:382] add7_add7_0_split -> add7_add7_0_split_1
I1011 15:06:38.891047 38966 net.cpp:124] Setting up add7_add7_0_split
I1011 15:06:38.891058 38966 net.cpp:131] Top shape: 20 87 26 26 (1176240)
I1011 15:06:38.891067 38966 net.cpp:131] Top shape: 20 87 26 26 (1176240)
I1011 15:06:38.891072 38966 net.cpp:139] Memory required for data: 6010648960
I1011 15:06:38.891079 38966 layer_factory.hpp:77] Creating layer conv37
I1011 15:06:38.891094 38966 net.cpp:86] Creating Layer conv37
I1011 15:06:38.891103 38966 net.cpp:408] conv37 <- add7_add7_0_split_0
I1011 15:06:38.891116 38966 net.cpp:382] conv37 -> conv37
I1011 15:06:38.891779 38966 net.cpp:124] Setting up conv37
I1011 15:06:38.891794 38966 net.cpp:131] Top shape: 20 461 26 26 (6232720)
I1011 15:06:38.891800 38966 net.cpp:139] Memory required for data: 6035579840
I1011 15:06:38.891810 38966 layer_factory.hpp:77] Creating layer batch_norm37
I1011 15:06:38.891821 38966 net.cpp:86] Creating Layer batch_norm37
I1011 15:06:38.891830 38966 net.cpp:408] batch_norm37 <- conv37
I1011 15:06:38.891844 38966 net.cpp:369] batch_norm37 -> conv37 (in-place)
I1011 15:06:38.892055 38966 net.cpp:124] Setting up batch_norm37
I1011 15:06:38.892066 38966 net.cpp:131] Top shape: 20 461 26 26 (6232720)
I1011 15:06:38.892072 38966 net.cpp:139] Memory required for data: 6060510720
I1011 15:06:38.892086 38966 layer_factory.hpp:77] Creating layer bn_scale37
I1011 15:06:38.892105 38966 net.cpp:86] Creating Layer bn_scale37
I1011 15:06:38.892114 38966 net.cpp:408] bn_scale37 <- conv37
I1011 15:06:38.892124 38966 net.cpp:369] bn_scale37 -> conv37 (in-place)
I1011 15:06:38.892174 38966 layer_factory.hpp:77] Creating layer bn_scale37
I1011 15:06:38.892302 38966 net.cpp:124] Setting up bn_scale37
I1011 15:06:38.892314 38966 net.cpp:131] Top shape: 20 461 26 26 (6232720)
I1011 15:06:38.892320 38966 net.cpp:139] Memory required for data: 6085441600
I1011 15:06:38.892333 38966 layer_factory.hpp:77] Creating layer relu25
I1011 15:06:38.892343 38966 net.cpp:86] Creating Layer relu25
I1011 15:06:38.892352 38966 net.cpp:408] relu25 <- conv37
I1011 15:06:38.892366 38966 net.cpp:369] relu25 -> conv37 (in-place)
I1011 15:06:38.892379 38966 net.cpp:124] Setting up relu25
I1011 15:06:38.892390 38966 net.cpp:131] Top shape: 20 461 26 26 (6232720)
I1011 15:06:38.892397 38966 net.cpp:139] Memory required for data: 6110372480
I1011 15:06:38.892405 38966 layer_factory.hpp:77] Creating layer conv38
I1011 15:06:38.892419 38966 net.cpp:86] Creating Layer conv38
I1011 15:06:38.892441 38966 net.cpp:408] conv38 <- conv37
I1011 15:06:38.892454 38966 net.cpp:382] conv38 -> conv38
I1011 15:06:38.892716 38966 net.cpp:124] Setting up conv38
I1011 15:06:38.892730 38966 net.cpp:131] Top shape: 20 461 26 26 (6232720)
I1011 15:06:38.892737 38966 net.cpp:139] Memory required for data: 6135303360
I1011 15:06:38.892747 38966 layer_factory.hpp:77] Creating layer batch_norm38
I1011 15:06:38.892765 38966 net.cpp:86] Creating Layer batch_norm38
I1011 15:06:38.892774 38966 net.cpp:408] batch_norm38 <- conv38
I1011 15:06:38.892784 38966 net.cpp:369] batch_norm38 -> conv38 (in-place)
I1011 15:06:38.892993 38966 net.cpp:124] Setting up batch_norm38
I1011 15:06:38.893005 38966 net.cpp:131] Top shape: 20 461 26 26 (6232720)
I1011 15:06:38.893012 38966 net.cpp:139] Memory required for data: 6160234240
I1011 15:06:38.893025 38966 layer_factory.hpp:77] Creating layer bn_scale38
I1011 15:06:38.893038 38966 net.cpp:86] Creating Layer bn_scale38
I1011 15:06:38.893049 38966 net.cpp:408] bn_scale38 <- conv38
I1011 15:06:38.893064 38966 net.cpp:369] bn_scale38 -> conv38 (in-place)
I1011 15:06:38.893111 38966 layer_factory.hpp:77] Creating layer bn_scale38
I1011 15:06:38.893237 38966 net.cpp:124] Setting up bn_scale38
I1011 15:06:38.893252 38966 net.cpp:131] Top shape: 20 461 26 26 (6232720)
I1011 15:06:38.893260 38966 net.cpp:139] Memory required for data: 6185165120
I1011 15:06:38.893270 38966 layer_factory.hpp:77] Creating layer relu26
I1011 15:06:38.893283 38966 net.cpp:86] Creating Layer relu26
I1011 15:06:38.893293 38966 net.cpp:408] relu26 <- conv38
I1011 15:06:38.893303 38966 net.cpp:369] relu26 -> conv38 (in-place)
I1011 15:06:38.893317 38966 net.cpp:124] Setting up relu26
I1011 15:06:38.893327 38966 net.cpp:131] Top shape: 20 461 26 26 (6232720)
I1011 15:06:38.893334 38966 net.cpp:139] Memory required for data: 6210096000
I1011 15:06:38.893342 38966 layer_factory.hpp:77] Creating layer conv39
I1011 15:06:38.893358 38966 net.cpp:86] Creating Layer conv39
I1011 15:06:38.893366 38966 net.cpp:408] conv39 <- conv38
I1011 15:06:38.893383 38966 net.cpp:382] conv39 -> conv39
I1011 15:06:38.895222 38966 net.cpp:124] Setting up conv39
I1011 15:06:38.895239 38966 net.cpp:131] Top shape: 20 87 26 26 (1176240)
I1011 15:06:38.895254 38966 net.cpp:139] Memory required for data: 6214800960
I1011 15:06:38.895267 38966 layer_factory.hpp:77] Creating layer batch_norm39
I1011 15:06:38.895278 38966 net.cpp:86] Creating Layer batch_norm39
I1011 15:06:38.895288 38966 net.cpp:408] batch_norm39 <- conv39
I1011 15:06:38.895304 38966 net.cpp:369] batch_norm39 -> conv39 (in-place)
I1011 15:06:38.895524 38966 net.cpp:124] Setting up batch_norm39
I1011 15:06:38.895537 38966 net.cpp:131] Top shape: 20 87 26 26 (1176240)
I1011 15:06:38.895543 38966 net.cpp:139] Memory required for data: 6219505920
I1011 15:06:38.895557 38966 layer_factory.hpp:77] Creating layer bn_scale39
I1011 15:06:38.895571 38966 net.cpp:86] Creating Layer bn_scale39
I1011 15:06:38.895581 38966 net.cpp:408] bn_scale39 <- conv39
I1011 15:06:38.895591 38966 net.cpp:369] bn_scale39 -> conv39 (in-place)
I1011 15:06:38.895645 38966 layer_factory.hpp:77] Creating layer bn_scale39
I1011 15:06:38.895778 38966 net.cpp:124] Setting up bn_scale39
I1011 15:06:38.895792 38966 net.cpp:131] Top shape: 20 87 26 26 (1176240)
I1011 15:06:38.895797 38966 net.cpp:139] Memory required for data: 6224210880
I1011 15:06:38.895808 38966 layer_factory.hpp:77] Creating layer add8
I1011 15:06:38.895823 38966 net.cpp:86] Creating Layer add8
I1011 15:06:38.895833 38966 net.cpp:408] add8 <- add7_add7_0_split_1
I1011 15:06:38.895843 38966 net.cpp:408] add8 <- conv39
I1011 15:06:38.895853 38966 net.cpp:382] add8 -> add8
I1011 15:06:38.895890 38966 net.cpp:124] Setting up add8
I1011 15:06:38.895901 38966 net.cpp:131] Top shape: 20 87 26 26 (1176240)
I1011 15:06:38.895908 38966 net.cpp:139] Memory required for data: 6228915840
I1011 15:06:38.895915 38966 layer_factory.hpp:77] Creating layer conv40
I1011 15:06:38.895933 38966 net.cpp:86] Creating Layer conv40
I1011 15:06:38.895942 38966 net.cpp:408] conv40 <- add8
I1011 15:06:38.895968 38966 net.cpp:382] conv40 -> conv40
I1011 15:06:38.896761 38966 net.cpp:124] Setting up conv40
I1011 15:06:38.896775 38966 net.cpp:131] Top shape: 20 576 26 26 (7787520)
I1011 15:06:38.896782 38966 net.cpp:139] Memory required for data: 6260065920
I1011 15:06:38.896792 38966 layer_factory.hpp:77] Creating layer batch_norm40
I1011 15:06:38.896806 38966 net.cpp:86] Creating Layer batch_norm40
I1011 15:06:38.896814 38966 net.cpp:408] batch_norm40 <- conv40
I1011 15:06:38.896828 38966 net.cpp:369] batch_norm40 -> conv40 (in-place)
I1011 15:06:38.897034 38966 net.cpp:124] Setting up batch_norm40
I1011 15:06:38.897047 38966 net.cpp:131] Top shape: 20 576 26 26 (7787520)
I1011 15:06:38.897053 38966 net.cpp:139] Memory required for data: 6291216000
I1011 15:06:38.897066 38966 layer_factory.hpp:77] Creating layer bn_scale40
I1011 15:06:38.897079 38966 net.cpp:86] Creating Layer bn_scale40
I1011 15:06:38.897089 38966 net.cpp:408] bn_scale40 <- conv40
I1011 15:06:38.897099 38966 net.cpp:369] bn_scale40 -> conv40 (in-place)
I1011 15:06:38.897151 38966 layer_factory.hpp:77] Creating layer bn_scale40
I1011 15:06:38.897279 38966 net.cpp:124] Setting up bn_scale40
I1011 15:06:38.897291 38966 net.cpp:131] Top shape: 20 576 26 26 (7787520)
I1011 15:06:38.897298 38966 net.cpp:139] Memory required for data: 6322366080
I1011 15:06:38.897310 38966 layer_factory.hpp:77] Creating layer relu27
I1011 15:06:38.897320 38966 net.cpp:86] Creating Layer relu27
I1011 15:06:38.897330 38966 net.cpp:408] relu27 <- conv40
I1011 15:06:38.897342 38966 net.cpp:369] relu27 -> conv40 (in-place)
I1011 15:06:38.897356 38966 net.cpp:124] Setting up relu27
I1011 15:06:38.897364 38966 net.cpp:131] Top shape: 20 576 26 26 (7787520)
I1011 15:06:38.897372 38966 net.cpp:139] Memory required for data: 6353516160
I1011 15:06:38.897379 38966 layer_factory.hpp:77] Creating layer conv40_relu27_0_split
I1011 15:06:38.897389 38966 net.cpp:86] Creating Layer conv40_relu27_0_split
I1011 15:06:38.897395 38966 net.cpp:408] conv40_relu27_0_split <- conv40
I1011 15:06:38.897413 38966 net.cpp:382] conv40_relu27_0_split -> conv40_relu27_0_split_0
I1011 15:06:38.897428 38966 net.cpp:382] conv40_relu27_0_split -> conv40_relu27_0_split_1
I1011 15:06:38.897477 38966 net.cpp:124] Setting up conv40_relu27_0_split
I1011 15:06:38.897488 38966 net.cpp:131] Top shape: 20 576 26 26 (7787520)
I1011 15:06:38.897497 38966 net.cpp:131] Top shape: 20 576 26 26 (7787520)
I1011 15:06:38.897503 38966 net.cpp:139] Memory required for data: 6415816320
I1011 15:06:38.897511 38966 layer_factory.hpp:77] Creating layer conv41
I1011 15:06:38.897527 38966 net.cpp:86] Creating Layer conv41
I1011 15:06:38.897536 38966 net.cpp:408] conv41 <- conv40_relu27_0_split_0
I1011 15:06:38.897550 38966 net.cpp:382] conv41 -> conv41
I1011 15:06:38.897806 38966 net.cpp:124] Setting up conv41
I1011 15:06:38.897819 38966 net.cpp:131] Top shape: 20 576 13 13 (1946880)
I1011 15:06:38.897826 38966 net.cpp:139] Memory required for data: 6423603840
I1011 15:06:38.897835 38966 layer_factory.hpp:77] Creating layer batch_norm41
I1011 15:06:38.897846 38966 net.cpp:86] Creating Layer batch_norm41
I1011 15:06:38.897853 38966 net.cpp:408] batch_norm41 <- conv41
I1011 15:06:38.897862 38966 net.cpp:369] batch_norm41 -> conv41 (in-place)
I1011 15:06:38.898067 38966 net.cpp:124] Setting up batch_norm41
I1011 15:06:38.898079 38966 net.cpp:131] Top shape: 20 576 13 13 (1946880)
I1011 15:06:38.898085 38966 net.cpp:139] Memory required for data: 6431391360
I1011 15:06:38.898098 38966 layer_factory.hpp:77] Creating layer bn_scale41
I1011 15:06:38.898109 38966 net.cpp:86] Creating Layer bn_scale41
I1011 15:06:38.898118 38966 net.cpp:408] bn_scale41 <- conv41
I1011 15:06:38.898128 38966 net.cpp:369] bn_scale41 -> conv41 (in-place)
I1011 15:06:38.898180 38966 layer_factory.hpp:77] Creating layer bn_scale41
I1011 15:06:38.898309 38966 net.cpp:124] Setting up bn_scale41
I1011 15:06:38.898321 38966 net.cpp:131] Top shape: 20 576 13 13 (1946880)
I1011 15:06:38.898329 38966 net.cpp:139] Memory required for data: 6439178880
I1011 15:06:38.898355 38966 layer_factory.hpp:77] Creating layer relu28
I1011 15:06:38.898366 38966 net.cpp:86] Creating Layer relu28
I1011 15:06:38.898376 38966 net.cpp:408] relu28 <- conv41
I1011 15:06:38.898391 38966 net.cpp:369] relu28 -> conv41 (in-place)
I1011 15:06:38.898403 38966 net.cpp:124] Setting up relu28
I1011 15:06:38.898414 38966 net.cpp:131] Top shape: 20 576 13 13 (1946880)
I1011 15:06:38.898424 38966 net.cpp:139] Memory required for data: 6446966400
I1011 15:06:38.898432 38966 layer_factory.hpp:77] Creating layer conv42
I1011 15:06:38.898445 38966 net.cpp:86] Creating Layer conv42
I1011 15:06:38.898453 38966 net.cpp:408] conv42 <- conv41
I1011 15:06:38.898473 38966 net.cpp:382] conv42 -> conv42
I1011 15:06:38.899528 38966 net.cpp:124] Setting up conv42
I1011 15:06:38.899543 38966 net.cpp:131] Top shape: 20 128 13 13 (432640)
I1011 15:06:38.899549 38966 net.cpp:139] Memory required for data: 6448696960
I1011 15:06:38.899559 38966 layer_factory.hpp:77] Creating layer batch_norm42
I1011 15:06:38.899574 38966 net.cpp:86] Creating Layer batch_norm42
I1011 15:06:38.899582 38966 net.cpp:408] batch_norm42 <- conv42
I1011 15:06:38.899592 38966 net.cpp:369] batch_norm42 -> conv42 (in-place)
I1011 15:06:38.899785 38966 net.cpp:124] Setting up batch_norm42
I1011 15:06:38.899796 38966 net.cpp:131] Top shape: 20 128 13 13 (432640)
I1011 15:06:38.899803 38966 net.cpp:139] Memory required for data: 6450427520
I1011 15:06:38.899816 38966 layer_factory.hpp:77] Creating layer bn_scale42
I1011 15:06:38.899832 38966 net.cpp:86] Creating Layer bn_scale42
I1011 15:06:38.899842 38966 net.cpp:408] bn_scale42 <- conv42
I1011 15:06:38.899852 38966 net.cpp:369] bn_scale42 -> conv42 (in-place)
I1011 15:06:38.899904 38966 layer_factory.hpp:77] Creating layer bn_scale42
I1011 15:06:38.900022 38966 net.cpp:124] Setting up bn_scale42
I1011 15:06:38.900034 38966 net.cpp:131] Top shape: 20 128 13 13 (432640)
I1011 15:06:38.900040 38966 net.cpp:139] Memory required for data: 6452158080
I1011 15:06:38.900053 38966 layer_factory.hpp:77] Creating layer conv42_bn_scale42_0_split
I1011 15:06:38.900066 38966 net.cpp:86] Creating Layer conv42_bn_scale42_0_split
I1011 15:06:38.900074 38966 net.cpp:408] conv42_bn_scale42_0_split <- conv42
I1011 15:06:38.900090 38966 net.cpp:382] conv42_bn_scale42_0_split -> conv42_bn_scale42_0_split_0
I1011 15:06:38.900105 38966 net.cpp:382] conv42_bn_scale42_0_split -> conv42_bn_scale42_0_split_1
I1011 15:06:38.900156 38966 net.cpp:124] Setting up conv42_bn_scale42_0_split
I1011 15:06:38.900169 38966 net.cpp:131] Top shape: 20 128 13 13 (432640)
I1011 15:06:38.900178 38966 net.cpp:131] Top shape: 20 128 13 13 (432640)
I1011 15:06:38.900190 38966 net.cpp:139] Memory required for data: 6455619200
I1011 15:06:38.900197 38966 layer_factory.hpp:77] Creating layer conv43
I1011 15:06:38.900211 38966 net.cpp:86] Creating Layer conv43
I1011 15:06:38.900220 38966 net.cpp:408] conv43 <- conv42_bn_scale42_0_split_0
I1011 15:06:38.900236 38966 net.cpp:382] conv43 -> conv43
I1011 15:06:38.901556 38966 net.cpp:124] Setting up conv43
I1011 15:06:38.901569 38966 net.cpp:131] Top shape: 20 768 13 13 (2595840)
I1011 15:06:38.901576 38966 net.cpp:139] Memory required for data: 6466002560
I1011 15:06:38.901585 38966 layer_factory.hpp:77] Creating layer batch_norm43
I1011 15:06:38.901598 38966 net.cpp:86] Creating Layer batch_norm43
I1011 15:06:38.901608 38966 net.cpp:408] batch_norm43 <- conv43
I1011 15:06:38.901623 38966 net.cpp:369] batch_norm43 -> conv43 (in-place)
I1011 15:06:38.901816 38966 net.cpp:124] Setting up batch_norm43
I1011 15:06:38.901829 38966 net.cpp:131] Top shape: 20 768 13 13 (2595840)
I1011 15:06:38.901835 38966 net.cpp:139] Memory required for data: 6476385920
I1011 15:06:38.901849 38966 layer_factory.hpp:77] Creating layer bn_scale43
I1011 15:06:38.901863 38966 net.cpp:86] Creating Layer bn_scale43
I1011 15:06:38.901871 38966 net.cpp:408] bn_scale43 <- conv43
I1011 15:06:38.901881 38966 net.cpp:369] bn_scale43 -> conv43 (in-place)
I1011 15:06:38.901937 38966 layer_factory.hpp:77] Creating layer bn_scale43
I1011 15:06:38.902077 38966 net.cpp:124] Setting up bn_scale43
I1011 15:06:38.902091 38966 net.cpp:131] Top shape: 20 768 13 13 (2595840)
I1011 15:06:38.902097 38966 net.cpp:139] Memory required for data: 6486769280
I1011 15:06:38.902132 38966 layer_factory.hpp:77] Creating layer relu29
I1011 15:06:38.902143 38966 net.cpp:86] Creating Layer relu29
I1011 15:06:38.902150 38966 net.cpp:408] relu29 <- conv43
I1011 15:06:38.902160 38966 net.cpp:369] relu29 -> conv43 (in-place)
I1011 15:06:38.902173 38966 net.cpp:124] Setting up relu29
I1011 15:06:38.902184 38966 net.cpp:131] Top shape: 20 768 13 13 (2595840)
I1011 15:06:38.902191 38966 net.cpp:139] Memory required for data: 6497152640
I1011 15:06:38.902199 38966 layer_factory.hpp:77] Creating layer conv44
I1011 15:06:38.902210 38966 net.cpp:86] Creating Layer conv44
I1011 15:06:38.902218 38966 net.cpp:408] conv44 <- conv43
I1011 15:06:38.902230 38966 net.cpp:382] conv44 -> conv44
I1011 15:06:38.902503 38966 net.cpp:124] Setting up conv44
I1011 15:06:38.902516 38966 net.cpp:131] Top shape: 20 768 13 13 (2595840)
I1011 15:06:38.902523 38966 net.cpp:139] Memory required for data: 6507536000
I1011 15:06:38.902531 38966 layer_factory.hpp:77] Creating layer batch_norm44
I1011 15:06:38.902546 38966 net.cpp:86] Creating Layer batch_norm44
I1011 15:06:38.902555 38966 net.cpp:408] batch_norm44 <- conv44
I1011 15:06:38.902565 38966 net.cpp:369] batch_norm44 -> conv44 (in-place)
I1011 15:06:38.902752 38966 net.cpp:124] Setting up batch_norm44
I1011 15:06:38.902765 38966 net.cpp:131] Top shape: 20 768 13 13 (2595840)
I1011 15:06:38.902770 38966 net.cpp:139] Memory required for data: 6517919360
I1011 15:06:38.902784 38966 layer_factory.hpp:77] Creating layer bn_scale44
I1011 15:06:38.902797 38966 net.cpp:86] Creating Layer bn_scale44
I1011 15:06:38.902807 38966 net.cpp:408] bn_scale44 <- conv44
I1011 15:06:38.902822 38966 net.cpp:369] bn_scale44 -> conv44 (in-place)
I1011 15:06:38.902871 38966 layer_factory.hpp:77] Creating layer bn_scale44
I1011 15:06:38.902987 38966 net.cpp:124] Setting up bn_scale44
I1011 15:06:38.902999 38966 net.cpp:131] Top shape: 20 768 13 13 (2595840)
I1011 15:06:38.903007 38966 net.cpp:139] Memory required for data: 6528302720
I1011 15:06:38.903017 38966 layer_factory.hpp:77] Creating layer relu30
I1011 15:06:38.903030 38966 net.cpp:86] Creating Layer relu30
I1011 15:06:38.903039 38966 net.cpp:408] relu30 <- conv44
I1011 15:06:38.903049 38966 net.cpp:369] relu30 -> conv44 (in-place)
I1011 15:06:38.903060 38966 net.cpp:124] Setting up relu30
I1011 15:06:38.903070 38966 net.cpp:131] Top shape: 20 768 13 13 (2595840)
I1011 15:06:38.903077 38966 net.cpp:139] Memory required for data: 6538686080
I1011 15:06:38.903084 38966 layer_factory.hpp:77] Creating layer conv45
I1011 15:06:38.903103 38966 net.cpp:86] Creating Layer conv45
I1011 15:06:38.903111 38966 net.cpp:408] conv45 <- conv44
I1011 15:06:38.903126 38966 net.cpp:382] conv45 -> conv45
I1011 15:06:38.904453 38966 net.cpp:124] Setting up conv45
I1011 15:06:38.904467 38966 net.cpp:131] Top shape: 20 128 13 13 (432640)
I1011 15:06:38.904474 38966 net.cpp:139] Memory required for data: 6540416640
I1011 15:06:38.904482 38966 layer_factory.hpp:77] Creating layer batch_norm45
I1011 15:06:38.904497 38966 net.cpp:86] Creating Layer batch_norm45
I1011 15:06:38.904506 38966 net.cpp:408] batch_norm45 <- conv45
I1011 15:06:38.904516 38966 net.cpp:369] batch_norm45 -> conv45 (in-place)
I1011 15:06:38.904709 38966 net.cpp:124] Setting up batch_norm45
I1011 15:06:38.904721 38966 net.cpp:131] Top shape: 20 128 13 13 (432640)
I1011 15:06:38.904727 38966 net.cpp:139] Memory required for data: 6542147200
I1011 15:06:38.904742 38966 layer_factory.hpp:77] Creating layer bn_scale45
I1011 15:06:38.904755 38966 net.cpp:86] Creating Layer bn_scale45
I1011 15:06:38.904765 38966 net.cpp:408] bn_scale45 <- conv45
I1011 15:06:38.904774 38966 net.cpp:369] bn_scale45 -> conv45 (in-place)
I1011 15:06:38.904831 38966 layer_factory.hpp:77] Creating layer bn_scale45
I1011 15:06:38.904953 38966 net.cpp:124] Setting up bn_scale45
I1011 15:06:38.904964 38966 net.cpp:131] Top shape: 20 128 13 13 (432640)
I1011 15:06:38.904986 38966 net.cpp:139] Memory required for data: 6543877760
I1011 15:06:38.905000 38966 layer_factory.hpp:77] Creating layer add9
I1011 15:06:38.905014 38966 net.cpp:86] Creating Layer add9
I1011 15:06:38.905022 38966 net.cpp:408] add9 <- conv42_bn_scale42_0_split_1
I1011 15:06:38.905032 38966 net.cpp:408] add9 <- conv45
I1011 15:06:38.905047 38966 net.cpp:382] add9 -> add9
I1011 15:06:38.905083 38966 net.cpp:124] Setting up add9
I1011 15:06:38.905094 38966 net.cpp:131] Top shape: 20 128 13 13 (432640)
I1011 15:06:38.905100 38966 net.cpp:139] Memory required for data: 6545608320
I1011 15:06:38.905107 38966 layer_factory.hpp:77] Creating layer add9_add9_0_split
I1011 15:06:38.905123 38966 net.cpp:86] Creating Layer add9_add9_0_split
I1011 15:06:38.905133 38966 net.cpp:408] add9_add9_0_split <- add9
I1011 15:06:38.905148 38966 net.cpp:382] add9_add9_0_split -> add9_add9_0_split_0
I1011 15:06:38.905162 38966 net.cpp:382] add9_add9_0_split -> add9_add9_0_split_1
I1011 15:06:38.905211 38966 net.cpp:124] Setting up add9_add9_0_split
I1011 15:06:38.905222 38966 net.cpp:131] Top shape: 20 128 13 13 (432640)
I1011 15:06:38.905230 38966 net.cpp:131] Top shape: 20 128 13 13 (432640)
I1011 15:06:38.905236 38966 net.cpp:139] Memory required for data: 6549069440
I1011 15:06:38.905243 38966 layer_factory.hpp:77] Creating layer conv46
I1011 15:06:38.905258 38966 net.cpp:86] Creating Layer conv46
I1011 15:06:38.905267 38966 net.cpp:408] conv46 <- add9_add9_0_split_0
I1011 15:06:38.905283 38966 net.cpp:382] conv46 -> conv46
I1011 15:06:38.906597 38966 net.cpp:124] Setting up conv46
I1011 15:06:38.906611 38966 net.cpp:131] Top shape: 20 768 13 13 (2595840)
I1011 15:06:38.906617 38966 net.cpp:139] Memory required for data: 6559452800
I1011 15:06:38.906626 38966 layer_factory.hpp:77] Creating layer batch_norm46
I1011 15:06:38.906639 38966 net.cpp:86] Creating Layer batch_norm46
I1011 15:06:38.906649 38966 net.cpp:408] batch_norm46 <- conv46
I1011 15:06:38.906663 38966 net.cpp:369] batch_norm46 -> conv46 (in-place)
I1011 15:06:38.906853 38966 net.cpp:124] Setting up batch_norm46
I1011 15:06:38.906865 38966 net.cpp:131] Top shape: 20 768 13 13 (2595840)
I1011 15:06:38.906872 38966 net.cpp:139] Memory required for data: 6569836160
I1011 15:06:38.906885 38966 layer_factory.hpp:77] Creating layer bn_scale46
I1011 15:06:38.906903 38966 net.cpp:86] Creating Layer bn_scale46
I1011 15:06:38.906911 38966 net.cpp:408] bn_scale46 <- conv46
I1011 15:06:38.906921 38966 net.cpp:369] bn_scale46 -> conv46 (in-place)
I1011 15:06:38.906971 38966 layer_factory.hpp:77] Creating layer bn_scale46
I1011 15:06:38.907086 38966 net.cpp:124] Setting up bn_scale46
I1011 15:06:38.907107 38966 net.cpp:131] Top shape: 20 768 13 13 (2595840)
I1011 15:06:38.907114 38966 net.cpp:139] Memory required for data: 6580219520
I1011 15:06:38.907125 38966 layer_factory.hpp:77] Creating layer relu31
I1011 15:06:38.907135 38966 net.cpp:86] Creating Layer relu31
I1011 15:06:38.907145 38966 net.cpp:408] relu31 <- conv46
I1011 15:06:38.907158 38966 net.cpp:369] relu31 -> conv46 (in-place)
I1011 15:06:38.907171 38966 net.cpp:124] Setting up relu31
I1011 15:06:38.907181 38966 net.cpp:131] Top shape: 20 768 13 13 (2595840)
I1011 15:06:38.907188 38966 net.cpp:139] Memory required for data: 6590602880
I1011 15:06:38.907194 38966 layer_factory.hpp:77] Creating layer conv47
I1011 15:06:38.907210 38966 net.cpp:86] Creating Layer conv47
I1011 15:06:38.907218 38966 net.cpp:408] conv47 <- conv46
I1011 15:06:38.907230 38966 net.cpp:382] conv47 -> conv47
I1011 15:06:38.907510 38966 net.cpp:124] Setting up conv47
I1011 15:06:38.907524 38966 net.cpp:131] Top shape: 20 768 13 13 (2595840)
I1011 15:06:38.907531 38966 net.cpp:139] Memory required for data: 6600986240
I1011 15:06:38.907539 38966 layer_factory.hpp:77] Creating layer batch_norm47
I1011 15:06:38.907550 38966 net.cpp:86] Creating Layer batch_norm47
I1011 15:06:38.907559 38966 net.cpp:408] batch_norm47 <- conv47
I1011 15:06:38.907569 38966 net.cpp:369] batch_norm47 -> conv47 (in-place)
I1011 15:06:38.907776 38966 net.cpp:124] Setting up batch_norm47
I1011 15:06:38.907789 38966 net.cpp:131] Top shape: 20 768 13 13 (2595840)
I1011 15:06:38.907795 38966 net.cpp:139] Memory required for data: 6611369600
I1011 15:06:38.907810 38966 layer_factory.hpp:77] Creating layer bn_scale47
I1011 15:06:38.907829 38966 net.cpp:86] Creating Layer bn_scale47
I1011 15:06:38.907837 38966 net.cpp:408] bn_scale47 <- conv47
I1011 15:06:38.907847 38966 net.cpp:369] bn_scale47 -> conv47 (in-place)
I1011 15:06:38.907898 38966 layer_factory.hpp:77] Creating layer bn_scale47
I1011 15:06:38.908017 38966 net.cpp:124] Setting up bn_scale47
I1011 15:06:38.908033 38966 net.cpp:131] Top shape: 20 768 13 13 (2595840)
I1011 15:06:38.908041 38966 net.cpp:139] Memory required for data: 6621752960
I1011 15:06:38.908051 38966 layer_factory.hpp:77] Creating layer relu32
I1011 15:06:38.908062 38966 net.cpp:86] Creating Layer relu32
I1011 15:06:38.908071 38966 net.cpp:408] relu32 <- conv47
I1011 15:06:38.908080 38966 net.cpp:369] relu32 -> conv47 (in-place)
I1011 15:06:38.908092 38966 net.cpp:124] Setting up relu32
I1011 15:06:38.908103 38966 net.cpp:131] Top shape: 20 768 13 13 (2595840)
I1011 15:06:38.908110 38966 net.cpp:139] Memory required for data: 6632136320
I1011 15:06:38.908116 38966 layer_factory.hpp:77] Creating layer conv48
I1011 15:06:38.908133 38966 net.cpp:86] Creating Layer conv48
I1011 15:06:38.908143 38966 net.cpp:408] conv48 <- conv47
I1011 15:06:38.908159 38966 net.cpp:382] conv48 -> conv48
I1011 15:06:38.910616 38966 net.cpp:124] Setting up conv48
I1011 15:06:38.910634 38966 net.cpp:131] Top shape: 20 128 13 13 (432640)
I1011 15:06:38.910641 38966 net.cpp:139] Memory required for data: 6633866880
I1011 15:06:38.910651 38966 layer_factory.hpp:77] Creating layer batch_norm48
I1011 15:06:38.910663 38966 net.cpp:86] Creating Layer batch_norm48
I1011 15:06:38.910673 38966 net.cpp:408] batch_norm48 <- conv48
I1011 15:06:38.910688 38966 net.cpp:369] batch_norm48 -> conv48 (in-place)
I1011 15:06:38.910890 38966 net.cpp:124] Setting up batch_norm48
I1011 15:06:38.910902 38966 net.cpp:131] Top shape: 20 128 13 13 (432640)
I1011 15:06:38.910908 38966 net.cpp:139] Memory required for data: 6635597440
I1011 15:06:38.910923 38966 layer_factory.hpp:77] Creating layer bn_scale48
I1011 15:06:38.910941 38966 net.cpp:86] Creating Layer bn_scale48
I1011 15:06:38.910950 38966 net.cpp:408] bn_scale48 <- conv48
I1011 15:06:38.910960 38966 net.cpp:369] bn_scale48 -> conv48 (in-place)
I1011 15:06:38.911011 38966 layer_factory.hpp:77] Creating layer bn_scale48
I1011 15:06:38.911132 38966 net.cpp:124] Setting up bn_scale48
I1011 15:06:38.911144 38966 net.cpp:131] Top shape: 20 128 13 13 (432640)
I1011 15:06:38.911151 38966 net.cpp:139] Memory required for data: 6637328000
I1011 15:06:38.911162 38966 layer_factory.hpp:77] Creating layer add10
I1011 15:06:38.911177 38966 net.cpp:86] Creating Layer add10
I1011 15:06:38.911186 38966 net.cpp:408] add10 <- add9_add9_0_split_1
I1011 15:06:38.911195 38966 net.cpp:408] add10 <- conv48
I1011 15:06:38.911206 38966 net.cpp:382] add10 -> add10
I1011 15:06:38.911244 38966 net.cpp:124] Setting up add10
I1011 15:06:38.911267 38966 net.cpp:131] Top shape: 20 128 13 13 (432640)
I1011 15:06:38.911274 38966 net.cpp:139] Memory required for data: 6639058560
I1011 15:06:38.911281 38966 layer_factory.hpp:77] Creating layer conv49
I1011 15:06:38.911299 38966 net.cpp:86] Creating Layer conv49
I1011 15:06:38.911309 38966 net.cpp:408] conv49 <- add10
I1011 15:06:38.911321 38966 net.cpp:382] conv49 -> conv49
I1011 15:06:38.912644 38966 net.cpp:124] Setting up conv49
I1011 15:06:38.912657 38966 net.cpp:131] Top shape: 20 768 13 13 (2595840)
I1011 15:06:38.912664 38966 net.cpp:139] Memory required for data: 6649441920
I1011 15:06:38.912673 38966 layer_factory.hpp:77] Creating layer batch_norm49
I1011 15:06:38.912690 38966 net.cpp:86] Creating Layer batch_norm49
I1011 15:06:38.912700 38966 net.cpp:408] batch_norm49 <- conv49
I1011 15:06:38.912710 38966 net.cpp:369] batch_norm49 -> conv49 (in-place)
I1011 15:06:38.912909 38966 net.cpp:124] Setting up batch_norm49
I1011 15:06:38.912932 38966 net.cpp:131] Top shape: 20 768 13 13 (2595840)
I1011 15:06:38.912940 38966 net.cpp:139] Memory required for data: 6659825280
I1011 15:06:38.912955 38966 layer_factory.hpp:77] Creating layer bn_scale49
I1011 15:06:38.912967 38966 net.cpp:86] Creating Layer bn_scale49
I1011 15:06:38.912977 38966 net.cpp:408] bn_scale49 <- conv49
I1011 15:06:38.912987 38966 net.cpp:369] bn_scale49 -> conv49 (in-place)
I1011 15:06:38.913045 38966 layer_factory.hpp:77] Creating layer bn_scale49
I1011 15:06:38.913166 38966 net.cpp:124] Setting up bn_scale49
I1011 15:06:38.913179 38966 net.cpp:131] Top shape: 20 768 13 13 (2595840)
I1011 15:06:38.913185 38966 net.cpp:139] Memory required for data: 6670208640
I1011 15:06:38.913200 38966 layer_factory.hpp:77] Creating layer relu33
I1011 15:06:38.913214 38966 net.cpp:86] Creating Layer relu33
I1011 15:06:38.913223 38966 net.cpp:408] relu33 <- conv49
I1011 15:06:38.913236 38966 net.cpp:369] relu33 -> conv49 (in-place)
I1011 15:06:38.913249 38966 net.cpp:124] Setting up relu33
I1011 15:06:38.913259 38966 net.cpp:131] Top shape: 20 768 13 13 (2595840)
I1011 15:06:38.913266 38966 net.cpp:139] Memory required for data: 6680592000
I1011 15:06:38.913273 38966 layer_factory.hpp:77] Creating layer conv50
I1011 15:06:38.913285 38966 net.cpp:86] Creating Layer conv50
I1011 15:06:38.913293 38966 net.cpp:408] conv50 <- conv49
I1011 15:06:38.913308 38966 net.cpp:382] conv50 -> conv50
I1011 15:06:38.913581 38966 net.cpp:124] Setting up conv50
I1011 15:06:38.913594 38966 net.cpp:131] Top shape: 20 768 13 13 (2595840)
I1011 15:06:38.913600 38966 net.cpp:139] Memory required for data: 6690975360
I1011 15:06:38.913610 38966 layer_factory.hpp:77] Creating layer batch_norm50
I1011 15:06:38.913621 38966 net.cpp:86] Creating Layer batch_norm50
I1011 15:06:38.913630 38966 net.cpp:408] batch_norm50 <- conv50
I1011 15:06:38.913643 38966 net.cpp:369] batch_norm50 -> conv50 (in-place)
I1011 15:06:38.913831 38966 net.cpp:124] Setting up batch_norm50
I1011 15:06:38.913842 38966 net.cpp:131] Top shape: 20 768 13 13 (2595840)
I1011 15:06:38.913849 38966 net.cpp:139] Memory required for data: 6701358720
I1011 15:06:38.913862 38966 layer_factory.hpp:77] Creating layer bn_scale50
I1011 15:06:38.913882 38966 net.cpp:86] Creating Layer bn_scale50
I1011 15:06:38.913890 38966 net.cpp:408] bn_scale50 <- conv50
I1011 15:06:38.913900 38966 net.cpp:369] bn_scale50 -> conv50 (in-place)
I1011 15:06:38.913951 38966 layer_factory.hpp:77] Creating layer bn_scale50
I1011 15:06:38.914072 38966 net.cpp:124] Setting up bn_scale50
I1011 15:06:38.914083 38966 net.cpp:131] Top shape: 20 768 13 13 (2595840)
I1011 15:06:38.914089 38966 net.cpp:139] Memory required for data: 6711742080
I1011 15:06:38.914101 38966 layer_factory.hpp:77] Creating layer relu34
I1011 15:06:38.914110 38966 net.cpp:86] Creating Layer relu34
I1011 15:06:38.914121 38966 net.cpp:408] relu34 <- conv50
I1011 15:06:38.914134 38966 net.cpp:369] relu34 -> conv50 (in-place)
I1011 15:06:38.914147 38966 net.cpp:124] Setting up relu34
I1011 15:06:38.914158 38966 net.cpp:131] Top shape: 20 768 13 13 (2595840)
I1011 15:06:38.914166 38966 net.cpp:139] Memory required for data: 6722125440
I1011 15:06:38.914173 38966 layer_factory.hpp:77] Creating layer conv51
I1011 15:06:38.914186 38966 net.cpp:86] Creating Layer conv51
I1011 15:06:38.914198 38966 net.cpp:408] conv51 <- conv50
I1011 15:06:38.914212 38966 net.cpp:382] conv51 -> conv51
I1011 15:06:38.916383 38966 net.cpp:124] Setting up conv51
I1011 15:06:38.916397 38966 net.cpp:131] Top shape: 20 224 13 13 (757120)
I1011 15:06:38.916404 38966 net.cpp:139] Memory required for data: 6725153920
I1011 15:06:38.916414 38966 layer_factory.hpp:77] Creating layer batch_norm51
I1011 15:06:38.916424 38966 net.cpp:86] Creating Layer batch_norm51
I1011 15:06:38.916432 38966 net.cpp:408] batch_norm51 <- conv51
I1011 15:06:38.916442 38966 net.cpp:369] batch_norm51 -> conv51 (in-place)
I1011 15:06:38.916652 38966 net.cpp:124] Setting up batch_norm51
I1011 15:06:38.916667 38966 net.cpp:131] Top shape: 20 224 13 13 (757120)
I1011 15:06:38.916687 38966 net.cpp:139] Memory required for data: 6728182400
I1011 15:06:38.916707 38966 layer_factory.hpp:77] Creating layer bn_scale51
I1011 15:06:38.916723 38966 net.cpp:86] Creating Layer bn_scale51
I1011 15:06:38.916733 38966 net.cpp:408] bn_scale51 <- conv51
I1011 15:06:38.916743 38966 net.cpp:369] bn_scale51 -> conv51 (in-place)
I1011 15:06:38.916798 38966 layer_factory.hpp:77] Creating layer bn_scale51
I1011 15:06:38.916924 38966 net.cpp:124] Setting up bn_scale51
I1011 15:06:38.916936 38966 net.cpp:131] Top shape: 20 224 13 13 (757120)
I1011 15:06:38.916942 38966 net.cpp:139] Memory required for data: 6731210880
I1011 15:06:38.916954 38966 layer_factory.hpp:77] Creating layer conv52
I1011 15:06:38.916971 38966 net.cpp:86] Creating Layer conv52
I1011 15:06:38.916980 38966 net.cpp:408] conv52 <- conv51
I1011 15:06:38.916996 38966 net.cpp:382] conv52 -> conv52
I1011 15:06:38.919975 38966 net.cpp:124] Setting up conv52
I1011 15:06:38.919994 38966 net.cpp:131] Top shape: 20 640 13 13 (2163200)
I1011 15:06:38.920001 38966 net.cpp:139] Memory required for data: 6739863680
I1011 15:06:38.920011 38966 layer_factory.hpp:77] Creating layer batch_norm52
I1011 15:06:38.920023 38966 net.cpp:86] Creating Layer batch_norm52
I1011 15:06:38.920042 38966 net.cpp:408] batch_norm52 <- conv52
I1011 15:06:38.920055 38966 net.cpp:369] batch_norm52 -> conv52 (in-place)
I1011 15:06:38.920264 38966 net.cpp:124] Setting up batch_norm52
I1011 15:06:38.920276 38966 net.cpp:131] Top shape: 20 640 13 13 (2163200)
I1011 15:06:38.920282 38966 net.cpp:139] Memory required for data: 6748516480
I1011 15:06:38.920296 38966 layer_factory.hpp:77] Creating layer bn_scale52
I1011 15:06:38.920310 38966 net.cpp:86] Creating Layer bn_scale52
I1011 15:06:38.920320 38966 net.cpp:408] bn_scale52 <- conv52
I1011 15:06:38.920330 38966 net.cpp:369] bn_scale52 -> conv52 (in-place)
I1011 15:06:38.920384 38966 layer_factory.hpp:77] Creating layer bn_scale52
I1011 15:06:38.920501 38966 net.cpp:124] Setting up bn_scale52
I1011 15:06:38.920514 38966 net.cpp:131] Top shape: 20 640 13 13 (2163200)
I1011 15:06:38.920521 38966 net.cpp:139] Memory required for data: 6757169280
I1011 15:06:38.920532 38966 layer_factory.hpp:77] Creating layer relu35
I1011 15:06:38.920547 38966 net.cpp:86] Creating Layer relu35
I1011 15:06:38.920555 38966 net.cpp:408] relu35 <- conv52
I1011 15:06:38.920565 38966 net.cpp:369] relu35 -> conv52 (in-place)
I1011 15:06:38.920576 38966 net.cpp:124] Setting up relu35
I1011 15:06:38.920586 38966 net.cpp:131] Top shape: 20 640 13 13 (2163200)
I1011 15:06:38.920593 38966 net.cpp:139] Memory required for data: 6765822080
I1011 15:06:38.920600 38966 layer_factory.hpp:77] Creating layer yolo/conv1/dw
I1011 15:06:38.920616 38966 net.cpp:86] Creating Layer yolo/conv1/dw
I1011 15:06:38.920624 38966 net.cpp:408] yolo/conv1/dw <- conv52
I1011 15:06:38.920640 38966 net.cpp:382] yolo/conv1/dw -> yolo/conv1/dw
I1011 15:06:38.920907 38966 net.cpp:124] Setting up yolo/conv1/dw
I1011 15:06:38.920919 38966 net.cpp:131] Top shape: 20 640 13 13 (2163200)
I1011 15:06:38.920925 38966 net.cpp:139] Memory required for data: 6774474880
I1011 15:06:38.920934 38966 layer_factory.hpp:77] Creating layer yolo/conv1/dw/bn
I1011 15:06:38.920949 38966 net.cpp:86] Creating Layer yolo/conv1/dw/bn
I1011 15:06:38.920958 38966 net.cpp:408] yolo/conv1/dw/bn <- yolo/conv1/dw
I1011 15:06:38.920974 38966 net.cpp:369] yolo/conv1/dw/bn -> yolo/conv1/dw (in-place)
I1011 15:06:38.921170 38966 net.cpp:124] Setting up yolo/conv1/dw/bn
I1011 15:06:38.921182 38966 net.cpp:131] Top shape: 20 640 13 13 (2163200)
I1011 15:06:38.921188 38966 net.cpp:139] Memory required for data: 6783127680
I1011 15:06:38.921202 38966 layer_factory.hpp:77] Creating layer yolo/conv1/dw/scale
I1011 15:06:38.921221 38966 net.cpp:86] Creating Layer yolo/conv1/dw/scale
I1011 15:06:38.921231 38966 net.cpp:408] yolo/conv1/dw/scale <- yolo/conv1/dw
I1011 15:06:38.921241 38966 net.cpp:369] yolo/conv1/dw/scale -> yolo/conv1/dw (in-place)
I1011 15:06:38.921298 38966 layer_factory.hpp:77] Creating layer yolo/conv1/dw/scale
I1011 15:06:38.921434 38966 net.cpp:124] Setting up yolo/conv1/dw/scale
I1011 15:06:38.921447 38966 net.cpp:131] Top shape: 20 640 13 13 (2163200)
I1011 15:06:38.921454 38966 net.cpp:139] Memory required for data: 6791780480
I1011 15:06:38.921465 38966 layer_factory.hpp:77] Creating layer yolo/conv1/dw/relu
I1011 15:06:38.921476 38966 net.cpp:86] Creating Layer yolo/conv1/dw/relu
I1011 15:06:38.921485 38966 net.cpp:408] yolo/conv1/dw/relu <- yolo/conv1/dw
I1011 15:06:38.921500 38966 net.cpp:369] yolo/conv1/dw/relu -> yolo/conv1/dw (in-place)
I1011 15:06:38.921514 38966 net.cpp:124] Setting up yolo/conv1/dw/relu
I1011 15:06:38.921525 38966 net.cpp:131] Top shape: 20 640 13 13 (2163200)
I1011 15:06:38.921531 38966 net.cpp:139] Memory required for data: 6800433280
I1011 15:06:38.921538 38966 layer_factory.hpp:77] Creating layer yolo/conv1
I1011 15:06:38.921555 38966 net.cpp:86] Creating Layer yolo/conv1
I1011 15:06:38.921563 38966 net.cpp:408] yolo/conv1 <- yolo/conv1/dw
I1011 15:06:38.921574 38966 net.cpp:382] yolo/conv1 -> yolo/conv1
I1011 15:06:38.925976 38966 net.cpp:124] Setting up yolo/conv1
I1011 15:06:38.925992 38966 net.cpp:131] Top shape: 20 576 13 13 (1946880)
I1011 15:06:38.925998 38966 net.cpp:139] Memory required for data: 6808220800
I1011 15:06:38.926007 38966 layer_factory.hpp:77] Creating layer yolo/conv1/bn
I1011 15:06:38.926018 38966 net.cpp:86] Creating Layer yolo/conv1/bn
I1011 15:06:38.926028 38966 net.cpp:408] yolo/conv1/bn <- yolo/conv1
I1011 15:06:38.926038 38966 net.cpp:369] yolo/conv1/bn -> yolo/conv1 (in-place)
I1011 15:06:38.926250 38966 net.cpp:124] Setting up yolo/conv1/bn
I1011 15:06:38.926262 38966 net.cpp:131] Top shape: 20 576 13 13 (1946880)
I1011 15:06:38.926268 38966 net.cpp:139] Memory required for data: 6816008320
I1011 15:06:38.926282 38966 layer_factory.hpp:77] Creating layer yolo/conv1/scale
I1011 15:06:38.926301 38966 net.cpp:86] Creating Layer yolo/conv1/scale
I1011 15:06:38.926311 38966 net.cpp:408] yolo/conv1/scale <- yolo/conv1
I1011 15:06:38.926321 38966 net.cpp:369] yolo/conv1/scale -> yolo/conv1 (in-place)
I1011 15:06:38.926379 38966 layer_factory.hpp:77] Creating layer yolo/conv1/scale
I1011 15:06:38.926510 38966 net.cpp:124] Setting up yolo/conv1/scale
I1011 15:06:38.926522 38966 net.cpp:131] Top shape: 20 576 13 13 (1946880)
I1011 15:06:38.926529 38966 net.cpp:139] Memory required for data: 6823795840
I1011 15:06:38.926540 38966 layer_factory.hpp:77] Creating layer yolo/conv1/relu
I1011 15:06:38.926550 38966 net.cpp:86] Creating Layer yolo/conv1/relu
I1011 15:06:38.926558 38966 net.cpp:408] yolo/conv1/relu <- yolo/conv1
I1011 15:06:38.926570 38966 net.cpp:369] yolo/conv1/relu -> yolo/conv1 (in-place)
I1011 15:06:38.926582 38966 net.cpp:124] Setting up yolo/conv1/relu
I1011 15:06:38.926594 38966 net.cpp:131] Top shape: 20 576 13 13 (1946880)
I1011 15:06:38.926601 38966 net.cpp:139] Memory required for data: 6831583360
I1011 15:06:38.926609 38966 layer_factory.hpp:77] Creating layer yolo/conv1_yolo/conv1/relu_0_split
I1011 15:06:38.926618 38966 net.cpp:86] Creating Layer yolo/conv1_yolo/conv1/relu_0_split
I1011 15:06:38.926625 38966 net.cpp:408] yolo/conv1_yolo/conv1/relu_0_split <- yolo/conv1
I1011 15:06:38.926640 38966 net.cpp:382] yolo/conv1_yolo/conv1/relu_0_split -> yolo/conv1_yolo/conv1/relu_0_split_0
I1011 15:06:38.926653 38966 net.cpp:382] yolo/conv1_yolo/conv1/relu_0_split -> yolo/conv1_yolo/conv1/relu_0_split_1
I1011 15:06:38.926699 38966 net.cpp:124] Setting up yolo/conv1_yolo/conv1/relu_0_split
I1011 15:06:38.926710 38966 net.cpp:131] Top shape: 20 576 13 13 (1946880)
I1011 15:06:38.926718 38966 net.cpp:131] Top shape: 20 576 13 13 (1946880)
I1011 15:06:38.926724 38966 net.cpp:139] Memory required for data: 6847158400
I1011 15:06:38.926733 38966 layer_factory.hpp:77] Creating layer upsample
I1011 15:06:38.926751 38966 net.cpp:86] Creating Layer upsample
I1011 15:06:38.926759 38966 net.cpp:408] upsample <- yolo/conv1_yolo/conv1/relu_0_split_0
I1011 15:06:38.926772 38966 net.cpp:382] upsample -> upsample
I1011 15:06:38.926973 38966 net.cpp:124] Setting up upsample
I1011 15:06:38.926997 38966 net.cpp:131] Top shape: 20 576 25 25 (7200000)
I1011 15:06:38.927004 38966 net.cpp:139] Memory required for data: 6875958400
I1011 15:06:38.927014 38966 layer_factory.hpp:77] Creating layer maxpool
I1011 15:06:38.927026 38966 net.cpp:86] Creating Layer maxpool
I1011 15:06:38.927037 38966 net.cpp:408] maxpool <- upsample
I1011 15:06:38.927047 38966 net.cpp:382] maxpool -> maxpool
I1011 15:06:38.927119 38966 net.cpp:124] Setting up maxpool
I1011 15:06:38.927132 38966 net.cpp:131] Top shape: 20 576 26 26 (7787520)
I1011 15:06:38.927139 38966 net.cpp:139] Memory required for data: 6907108480
I1011 15:06:38.927145 38966 layer_factory.hpp:77] Creating layer yolo/conv2/dw
I1011 15:06:38.927163 38966 net.cpp:86] Creating Layer yolo/conv2/dw
I1011 15:06:38.927171 38966 net.cpp:408] yolo/conv2/dw <- conv40_relu27_0_split_1
I1011 15:06:38.927191 38966 net.cpp:382] yolo/conv2/dw -> yolo/conv2/dw
I1011 15:06:38.927458 38966 net.cpp:124] Setting up yolo/conv2/dw
I1011 15:06:38.927471 38966 net.cpp:131] Top shape: 20 576 26 26 (7787520)
I1011 15:06:38.927477 38966 net.cpp:139] Memory required for data: 6938258560
I1011 15:06:38.927486 38966 layer_factory.hpp:77] Creating layer yolo/conv2/dw/bn
I1011 15:06:38.927502 38966 net.cpp:86] Creating Layer yolo/conv2/dw/bn
I1011 15:06:38.927511 38966 net.cpp:408] yolo/conv2/dw/bn <- yolo/conv2/dw
I1011 15:06:38.927521 38966 net.cpp:369] yolo/conv2/dw/bn -> yolo/conv2/dw (in-place)
I1011 15:06:38.927736 38966 net.cpp:124] Setting up yolo/conv2/dw/bn
I1011 15:06:38.927748 38966 net.cpp:131] Top shape: 20 576 26 26 (7787520)
I1011 15:06:38.927754 38966 net.cpp:139] Memory required for data: 6969408640
I1011 15:06:38.927768 38966 layer_factory.hpp:77] Creating layer yolo/conv2/dw/scale
I1011 15:06:38.927784 38966 net.cpp:86] Creating Layer yolo/conv2/dw/scale
I1011 15:06:38.927793 38966 net.cpp:408] yolo/conv2/dw/scale <- yolo/conv2/dw
I1011 15:06:38.927803 38966 net.cpp:369] yolo/conv2/dw/scale -> yolo/conv2/dw (in-place)
I1011 15:06:38.927858 38966 layer_factory.hpp:77] Creating layer yolo/conv2/dw/scale
I1011 15:06:38.927992 38966 net.cpp:124] Setting up yolo/conv2/dw/scale
I1011 15:06:38.928005 38966 net.cpp:131] Top shape: 20 576 26 26 (7787520)
I1011 15:06:38.928011 38966 net.cpp:139] Memory required for data: 7000558720
I1011 15:06:38.928022 38966 layer_factory.hpp:77] Creating layer yolo/conv2/dw/relu
I1011 15:06:38.928036 38966 net.cpp:86] Creating Layer yolo/conv2/dw/relu
I1011 15:06:38.928045 38966 net.cpp:408] yolo/conv2/dw/relu <- yolo/conv2/dw
I1011 15:06:38.928056 38966 net.cpp:369] yolo/conv2/dw/relu -> yolo/conv2/dw (in-place)
I1011 15:06:38.928066 38966 net.cpp:124] Setting up yolo/conv2/dw/relu
I1011 15:06:38.928076 38966 net.cpp:131] Top shape: 20 576 26 26 (7787520)
I1011 15:06:38.928083 38966 net.cpp:139] Memory required for data: 7031708800
I1011 15:06:38.928090 38966 layer_factory.hpp:77] Creating layer yolo/conv2
I1011 15:06:38.928107 38966 net.cpp:86] Creating Layer yolo/conv2
I1011 15:06:38.928115 38966 net.cpp:408] yolo/conv2 <- yolo/conv2/dw
I1011 15:06:38.928129 38966 net.cpp:382] yolo/conv2 -> yolo/conv2
I1011 15:06:38.933270 38966 net.cpp:124] Setting up yolo/conv2
I1011 15:06:38.933290 38966 net.cpp:131] Top shape: 20 576 26 26 (7787520)
I1011 15:06:38.933296 38966 net.cpp:139] Memory required for data: 7062858880
I1011 15:06:38.933306 38966 layer_factory.hpp:77] Creating layer yolo/conv2/bn
I1011 15:06:38.933323 38966 net.cpp:86] Creating Layer yolo/conv2/bn
I1011 15:06:38.933333 38966 net.cpp:408] yolo/conv2/bn <- yolo/conv2
I1011 15:06:38.933343 38966 net.cpp:369] yolo/conv2/bn -> yolo/conv2 (in-place)
I1011 15:06:38.933557 38966 net.cpp:124] Setting up yolo/conv2/bn
I1011 15:06:38.933569 38966 net.cpp:131] Top shape: 20 576 26 26 (7787520)
I1011 15:06:38.933575 38966 net.cpp:139] Memory required for data: 7094008960
I1011 15:06:38.933588 38966 layer_factory.hpp:77] Creating layer yolo/conv2/scale
I1011 15:06:38.933610 38966 net.cpp:86] Creating Layer yolo/conv2/scale
I1011 15:06:38.933619 38966 net.cpp:408] yolo/conv2/scale <- yolo/conv2
I1011 15:06:38.933645 38966 net.cpp:369] yolo/conv2/scale -> yolo/conv2 (in-place)
I1011 15:06:38.933703 38966 layer_factory.hpp:77] Creating layer yolo/conv2/scale
I1011 15:06:38.933845 38966 net.cpp:124] Setting up yolo/conv2/scale
I1011 15:06:38.933856 38966 net.cpp:131] Top shape: 20 576 26 26 (7787520)
I1011 15:06:38.933863 38966 net.cpp:139] Memory required for data: 7125159040
I1011 15:06:38.933876 38966 layer_factory.hpp:77] Creating layer yolo/conv2/relu
I1011 15:06:38.933888 38966 net.cpp:86] Creating Layer yolo/conv2/relu
I1011 15:06:38.933897 38966 net.cpp:408] yolo/conv2/relu <- yolo/conv2
I1011 15:06:38.933908 38966 net.cpp:369] yolo/conv2/relu -> yolo/conv2 (in-place)
I1011 15:06:38.933919 38966 net.cpp:124] Setting up yolo/conv2/relu
I1011 15:06:38.933929 38966 net.cpp:131] Top shape: 20 576 26 26 (7787520)
I1011 15:06:38.933936 38966 net.cpp:139] Memory required for data: 7156309120
I1011 15:06:38.933943 38966 layer_factory.hpp:77] Creating layer yolo/conv2/sum
I1011 15:06:38.933956 38966 net.cpp:86] Creating Layer yolo/conv2/sum
I1011 15:06:38.933965 38966 net.cpp:408] yolo/conv2/sum <- maxpool
I1011 15:06:38.933974 38966 net.cpp:408] yolo/conv2/sum <- yolo/conv2
I1011 15:06:38.933984 38966 net.cpp:382] yolo/conv2/sum -> yolo/conv2/sum
I1011 15:06:38.934023 38966 net.cpp:124] Setting up yolo/conv2/sum
I1011 15:06:38.934034 38966 net.cpp:131] Top shape: 20 576 26 26 (7787520)
I1011 15:06:38.934041 38966 net.cpp:139] Memory required for data: 7187459200
I1011 15:06:38.934047 38966 layer_factory.hpp:77] Creating layer yolo/conv3/dw
I1011 15:06:38.934060 38966 net.cpp:86] Creating Layer yolo/conv3/dw
I1011 15:06:38.934068 38966 net.cpp:408] yolo/conv3/dw <- yolo/conv2/sum
I1011 15:06:38.934079 38966 net.cpp:382] yolo/conv3/dw -> yolo/conv3/dw
I1011 15:06:38.934340 38966 net.cpp:124] Setting up yolo/conv3/dw
I1011 15:06:38.934352 38966 net.cpp:131] Top shape: 20 576 26 26 (7787520)
I1011 15:06:38.934358 38966 net.cpp:139] Memory required for data: 7218609280
I1011 15:06:38.934367 38966 layer_factory.hpp:77] Creating layer yolo/conv3/dw/bn
I1011 15:06:38.934378 38966 net.cpp:86] Creating Layer yolo/conv3/dw/bn
I1011 15:06:38.934386 38966 net.cpp:408] yolo/conv3/dw/bn <- yolo/conv3/dw
I1011 15:06:38.934401 38966 net.cpp:369] yolo/conv3/dw/bn -> yolo/conv3/dw (in-place)
I1011 15:06:38.934608 38966 net.cpp:124] Setting up yolo/conv3/dw/bn
I1011 15:06:38.934620 38966 net.cpp:131] Top shape: 20 576 26 26 (7787520)
I1011 15:06:38.934628 38966 net.cpp:139] Memory required for data: 7249759360
I1011 15:06:38.934640 38966 layer_factory.hpp:77] Creating layer yolo/conv3/dw/scale
I1011 15:06:38.934653 38966 net.cpp:86] Creating Layer yolo/conv3/dw/scale
I1011 15:06:38.934661 38966 net.cpp:408] yolo/conv3/dw/scale <- yolo/conv3/dw
I1011 15:06:38.934676 38966 net.cpp:369] yolo/conv3/dw/scale -> yolo/conv3/dw (in-place)
I1011 15:06:38.934727 38966 layer_factory.hpp:77] Creating layer yolo/conv3/dw/scale
I1011 15:06:38.934860 38966 net.cpp:124] Setting up yolo/conv3/dw/scale
I1011 15:06:38.934873 38966 net.cpp:131] Top shape: 20 576 26 26 (7787520)
I1011 15:06:38.934880 38966 net.cpp:139] Memory required for data: 7280909440
I1011 15:06:38.934890 38966 layer_factory.hpp:77] Creating layer yolo/conv3/dw/relu
I1011 15:06:38.934901 38966 net.cpp:86] Creating Layer yolo/conv3/dw/relu
I1011 15:06:38.934911 38966 net.cpp:408] yolo/conv3/dw/relu <- yolo/conv3/dw
I1011 15:06:38.934921 38966 net.cpp:369] yolo/conv3/dw/relu -> yolo/conv3/dw (in-place)
I1011 15:06:38.934932 38966 net.cpp:124] Setting up yolo/conv3/dw/relu
I1011 15:06:38.934943 38966 net.cpp:131] Top shape: 20 576 26 26 (7787520)
I1011 15:06:38.934950 38966 net.cpp:139] Memory required for data: 7312059520
I1011 15:06:38.934957 38966 layer_factory.hpp:77] Creating layer yolo/conv3
I1011 15:06:38.934973 38966 net.cpp:86] Creating Layer yolo/conv3
I1011 15:06:38.934981 38966 net.cpp:408] yolo/conv3 <- yolo/conv3/dw
I1011 15:06:38.934998 38966 net.cpp:382] yolo/conv3 -> yolo/conv3
I1011 15:06:38.940713 38966 net.cpp:124] Setting up yolo/conv3
I1011 15:06:38.940744 38966 net.cpp:131] Top shape: 20 576 26 26 (7787520)
I1011 15:06:38.940752 38966 net.cpp:139] Memory required for data: 7343209600
I1011 15:06:38.940762 38966 layer_factory.hpp:77] Creating layer yolo/conv3/bn
I1011 15:06:38.940774 38966 net.cpp:86] Creating Layer yolo/conv3/bn
I1011 15:06:38.940783 38966 net.cpp:408] yolo/conv3/bn <- yolo/conv3
I1011 15:06:38.940796 38966 net.cpp:369] yolo/conv3/bn -> yolo/conv3 (in-place)
I1011 15:06:38.941040 38966 net.cpp:124] Setting up yolo/conv3/bn
I1011 15:06:38.941054 38966 net.cpp:131] Top shape: 20 576 26 26 (7787520)
I1011 15:06:38.941061 38966 net.cpp:139] Memory required for data: 7374359680
I1011 15:06:38.941076 38966 layer_factory.hpp:77] Creating layer yolo/conv3/scale
I1011 15:06:38.941089 38966 net.cpp:86] Creating Layer yolo/conv3/scale
I1011 15:06:38.941097 38966 net.cpp:408] yolo/conv3/scale <- yolo/conv3
I1011 15:06:38.941110 38966 net.cpp:369] yolo/conv3/scale -> yolo/conv3 (in-place)
I1011 15:06:38.941165 38966 layer_factory.hpp:77] Creating layer yolo/conv3/scale
I1011 15:06:38.941300 38966 net.cpp:124] Setting up yolo/conv3/scale
I1011 15:06:38.941313 38966 net.cpp:131] Top shape: 20 576 26 26 (7787520)
I1011 15:06:38.941319 38966 net.cpp:139] Memory required for data: 7405509760
I1011 15:06:38.941331 38966 layer_factory.hpp:77] Creating layer yolo/conv3/relu
I1011 15:06:38.941341 38966 net.cpp:86] Creating Layer yolo/conv3/relu
I1011 15:06:38.941352 38966 net.cpp:408] yolo/conv3/relu <- yolo/conv3
I1011 15:06:38.941363 38966 net.cpp:369] yolo/conv3/relu -> yolo/conv3 (in-place)
I1011 15:06:38.941376 38966 net.cpp:124] Setting up yolo/conv3/relu
I1011 15:06:38.941387 38966 net.cpp:131] Top shape: 20 576 26 26 (7787520)
I1011 15:06:38.941395 38966 net.cpp:139] Memory required for data: 7436659840
I1011 15:06:38.941401 38966 layer_factory.hpp:77] Creating layer yolo/conv4
I1011 15:06:38.941421 38966 net.cpp:86] Creating Layer yolo/conv4
I1011 15:06:38.941428 38966 net.cpp:408] yolo/conv4 <- yolo/conv1_yolo/conv1/relu_0_split_1
I1011 15:06:38.941445 38966 net.cpp:382] yolo/conv4 -> yolo/conv4
I1011 15:06:38.941812 38966 net.cpp:124] Setting up yolo/conv4
I1011 15:06:38.941826 38966 net.cpp:131] Top shape: 20 18 13 13 (60840)
I1011 15:06:38.941833 38966 net.cpp:139] Memory required for data: 7436903200
I1011 15:06:38.941843 38966 layer_factory.hpp:77] Creating layer yolo/conv5
I1011 15:06:38.941865 38966 net.cpp:86] Creating Layer yolo/conv5
I1011 15:06:38.941874 38966 net.cpp:408] yolo/conv5 <- yolo/conv3
I1011 15:06:38.941890 38966 net.cpp:382] yolo/conv5 -> yolo/conv5
I1011 15:06:38.942324 38966 net.cpp:124] Setting up yolo/conv5
I1011 15:06:38.942350 38966 net.cpp:131] Top shape: 20 18 26 26 (243360)
I1011 15:06:38.942359 38966 net.cpp:139] Memory required for data: 7437876640
I1011 15:06:38.942373 38966 layer_factory.hpp:77] Creating layer Yolov3Loss1
I1011 15:06:38.942390 38966 net.cpp:86] Creating Layer Yolov3Loss1
I1011 15:06:38.942399 38966 net.cpp:408] Yolov3Loss1 <- yolo/conv4
I1011 15:06:38.942409 38966 net.cpp:408] Yolov3Loss1 <- label_data_1_split_0
I1011 15:06:38.942431 38966 net.cpp:382] Yolov3Loss1 -> det_loss1
I1011 15:06:38.942555 38966 net.cpp:124] Setting up Yolov3Loss1
I1011 15:06:38.942572 38966 net.cpp:131] Top shape: (1)
I1011 15:06:38.942580 38966 net.cpp:134]     with loss weight 1
I1011 15:06:38.942629 38966 net.cpp:139] Memory required for data: 7437876644
I1011 15:06:38.942638 38966 layer_factory.hpp:77] Creating layer Yolov3Loss2
I1011 15:06:38.942651 38966 net.cpp:86] Creating Layer Yolov3Loss2
I1011 15:06:38.942661 38966 net.cpp:408] Yolov3Loss2 <- yolo/conv5
I1011 15:06:38.942670 38966 net.cpp:408] Yolov3Loss2 <- label_data_1_split_1
I1011 15:06:38.942687 38966 net.cpp:382] Yolov3Loss2 -> det_loss2
I1011 15:06:38.942791 38966 net.cpp:124] Setting up Yolov3Loss2
I1011 15:06:38.942804 38966 net.cpp:131] Top shape: (1)
I1011 15:06:38.942811 38966 net.cpp:134]     with loss weight 1
I1011 15:06:38.942822 38966 net.cpp:139] Memory required for data: 7437876648
I1011 15:06:38.942831 38966 net.cpp:200] Yolov3Loss2 needs backward computation.
I1011 15:06:38.942868 38966 net.cpp:200] Yolov3Loss1 needs backward computation.
I1011 15:06:38.942878 38966 net.cpp:200] yolo/conv5 needs backward computation.
I1011 15:06:38.942888 38966 net.cpp:200] yolo/conv4 needs backward computation.
I1011 15:06:38.942895 38966 net.cpp:200] yolo/conv3/relu needs backward computation.
I1011 15:06:38.942903 38966 net.cpp:200] yolo/conv3/scale needs backward computation.
I1011 15:06:38.942910 38966 net.cpp:200] yolo/conv3/bn needs backward computation.
I1011 15:06:38.942919 38966 net.cpp:200] yolo/conv3 needs backward computation.
I1011 15:06:38.942926 38966 net.cpp:200] yolo/conv3/dw/relu needs backward computation.
I1011 15:06:38.942934 38966 net.cpp:200] yolo/conv3/dw/scale needs backward computation.
I1011 15:06:38.942941 38966 net.cpp:200] yolo/conv3/dw/bn needs backward computation.
I1011 15:06:38.942948 38966 net.cpp:200] yolo/conv3/dw needs backward computation.
I1011 15:06:38.942957 38966 net.cpp:200] yolo/conv2/sum needs backward computation.
I1011 15:06:38.942970 38966 net.cpp:200] yolo/conv2/relu needs backward computation.
I1011 15:06:38.942978 38966 net.cpp:200] yolo/conv2/scale needs backward computation.
I1011 15:06:38.942986 38966 net.cpp:200] yolo/conv2/bn needs backward computation.
I1011 15:06:38.942993 38966 net.cpp:200] yolo/conv2 needs backward computation.
I1011 15:06:38.943002 38966 net.cpp:200] yolo/conv2/dw/relu needs backward computation.
I1011 15:06:38.943011 38966 net.cpp:200] yolo/conv2/dw/scale needs backward computation.
I1011 15:06:38.943018 38966 net.cpp:200] yolo/conv2/dw/bn needs backward computation.
I1011 15:06:38.943025 38966 net.cpp:200] yolo/conv2/dw needs backward computation.
I1011 15:06:38.943033 38966 net.cpp:200] maxpool needs backward computation.
I1011 15:06:38.943042 38966 net.cpp:200] upsample needs backward computation.
I1011 15:06:38.943050 38966 net.cpp:200] yolo/conv1_yolo/conv1/relu_0_split needs backward computation.
I1011 15:06:38.943059 38966 net.cpp:200] yolo/conv1/relu needs backward computation.
I1011 15:06:38.943066 38966 net.cpp:200] yolo/conv1/scale needs backward computation.
I1011 15:06:38.943074 38966 net.cpp:200] yolo/conv1/bn needs backward computation.
I1011 15:06:38.943083 38966 net.cpp:200] yolo/conv1 needs backward computation.
I1011 15:06:38.943089 38966 net.cpp:200] yolo/conv1/dw/relu needs backward computation.
I1011 15:06:38.943097 38966 net.cpp:200] yolo/conv1/dw/scale needs backward computation.
I1011 15:06:38.943105 38966 net.cpp:200] yolo/conv1/dw/bn needs backward computation.
I1011 15:06:38.943114 38966 net.cpp:200] yolo/conv1/dw needs backward computation.
I1011 15:06:38.943122 38966 net.cpp:200] relu35 needs backward computation.
I1011 15:06:38.943130 38966 net.cpp:200] bn_scale52 needs backward computation.
I1011 15:06:38.943138 38966 net.cpp:200] batch_norm52 needs backward computation.
I1011 15:06:38.943146 38966 net.cpp:200] conv52 needs backward computation.
I1011 15:06:38.943154 38966 net.cpp:200] bn_scale51 needs backward computation.
I1011 15:06:38.943162 38966 net.cpp:200] batch_norm51 needs backward computation.
I1011 15:06:38.943171 38966 net.cpp:200] conv51 needs backward computation.
I1011 15:06:38.943178 38966 net.cpp:200] relu34 needs backward computation.
I1011 15:06:38.943186 38966 net.cpp:200] bn_scale50 needs backward computation.
I1011 15:06:38.943193 38966 net.cpp:200] batch_norm50 needs backward computation.
I1011 15:06:38.943202 38966 net.cpp:200] conv50 needs backward computation.
I1011 15:06:38.943209 38966 net.cpp:200] relu33 needs backward computation.
I1011 15:06:38.943217 38966 net.cpp:200] bn_scale49 needs backward computation.
I1011 15:06:38.943224 38966 net.cpp:200] batch_norm49 needs backward computation.
I1011 15:06:38.943231 38966 net.cpp:200] conv49 needs backward computation.
I1011 15:06:38.943238 38966 net.cpp:200] add10 needs backward computation.
I1011 15:06:38.943243 38966 net.cpp:200] bn_scale48 needs backward computation.
I1011 15:06:38.943346 38966 net.cpp:200] batch_norm48 needs backward computation.
I1011 15:06:38.943369 38966 net.cpp:200] conv48 needs backward computation.
I1011 15:06:38.943377 38966 net.cpp:200] relu32 needs backward computation.
I1011 15:06:38.943384 38966 net.cpp:200] bn_scale47 needs backward computation.
I1011 15:06:38.943390 38966 net.cpp:200] batch_norm47 needs backward computation.
I1011 15:06:38.943397 38966 net.cpp:200] conv47 needs backward computation.
I1011 15:06:38.943404 38966 net.cpp:200] relu31 needs backward computation.
I1011 15:06:38.943410 38966 net.cpp:200] bn_scale46 needs backward computation.
I1011 15:06:38.943418 38966 net.cpp:200] batch_norm46 needs backward computation.
I1011 15:06:38.943424 38966 net.cpp:200] conv46 needs backward computation.
I1011 15:06:38.943431 38966 net.cpp:200] add9_add9_0_split needs backward computation.
I1011 15:06:38.943439 38966 net.cpp:200] add9 needs backward computation.
I1011 15:06:38.943446 38966 net.cpp:200] bn_scale45 needs backward computation.
I1011 15:06:38.943454 38966 net.cpp:200] batch_norm45 needs backward computation.
I1011 15:06:38.943460 38966 net.cpp:200] conv45 needs backward computation.
I1011 15:06:38.943467 38966 net.cpp:200] relu30 needs backward computation.
I1011 15:06:38.943475 38966 net.cpp:200] bn_scale44 needs backward computation.
I1011 15:06:38.943480 38966 net.cpp:200] batch_norm44 needs backward computation.
I1011 15:06:38.943486 38966 net.cpp:200] conv44 needs backward computation.
I1011 15:06:38.943495 38966 net.cpp:200] relu29 needs backward computation.
I1011 15:06:38.943501 38966 net.cpp:200] bn_scale43 needs backward computation.
I1011 15:06:38.943507 38966 net.cpp:200] batch_norm43 needs backward computation.
I1011 15:06:38.943514 38966 net.cpp:200] conv43 needs backward computation.
I1011 15:06:38.943522 38966 net.cpp:200] conv42_bn_scale42_0_split needs backward computation.
I1011 15:06:38.943528 38966 net.cpp:200] bn_scale42 needs backward computation.
I1011 15:06:38.943536 38966 net.cpp:200] batch_norm42 needs backward computation.
I1011 15:06:38.943542 38966 net.cpp:200] conv42 needs backward computation.
I1011 15:06:38.943552 38966 net.cpp:200] relu28 needs backward computation.
I1011 15:06:38.943564 38966 net.cpp:200] bn_scale41 needs backward computation.
I1011 15:06:38.943570 38966 net.cpp:200] batch_norm41 needs backward computation.
I1011 15:06:38.943578 38966 net.cpp:200] conv41 needs backward computation.
I1011 15:06:38.943585 38966 net.cpp:200] conv40_relu27_0_split needs backward computation.
I1011 15:06:38.943593 38966 net.cpp:200] relu27 needs backward computation.
I1011 15:06:38.943599 38966 net.cpp:200] bn_scale40 needs backward computation.
I1011 15:06:38.943605 38966 net.cpp:200] batch_norm40 needs backward computation.
I1011 15:06:38.943614 38966 net.cpp:200] conv40 needs backward computation.
I1011 15:06:38.943619 38966 net.cpp:200] add8 needs backward computation.
I1011 15:06:38.943627 38966 net.cpp:200] bn_scale39 needs backward computation.
I1011 15:06:38.943634 38966 net.cpp:200] batch_norm39 needs backward computation.
I1011 15:06:38.943641 38966 net.cpp:200] conv39 needs backward computation.
I1011 15:06:38.943647 38966 net.cpp:200] relu26 needs backward computation.
I1011 15:06:38.943655 38966 net.cpp:200] bn_scale38 needs backward computation.
I1011 15:06:38.943661 38966 net.cpp:200] batch_norm38 needs backward computation.
I1011 15:06:38.943667 38966 net.cpp:200] conv38 needs backward computation.
I1011 15:06:38.943675 38966 net.cpp:200] relu25 needs backward computation.
I1011 15:06:38.943681 38966 net.cpp:200] bn_scale37 needs backward computation.
I1011 15:06:38.943688 38966 net.cpp:200] batch_norm37 needs backward computation.
I1011 15:06:38.943694 38966 net.cpp:200] conv37 needs backward computation.
I1011 15:06:38.943701 38966 net.cpp:200] add7_add7_0_split needs backward computation.
I1011 15:06:38.943708 38966 net.cpp:200] add7 needs backward computation.
I1011 15:06:38.943717 38966 net.cpp:200] bn_scale36 needs backward computation.
I1011 15:06:38.943724 38966 net.cpp:200] batch_norm36 needs backward computation.
I1011 15:06:38.943730 38966 net.cpp:200] conv36 needs backward computation.
I1011 15:06:38.943749 38966 net.cpp:200] relu24 needs backward computation.
I1011 15:06:38.943758 38966 net.cpp:200] bn_scale35 needs backward computation.
I1011 15:06:38.943763 38966 net.cpp:200] batch_norm35 needs backward computation.
I1011 15:06:38.943770 38966 net.cpp:200] conv35 needs backward computation.
I1011 15:06:38.943778 38966 net.cpp:200] relu23 needs backward computation.
I1011 15:06:38.943784 38966 net.cpp:200] bn_scale34 needs backward computation.
I1011 15:06:38.943790 38966 net.cpp:200] batch_norm34 needs backward computation.
I1011 15:06:38.943796 38966 net.cpp:200] conv34 needs backward computation.
I1011 15:06:38.943804 38966 net.cpp:200] conv33_bn_scale33_0_split needs backward computation.
I1011 15:06:38.943811 38966 net.cpp:200] bn_scale33 needs backward computation.
I1011 15:06:38.943817 38966 net.cpp:200] batch_norm33 needs backward computation.
I1011 15:06:38.943825 38966 net.cpp:200] conv33 needs backward computation.
I1011 15:06:38.943831 38966 net.cpp:200] relu22 needs backward computation.
I1011 15:06:38.943837 38966 net.cpp:200] bn_scale32 needs backward computation.
I1011 15:06:38.943845 38966 net.cpp:200] batch_norm32 needs backward computation.
I1011 15:06:38.943850 38966 net.cpp:200] conv32 needs backward computation.
I1011 15:06:38.943857 38966 net.cpp:200] relu21 needs backward computation.
I1011 15:06:38.943864 38966 net.cpp:200] bn_scale31 needs backward computation.
I1011 15:06:38.943871 38966 net.cpp:200] batch_norm31 needs backward computation.
I1011 15:06:38.943877 38966 net.cpp:200] conv31 needs backward computation.
I1011 15:06:38.943884 38966 net.cpp:200] add6 needs backward computation.
I1011 15:06:38.943897 38966 net.cpp:200] bn_scale30 needs backward computation.
I1011 15:06:38.943912 38966 net.cpp:200] batch_norm30 needs backward computation.
I1011 15:06:38.943919 38966 net.cpp:200] conv30 needs backward computation.
I1011 15:06:38.943928 38966 net.cpp:200] relu20 needs backward computation.
I1011 15:06:38.943936 38966 net.cpp:200] bn_scale29 needs backward computation.
I1011 15:06:38.943944 38966 net.cpp:200] batch_norm29 needs backward computation.
I1011 15:06:38.943951 38966 net.cpp:200] conv29 needs backward computation.
I1011 15:06:38.943959 38966 net.cpp:200] relu19 needs backward computation.
I1011 15:06:38.943969 38966 net.cpp:200] bn_scale28 needs backward computation.
I1011 15:06:38.943975 38966 net.cpp:200] batch_norm28 needs backward computation.
I1011 15:06:38.943984 38966 net.cpp:200] conv28 needs backward computation.
I1011 15:06:38.943991 38966 net.cpp:200] add5_add5_0_split needs backward computation.
I1011 15:06:38.944000 38966 net.cpp:200] add5 needs backward computation.
I1011 15:06:38.944010 38966 net.cpp:200] bn_scale27 needs backward computation.
I1011 15:06:38.944016 38966 net.cpp:200] batch_norm27 needs backward computation.
I1011 15:06:38.944025 38966 net.cpp:200] conv27 needs backward computation.
I1011 15:06:38.944032 38966 net.cpp:200] relu18 needs backward computation.
I1011 15:06:38.944039 38966 net.cpp:200] bn_scale26 needs backward computation.
I1011 15:06:38.944047 38966 net.cpp:200] batch_norm26 needs backward computation.
I1011 15:06:38.944054 38966 net.cpp:200] conv26 needs backward computation.
I1011 15:06:38.944062 38966 net.cpp:200] relu17 needs backward computation.
I1011 15:06:38.944070 38966 net.cpp:200] bn_scale25 needs backward computation.
I1011 15:06:38.944078 38966 net.cpp:200] batch_norm25 needs backward computation.
I1011 15:06:38.944087 38966 net.cpp:200] conv25 needs backward computation.
I1011 15:06:38.944094 38966 net.cpp:200] add4_add4_0_split needs backward computation.
I1011 15:06:38.944103 38966 net.cpp:200] add4 needs backward computation.
I1011 15:06:38.944111 38966 net.cpp:200] bn_scale24 needs backward computation.
I1011 15:06:38.944119 38966 net.cpp:200] batch_norm24 needs backward computation.
I1011 15:06:38.944128 38966 net.cpp:200] conv24 needs backward computation.
I1011 15:06:38.944135 38966 net.cpp:200] relu16 needs backward computation.
I1011 15:06:38.944144 38966 net.cpp:200] bn_scale23 needs backward computation.
I1011 15:06:38.944166 38966 net.cpp:200] batch_norm23 needs backward computation.
I1011 15:06:38.944175 38966 net.cpp:200] conv23 needs backward computation.
I1011 15:06:38.944182 38966 net.cpp:200] relu15 needs backward computation.
I1011 15:06:38.944190 38966 net.cpp:200] bn_scale22 needs backward computation.
I1011 15:06:38.944197 38966 net.cpp:200] batch_norm22 needs backward computation.
I1011 15:06:38.944205 38966 net.cpp:200] conv22 needs backward computation.
I1011 15:06:38.944213 38966 net.cpp:200] conv21_bn_scale21_0_split needs backward computation.
I1011 15:06:38.944221 38966 net.cpp:200] bn_scale21 needs backward computation.
I1011 15:06:38.944229 38966 net.cpp:200] batch_norm21 needs backward computation.
I1011 15:06:38.944237 38966 net.cpp:200] conv21 needs backward computation.
I1011 15:06:38.944245 38966 net.cpp:200] relu14 needs backward computation.
I1011 15:06:38.944253 38966 net.cpp:200] bn_scale20 needs backward computation.
I1011 15:06:38.944260 38966 net.cpp:200] batch_norm20 needs backward computation.
I1011 15:06:38.944268 38966 net.cpp:200] conv20 needs backward computation.
I1011 15:06:38.944277 38966 net.cpp:200] relu13 needs backward computation.
I1011 15:06:38.944284 38966 net.cpp:200] bn_scale19 needs backward computation.
I1011 15:06:38.944291 38966 net.cpp:200] batch_norm19 needs backward computation.
I1011 15:06:38.944299 38966 net.cpp:200] conv19 needs backward computation.
I1011 15:06:38.944308 38966 net.cpp:200] add3 needs backward computation.
I1011 15:06:38.944316 38966 net.cpp:200] bn_scale18 needs backward computation.
I1011 15:06:38.944324 38966 net.cpp:200] batch_norm18 needs backward computation.
I1011 15:06:38.944332 38966 net.cpp:200] conv18 needs backward computation.
I1011 15:06:38.944340 38966 net.cpp:200] relu12 needs backward computation.
I1011 15:06:38.944348 38966 net.cpp:200] bn_scale17 needs backward computation.
I1011 15:06:38.944356 38966 net.cpp:200] batch_norm17 needs backward computation.
I1011 15:06:38.944365 38966 net.cpp:200] conv17 needs backward computation.
I1011 15:06:38.944372 38966 net.cpp:200] relu11 needs backward computation.
I1011 15:06:38.944380 38966 net.cpp:200] bn_scale16 needs backward computation.
I1011 15:06:38.944387 38966 net.cpp:200] batch_norm16 needs backward computation.
I1011 15:06:38.944394 38966 net.cpp:200] conv16 needs backward computation.
I1011 15:06:38.944403 38966 net.cpp:200] add2_add2_0_split needs backward computation.
I1011 15:06:38.944411 38966 net.cpp:200] add2 needs backward computation.
I1011 15:06:38.944425 38966 net.cpp:200] bn_scale15 needs backward computation.
I1011 15:06:38.944433 38966 net.cpp:200] batch_norm15 needs backward computation.
I1011 15:06:38.944440 38966 net.cpp:200] conv15 needs backward computation.
I1011 15:06:38.944448 38966 net.cpp:200] relu10 needs backward computation.
I1011 15:06:38.944456 38966 net.cpp:200] bn_scale14 needs backward computation.
I1011 15:06:38.944463 38966 net.cpp:200] batch_norm14 needs backward computation.
I1011 15:06:38.944471 38966 net.cpp:200] conv14 needs backward computation.
I1011 15:06:38.944479 38966 net.cpp:200] relu9 needs backward computation.
I1011 15:06:38.944487 38966 net.cpp:200] bn_scale13 needs backward computation.
I1011 15:06:38.944495 38966 net.cpp:200] batch_norm13 needs backward computation.
I1011 15:06:38.944504 38966 net.cpp:200] conv13 needs backward computation.
I1011 15:06:38.944511 38966 net.cpp:200] conv12_bn_scale12_0_split needs backward computation.
I1011 15:06:38.944519 38966 net.cpp:200] bn_scale12 needs backward computation.
I1011 15:06:38.944527 38966 net.cpp:200] batch_norm12 needs backward computation.
I1011 15:06:38.944535 38966 net.cpp:200] conv12 needs backward computation.
I1011 15:06:38.944542 38966 net.cpp:200] relu8 needs backward computation.
I1011 15:06:38.944550 38966 net.cpp:200] bn_scale11 needs backward computation.
I1011 15:06:38.944558 38966 net.cpp:200] batch_norm11 needs backward computation.
I1011 15:06:38.944566 38966 net.cpp:200] conv11 needs backward computation.
I1011 15:06:38.944573 38966 net.cpp:200] relu7 needs backward computation.
I1011 15:06:38.944595 38966 net.cpp:200] bn_scale10 needs backward computation.
I1011 15:06:38.944604 38966 net.cpp:200] batch_norm10 needs backward computation.
I1011 15:06:38.944612 38966 net.cpp:200] conv10 needs backward computation.
I1011 15:06:38.944620 38966 net.cpp:200] add1 needs backward computation.
I1011 15:06:38.944629 38966 net.cpp:200] bn_scale9 needs backward computation.
I1011 15:06:38.944638 38966 net.cpp:200] batch_norm9 needs backward computation.
I1011 15:06:38.944646 38966 net.cpp:200] conv9 needs backward computation.
I1011 15:06:38.944654 38966 net.cpp:200] relu6 needs backward computation.
I1011 15:06:38.944663 38966 net.cpp:200] bn_scale8 needs backward computation.
I1011 15:06:38.944670 38966 net.cpp:200] batch_norm8 needs backward computation.
I1011 15:06:38.944677 38966 net.cpp:200] conv8 needs backward computation.
I1011 15:06:38.944685 38966 net.cpp:200] relu5 needs backward computation.
I1011 15:06:38.944694 38966 net.cpp:200] bn_scale7 needs backward computation.
I1011 15:06:38.944702 38966 net.cpp:200] batch_norm7 needs backward computation.
I1011 15:06:38.944710 38966 net.cpp:200] conv7 needs backward computation.
I1011 15:06:38.944718 38966 net.cpp:200] conv6_bn_scale6_0_split needs backward computation.
I1011 15:06:38.944727 38966 net.cpp:200] bn_scale6 needs backward computation.
I1011 15:06:38.944734 38966 net.cpp:200] batch_norm6 needs backward computation.
I1011 15:06:38.944742 38966 net.cpp:200] conv6 needs backward computation.
I1011 15:06:38.944751 38966 net.cpp:200] relu4 needs backward computation.
I1011 15:06:38.944759 38966 net.cpp:200] bn_scale5 needs backward computation.
I1011 15:06:38.944767 38966 net.cpp:200] batch_norm5 needs backward computation.
I1011 15:06:38.944774 38966 net.cpp:200] conv5 needs backward computation.
I1011 15:06:38.944782 38966 net.cpp:200] relu3 needs backward computation.
I1011 15:06:38.944792 38966 net.cpp:200] bn_scale4 needs backward computation.
I1011 15:06:38.944799 38966 net.cpp:200] batch_norm4 needs backward computation.
I1011 15:06:38.944806 38966 net.cpp:200] conv4 needs backward computation.
I1011 15:06:38.944815 38966 net.cpp:200] bn_scale3 needs backward computation.
I1011 15:06:38.944823 38966 net.cpp:200] batch_norm3 needs backward computation.
I1011 15:06:38.944831 38966 net.cpp:200] conv3 needs backward computation.
I1011 15:06:38.944840 38966 net.cpp:200] relu2 needs backward computation.
I1011 15:06:38.944847 38966 net.cpp:200] bn_scale2 needs backward computation.
I1011 15:06:38.944855 38966 net.cpp:200] batch_norm2 needs backward computation.
I1011 15:06:38.944862 38966 net.cpp:200] conv2 needs backward computation.
I1011 15:06:38.944871 38966 net.cpp:200] relu1 needs backward computation.
I1011 15:06:38.944883 38966 net.cpp:200] bn_scale1 needs backward computation.
I1011 15:06:38.944890 38966 net.cpp:200] batch_norm1 needs backward computation.
I1011 15:06:38.944898 38966 net.cpp:200] conv1 needs backward computation.
I1011 15:06:38.944908 38966 net.cpp:202] label_data_1_split does not need backward computation.
I1011 15:06:38.944918 38966 net.cpp:202] data does not need backward computation.
I1011 15:06:38.944926 38966 net.cpp:244] This network produces output det_loss1
I1011 15:06:38.944936 38966 net.cpp:244] This network produces output det_loss2
I1011 15:06:38.945062 38966 net.cpp:257] Network initialization done.
I1011 15:06:38.946918 38966 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: yolo_lite/test.prototxt
I1011 15:06:38.946938 38966 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I1011 15:06:38.946945 38966 solver.cpp:203] Creating test net (#0) specified by test_net file: yolo_lite/test.prototxt
I1011 15:06:38.948699 38966 net.cpp:53] Initializing net from parameters: 
name: "MobileNetV2"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.007843
    mean_value: 127.5
    mean_value: 127.5
    mean_value: 127.5
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 352
      width: 352
      interp_mode: LINEAR
    }
  }
  data_param {
    source: "test_lmdb"
    batch_size: 1
    backend: LMDB
  }
  annotated_data_param {
    batch_sampler {
    }
    label_map_file: "labelmap.prototxt"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "DepthwiseConvolution"
  bottom: "conv1"
  top: "conv2"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  convolution_param {
    num_output: 15
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 87
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "DepthwiseConvolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 87
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 87
    stride: 2
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm5"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale5"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "conv5"
  top: "conv6"
  convolution_param {
    num_output: 22
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm6"
  type: "BatchNorm"
  bottom: "conv6"
  top: "conv6"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale6"
  type: "Scale"
  bottom: "conv6"
  top: "conv6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7"
  convolution_param {
    num_output: 130
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm7"
  type: "BatchNorm"
  bottom: "conv7"
  top: "conv7"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale7"
  type: "Scale"
  bottom: "conv7"
  top: "conv7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "conv8"
  type: "DepthwiseConvolution"
  bottom: "conv7"
  top: "conv8"
  convolution_param {
    num_output: 130
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 130
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm8"
  type: "BatchNorm"
  bottom: "conv8"
  top: "conv8"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale8"
  type: "Scale"
  bottom: "conv8"
  top: "conv8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "conv8"
  top: "conv8"
}
layer {
  name: "conv9"
  type: "Convolution"
  bottom: "conv8"
  top: "conv9"
  convolution_param {
    num_output: 22
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm9"
  type: "BatchNorm"
  bottom: "conv9"
  top: "conv9"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale9"
  type: "Scale"
  bottom: "conv9"
  top: "conv9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add1"
  type: "Eltwise"
  bottom: "conv6"
  bottom: "conv9"
  top: "add1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv10"
  type: "Convolution"
  bottom: "add1"
  top: "conv10"
  convolution_param {
    num_output: 130
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm10"
  type: "BatchNorm"
  bottom: "conv10"
  top: "conv10"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale10"
  type: "Scale"
  bottom: "conv10"
  top: "conv10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "conv11"
  type: "DepthwiseConvolution"
  bottom: "conv10"
  top: "conv11"
  convolution_param {
    num_output: 130
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 130
    stride: 2
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "conv11"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale11"
  type: "Scale"
  bottom: "conv11"
  top: "conv11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu8"
  type: "ReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "conv12"
  type: "Convolution"
  bottom: "conv11"
  top: "conv12"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm12"
  type: "BatchNorm"
  bottom: "conv12"
  top: "conv12"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale12"
  type: "Scale"
  bottom: "conv12"
  top: "conv12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv13"
  type: "Convolution"
  bottom: "conv12"
  top: "conv13"
  convolution_param {
    num_output: 173
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm13"
  type: "BatchNorm"
  bottom: "conv13"
  top: "conv13"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale13"
  type: "Scale"
  bottom: "conv13"
  top: "conv13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu9"
  type: "ReLU"
  bottom: "conv13"
  top: "conv13"
}
layer {
  name: "conv14"
  type: "DepthwiseConvolution"
  bottom: "conv13"
  top: "conv14"
  convolution_param {
    num_output: 173
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 173
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm14"
  type: "BatchNorm"
  bottom: "conv14"
  top: "conv14"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale14"
  type: "Scale"
  bottom: "conv14"
  top: "conv14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu10"
  type: "ReLU"
  bottom: "conv14"
  top: "conv14"
}
layer {
  name: "conv15"
  type: "Convolution"
  bottom: "conv14"
  top: "conv15"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm15"
  type: "BatchNorm"
  bottom: "conv15"
  top: "conv15"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale15"
  type: "Scale"
  bottom: "conv15"
  top: "conv15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add2"
  type: "Eltwise"
  bottom: "conv12"
  bottom: "conv15"
  top: "add2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv16"
  type: "Convolution"
  bottom: "add2"
  top: "conv16"
  convolution_param {
    num_output: 173
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm16"
  type: "BatchNorm"
  bottom: "conv16"
  top: "conv16"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale16"
  type: "Scale"
  bottom: "conv16"
  top: "conv16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu11"
  type: "ReLU"
  bottom: "conv16"
  top: "conv16"
}
layer {
  name: "conv17"
  type: "DepthwiseConvolution"
  bottom: "conv16"
  top: "conv17"
  convolution_param {
    num_output: 173
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 173
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm17"
  type: "BatchNorm"
  bottom: "conv17"
  top: "conv17"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale17"
  type: "Scale"
  bottom: "conv17"
  top: "conv17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu12"
  type: "ReLU"
  bottom: "conv17"
  top: "conv17"
}
layer {
  name: "conv18"
  type: "Convolution"
  bottom: "conv17"
  top: "conv18"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm18"
  type: "BatchNorm"
  bottom: "conv18"
  top: "conv18"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale18"
  type: "Scale"
  bottom: "conv18"
  top: "conv18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add3"
  type: "Eltwise"
  bottom: "add2"
  bottom: "conv18"
  top: "add3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv19"
  type: "Convolution"
  bottom: "add3"
  top: "conv19"
  convolution_param {
    num_output: 173
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm19"
  type: "BatchNorm"
  bottom: "conv19"
  top: "conv19"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale19"
  type: "Scale"
  bottom: "conv19"
  top: "conv19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu13"
  type: "ReLU"
  bottom: "conv19"
  top: "conv19"
}
layer {
  name: "conv20"
  type: "DepthwiseConvolution"
  bottom: "conv19"
  top: "conv20"
  convolution_param {
    num_output: 173
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 173
    stride: 2
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm20"
  type: "BatchNorm"
  bottom: "conv20"
  top: "conv20"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale20"
  type: "Scale"
  bottom: "conv20"
  top: "conv20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu14"
  type: "ReLU"
  bottom: "conv20"
  top: "conv20"
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "conv20"
  top: "conv21"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm21"
  type: "BatchNorm"
  bottom: "conv21"
  top: "conv21"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale21"
  type: "Scale"
  bottom: "conv21"
  top: "conv21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  convolution_param {
    num_output: 346
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm22"
  type: "BatchNorm"
  bottom: "conv22"
  top: "conv22"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale22"
  type: "Scale"
  bottom: "conv22"
  top: "conv22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu15"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "conv23"
  type: "DepthwiseConvolution"
  bottom: "conv22"
  top: "conv23"
  convolution_param {
    num_output: 346
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 346
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm23"
  type: "BatchNorm"
  bottom: "conv23"
  top: "conv23"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale23"
  type: "Scale"
  bottom: "conv23"
  top: "conv23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu16"
  type: "ReLU"
  bottom: "conv23"
  top: "conv23"
}
layer {
  name: "conv24"
  type: "Convolution"
  bottom: "conv23"
  top: "conv24"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm24"
  type: "BatchNorm"
  bottom: "conv24"
  top: "conv24"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale24"
  type: "Scale"
  bottom: "conv24"
  top: "conv24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add4"
  type: "Eltwise"
  bottom: "conv21"
  bottom: "conv24"
  top: "add4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv25"
  type: "Convolution"
  bottom: "add4"
  top: "conv25"
  convolution_param {
    num_output: 327
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm25"
  type: "BatchNorm"
  bottom: "conv25"
  top: "conv25"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale25"
  type: "Scale"
  bottom: "conv25"
  top: "conv25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu17"
  type: "ReLU"
  bottom: "conv25"
  top: "conv25"
}
layer {
  name: "conv26"
  type: "DepthwiseConvolution"
  bottom: "conv25"
  top: "conv26"
  convolution_param {
    num_output: 327
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 327
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm26"
  type: "BatchNorm"
  bottom: "conv26"
  top: "conv26"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale26"
  type: "Scale"
  bottom: "conv26"
  top: "conv26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu18"
  type: "ReLU"
  bottom: "conv26"
  top: "conv26"
}
layer {
  name: "conv27"
  type: "Convolution"
  bottom: "conv26"
  top: "conv27"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm27"
  type: "BatchNorm"
  bottom: "conv27"
  top: "conv27"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale27"
  type: "Scale"
  bottom: "conv27"
  top: "conv27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add5"
  type: "Eltwise"
  bottom: "add4"
  bottom: "conv27"
  top: "add5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv28"
  type: "Convolution"
  bottom: "add5"
  top: "conv28"
  convolution_param {
    num_output: 327
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm28"
  type: "BatchNorm"
  bottom: "conv28"
  top: "conv28"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale28"
  type: "Scale"
  bottom: "conv28"
  top: "conv28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu19"
  type: "ReLU"
  bottom: "conv28"
  top: "conv28"
}
layer {
  name: "conv29"
  type: "DepthwiseConvolution"
  bottom: "conv28"
  top: "conv29"
  convolution_param {
    num_output: 327
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 327
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm29"
  type: "BatchNorm"
  bottom: "conv29"
  top: "conv29"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale29"
  type: "Scale"
  bottom: "conv29"
  top: "conv29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu20"
  type: "ReLU"
  bottom: "conv29"
  top: "conv29"
}
layer {
  name: "conv30"
  type: "Convolution"
  bottom: "conv29"
  top: "conv30"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm30"
  type: "BatchNorm"
  bottom: "conv30"
  top: "conv30"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale30"
  type: "Scale"
  bottom: "conv30"
  top: "conv30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add6"
  type: "Eltwise"
  bottom: "add5"
  bottom: "conv30"
  top: "add6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "add6"
  top: "conv31"
  convolution_param {
    num_output: 327
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm31"
  type: "BatchNorm"
  bottom: "conv31"
  top: "conv31"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale31"
  type: "Scale"
  bottom: "conv31"
  top: "conv31"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
}
layer {
  name: "conv32"
  type: "DepthwiseConvolution"
  bottom: "conv31"
  top: "conv32"
  convolution_param {
    num_output: 327
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 327
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm32"
  type: "BatchNorm"
  bottom: "conv32"
  top: "conv32"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale32"
  type: "Scale"
  bottom: "conv32"
  top: "conv32"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "conv33"
  type: "Convolution"
  bottom: "conv32"
  top: "conv33"
  convolution_param {
    num_output: 87
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm33"
  type: "BatchNorm"
  bottom: "conv33"
  top: "conv33"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale33"
  type: "Scale"
  bottom: "conv33"
  top: "conv33"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv34"
  type: "Convolution"
  bottom: "conv33"
  top: "conv34"
  convolution_param {
    num_output: 461
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm34"
  type: "BatchNorm"
  bottom: "conv34"
  top: "conv34"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale34"
  type: "Scale"
  bottom: "conv34"
  top: "conv34"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu23"
  type: "ReLU"
  bottom: "conv34"
  top: "conv34"
}
layer {
  name: "conv35"
  type: "DepthwiseConvolution"
  bottom: "conv34"
  top: "conv35"
  convolution_param {
    num_output: 461
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 461
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm35"
  type: "BatchNorm"
  bottom: "conv35"
  top: "conv35"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale35"
  type: "Scale"
  bottom: "conv35"
  top: "conv35"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu24"
  type: "ReLU"
  bottom: "conv35"
  top: "conv35"
}
layer {
  name: "conv36"
  type: "Convolution"
  bottom: "conv35"
  top: "conv36"
  convolution_param {
    num_output: 87
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm36"
  type: "BatchNorm"
  bottom: "conv36"
  top: "conv36"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale36"
  type: "Scale"
  bottom: "conv36"
  top: "conv36"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add7"
  type: "Eltwise"
  bottom: "conv33"
  bottom: "conv36"
  top: "add7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv37"
  type: "Convolution"
  bottom: "add7"
  top: "conv37"
  convolution_param {
    num_output: 461
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm37"
  type: "BatchNorm"
  bottom: "conv37"
  top: "conv37"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale37"
  type: "Scale"
  bottom: "conv37"
  top: "conv37"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu25"
  type: "ReLU"
  bottom: "conv37"
  top: "conv37"
}
layer {
  name: "conv38"
  type: "DepthwiseConvolution"
  bottom: "conv37"
  top: "conv38"
  convolution_param {
    num_output: 461
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 461
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm38"
  type: "BatchNorm"
  bottom: "conv38"
  top: "conv38"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale38"
  type: "Scale"
  bottom: "conv38"
  top: "conv38"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu26"
  type: "ReLU"
  bottom: "conv38"
  top: "conv38"
}
layer {
  name: "conv39"
  type: "Convolution"
  bottom: "conv38"
  top: "conv39"
  convolution_param {
    num_output: 87
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm39"
  type: "BatchNorm"
  bottom: "conv39"
  top: "conv39"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale39"
  type: "Scale"
  bottom: "conv39"
  top: "conv39"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add8"
  type: "Eltwise"
  bottom: "add7"
  bottom: "conv39"
  top: "add8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv40"
  type: "Convolution"
  bottom: "add8"
  top: "conv40"
  convolution_param {
    num_output: 576
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm40"
  type: "BatchNorm"
  bottom: "conv40"
  top: "conv40"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale40"
  type: "Scale"
  bottom: "conv40"
  top: "conv40"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu27"
  type: "ReLU"
  bottom: "conv40"
  top: "conv40"
}
layer {
  name: "conv41"
  type: "DepthwiseConvolution"
  bottom: "conv40"
  top: "conv41"
  convolution_param {
    num_output: 576
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 576
    stride: 2
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm41"
  type: "BatchNorm"
  bottom: "conv41"
  top: "conv41"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale41"
  type: "Scale"
  bottom: "conv41"
  top: "conv41"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu28"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
}
layer {
  name: "conv42"
  type: "Convolution"
  bottom: "conv41"
  top: "conv42"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm42"
  type: "BatchNorm"
  bottom: "conv42"
  top: "conv42"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale42"
  type: "Scale"
  bottom: "conv42"
  top: "conv42"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv43"
  type: "Convolution"
  bottom: "conv42"
  top: "conv43"
  convolution_param {
    num_output: 768
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm43"
  type: "BatchNorm"
  bottom: "conv43"
  top: "conv43"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale43"
  type: "Scale"
  bottom: "conv43"
  top: "conv43"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu29"
  type: "ReLU"
  bottom: "conv43"
  top: "conv43"
}
layer {
  name: "conv44"
  type: "DepthwiseConvolution"
  bottom: "conv43"
  top: "conv44"
  convolution_param {
    num_output: 768
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 768
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm44"
  type: "BatchNorm"
  bottom: "conv44"
  top: "conv44"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale44"
  type: "Scale"
  bottom: "conv44"
  top: "conv44"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu30"
  type: "ReLU"
  bottom: "conv44"
  top: "conv44"
}
layer {
  name: "conv45"
  type: "Convolution"
  bottom: "conv44"
  top: "conv45"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm45"
  type: "BatchNorm"
  bottom: "conv45"
  top: "conv45"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale45"
  type: "Scale"
  bottom: "conv45"
  top: "conv45"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add9"
  type: "Eltwise"
  bottom: "conv42"
  bottom: "conv45"
  top: "add9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv46"
  type: "Convolution"
  bottom: "add9"
  top: "conv46"
  convolution_param {
    num_output: 768
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm46"
  type: "BatchNorm"
  bottom: "conv46"
  top: "conv46"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale46"
  type: "Scale"
  bottom: "conv46"
  top: "conv46"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv46"
  top: "conv46"
}
layer {
  name: "conv47"
  type: "DepthwiseConvolution"
  bottom: "conv46"
  top: "conv47"
  convolution_param {
    num_output: 768
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 768
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm47"
  type: "BatchNorm"
  bottom: "conv47"
  top: "conv47"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale47"
  type: "Scale"
  bottom: "conv47"
  top: "conv47"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv47"
  top: "conv47"
}
layer {
  name: "conv48"
  type: "Convolution"
  bottom: "conv47"
  top: "conv48"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm48"
  type: "BatchNorm"
  bottom: "conv48"
  top: "conv48"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale48"
  type: "Scale"
  bottom: "conv48"
  top: "conv48"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "add10"
  type: "Eltwise"
  bottom: "add9"
  bottom: "conv48"
  top: "add10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv49"
  type: "Convolution"
  bottom: "add10"
  top: "conv49"
  convolution_param {
    num_output: 768
    bias_term: false
    pad: 0
    kernel_size: 1
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    dilation: 1
  }
}
layer {
  name: "batch_norm49"
  type: "BatchNorm"
  bottom: "conv49"
  top: "conv49"
  batch_norm_param {
    eps: 1e-05
  }
}
layer {
  name: "bn_scale49"
  type: "Scale"
  bottom: "conv49"
  top: "conv49"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu33"
  type: "ReLU"
  bottom: "conv49"
  top: "conv49"
}
laye
I1011 15:06:38.949640 38966 layer_factory.hpp:77] Creating layer data
I1011 15:06:38.949740 38966 net.cpp:86] Creating Layer data
I1011 15:06:38.949755 38966 net.cpp:382] data -> data
I1011 15:06:38.949774 38966 net.cpp:382] data -> label
I1011 15:06:38.951592 39022 db_lmdb.cpp:35] Opened lmdb test_lmdb
I1011 15:06:38.954001 38966 annotated_data_layer.cpp:78] output data size: 1,3,352,352
I1011 15:06:38.961148 38966 net.cpp:124] Setting up data
I1011 15:06:38.961184 38966 net.cpp:131] Top shape: 1 3 352 352 (371712)
I1011 15:06:38.961197 38966 net.cpp:131] Top shape: 1 1 1 8 (8)
I1011 15:06:38.961205 38966 net.cpp:139] Memory required for data: 1486880
I1011 15:06:38.961215 38966 layer_factory.hpp:77] Creating layer conv1
I1011 15:06:38.961235 38966 net.cpp:86] Creating Layer conv1
I1011 15:06:38.961244 38966 net.cpp:408] conv1 <- data
I1011 15:06:38.961257 38966 net.cpp:382] conv1 -> conv1
I1011 15:06:38.962278 38966 net.cpp:124] Setting up conv1
I1011 15:06:38.962306 38966 net.cpp:131] Top shape: 1 32 176 176 (991232)
I1011 15:06:38.962316 38966 net.cpp:139] Memory required for data: 5451808
I1011 15:06:38.962332 38966 layer_factory.hpp:77] Creating layer batch_norm1
I1011 15:06:38.962347 38966 net.cpp:86] Creating Layer batch_norm1
I1011 15:06:38.962357 38966 net.cpp:408] batch_norm1 <- conv1
I1011 15:06:38.962371 38966 net.cpp:369] batch_norm1 -> conv1 (in-place)
I1011 15:06:38.962847 38966 net.cpp:124] Setting up batch_norm1
I1011 15:06:38.962864 38966 net.cpp:131] Top shape: 1 32 176 176 (991232)
I1011 15:06:38.962873 38966 net.cpp:139] Memory required for data: 9416736
I1011 15:06:38.962901 38966 layer_factory.hpp:77] Creating layer bn_scale1
I1011 15:06:38.962915 38966 net.cpp:86] Creating Layer bn_scale1
I1011 15:06:38.962924 38966 net.cpp:408] bn_scale1 <- conv1
I1011 15:06:38.962934 38966 net.cpp:369] bn_scale1 -> conv1 (in-place)
I1011 15:06:38.963002 38966 layer_factory.hpp:77] Creating layer bn_scale1
I1011 15:06:38.963179 38966 net.cpp:124] Setting up bn_scale1
I1011 15:06:38.963193 38966 net.cpp:131] Top shape: 1 32 176 176 (991232)
I1011 15:06:38.963201 38966 net.cpp:139] Memory required for data: 13381664
I1011 15:06:38.963218 38966 layer_factory.hpp:77] Creating layer relu1
I1011 15:06:38.963229 38966 net.cpp:86] Creating Layer relu1
I1011 15:06:38.963238 38966 net.cpp:408] relu1 <- conv1
I1011 15:06:38.963259 38966 net.cpp:369] relu1 -> conv1 (in-place)
I1011 15:06:38.963270 38966 net.cpp:124] Setting up relu1
I1011 15:06:38.963279 38966 net.cpp:131] Top shape: 1 32 176 176 (991232)
I1011 15:06:38.963285 38966 net.cpp:139] Memory required for data: 17346592
I1011 15:06:38.963291 38966 layer_factory.hpp:77] Creating layer conv2
I1011 15:06:38.963305 38966 net.cpp:86] Creating Layer conv2
I1011 15:06:38.963312 38966 net.cpp:408] conv2 <- conv1
I1011 15:06:38.963323 38966 net.cpp:382] conv2 -> conv2
I1011 15:06:38.963543 38966 net.cpp:124] Setting up conv2
I1011 15:06:38.963557 38966 net.cpp:131] Top shape: 1 32 176 176 (991232)
I1011 15:06:38.963564 38966 net.cpp:139] Memory required for data: 21311520
I1011 15:06:38.963587 38966 layer_factory.hpp:77] Creating layer batch_norm2
I1011 15:06:38.963599 38966 net.cpp:86] Creating Layer batch_norm2
I1011 15:06:38.963605 38966 net.cpp:408] batch_norm2 <- conv2
I1011 15:06:38.963615 38966 net.cpp:369] batch_norm2 -> conv2 (in-place)
I1011 15:06:38.963829 38966 net.cpp:124] Setting up batch_norm2
I1011 15:06:38.963842 38966 net.cpp:131] Top shape: 1 32 176 176 (991232)
I1011 15:06:38.963848 38966 net.cpp:139] Memory required for data: 25276448
I1011 15:06:38.963865 38966 layer_factory.hpp:77] Creating layer bn_scale2
I1011 15:06:38.963886 38966 net.cpp:86] Creating Layer bn_scale2
I1011 15:06:38.963905 38966 net.cpp:408] bn_scale2 <- conv2
I1011 15:06:38.963917 38966 net.cpp:369] bn_scale2 -> conv2 (in-place)
I1011 15:06:38.963968 38966 layer_factory.hpp:77] Creating layer bn_scale2
I1011 15:06:38.964112 38966 net.cpp:124] Setting up bn_scale2
I1011 15:06:38.964124 38966 net.cpp:131] Top shape: 1 32 176 176 (991232)
I1011 15:06:38.964130 38966 net.cpp:139] Memory required for data: 29241376
I1011 15:06:38.964143 38966 layer_factory.hpp:77] Creating layer relu2
I1011 15:06:38.964154 38966 net.cpp:86] Creating Layer relu2
I1011 15:06:38.964162 38966 net.cpp:408] relu2 <- conv2
I1011 15:06:38.964172 38966 net.cpp:369] relu2 -> conv2 (in-place)
I1011 15:06:38.964184 38966 net.cpp:124] Setting up relu2
I1011 15:06:38.964195 38966 net.cpp:131] Top shape: 1 32 176 176 (991232)
I1011 15:06:38.964201 38966 net.cpp:139] Memory required for data: 33206304
I1011 15:06:38.964208 38966 layer_factory.hpp:77] Creating layer conv3
I1011 15:06:38.964221 38966 net.cpp:86] Creating Layer conv3
I1011 15:06:38.964231 38966 net.cpp:408] conv3 <- conv2
I1011 15:06:38.964241 38966 net.cpp:382] conv3 -> conv3
I1011 15:06:38.964442 38966 net.cpp:124] Setting up conv3
I1011 15:06:38.964454 38966 net.cpp:131] Top shape: 1 15 176 176 (464640)
I1011 15:06:38.964460 38966 net.cpp:139] Memory required for data: 35064864
I1011 15:06:38.964470 38966 layer_factory.hpp:77] Creating layer batch_norm3
I1011 15:06:38.964481 38966 net.cpp:86] Creating Layer batch_norm3
I1011 15:06:38.964489 38966 net.cpp:408] batch_norm3 <- conv3
I1011 15:06:38.964499 38966 net.cpp:369] batch_norm3 -> conv3 (in-place)
I1011 15:06:38.964947 38966 net.cpp:124] Setting up batch_norm3
I1011 15:06:38.964972 38966 net.cpp:131] Top shape: 1 15 176 176 (464640)
I1011 15:06:38.964980 38966 net.cpp:139] Memory required for data: 36923424
I1011 15:06:38.964998 38966 layer_factory.hpp:77] Creating layer bn_scale3
I1011 15:06:38.965009 38966 net.cpp:86] Creating Layer bn_scale3
I1011 15:06:38.965018 38966 net.cpp:408] bn_scale3 <- conv3
I1011 15:06:38.965029 38966 net.cpp:369] bn_scale3 -> conv3 (in-place)
I1011 15:06:38.965101 38966 layer_factory.hpp:77] Creating layer bn_scale3
I1011 15:06:38.965339 38966 net.cpp:124] Setting up bn_scale3
I1011 15:06:38.965355 38966 net.cpp:131] Top shape: 1 15 176 176 (464640)
I1011 15:06:38.965363 38966 net.cpp:139] Memory required for data: 38781984
I1011 15:06:38.965381 38966 layer_factory.hpp:77] Creating layer conv4
I1011 15:06:38.965397 38966 net.cpp:86] Creating Layer conv4
I1011 15:06:38.965405 38966 net.cpp:408] conv4 <- conv3
I1011 15:06:38.965418 38966 net.cpp:382] conv4 -> conv4
I1011 15:06:38.965668 38966 net.cpp:124] Setting up conv4
I1011 15:06:38.965677 38966 net.cpp:131] Top shape: 1 87 176 176 (2694912)
I1011 15:06:38.965680 38966 net.cpp:139] Memory required for data: 49561632
I1011 15:06:38.965685 38966 layer_factory.hpp:77] Creating layer batch_norm4
I1011 15:06:38.965692 38966 net.cpp:86] Creating Layer batch_norm4
I1011 15:06:38.965695 38966 net.cpp:408] batch_norm4 <- conv4
I1011 15:06:38.965700 38966 net.cpp:369] batch_norm4 -> conv4 (in-place)
I1011 15:06:38.965905 38966 net.cpp:124] Setting up batch_norm4
I1011 15:06:38.965912 38966 net.cpp:131] Top shape: 1 87 176 176 (2694912)
I1011 15:06:38.965915 38966 net.cpp:139] Memory required for data: 60341280
I1011 15:06:38.965924 38966 layer_factory.hpp:77] Creating layer bn_scale4
I1011 15:06:38.965929 38966 net.cpp:86] Creating Layer bn_scale4
I1011 15:06:38.965945 38966 net.cpp:408] bn_scale4 <- conv4
I1011 15:06:38.965951 38966 net.cpp:369] bn_scale4 -> conv4 (in-place)
I1011 15:06:38.965988 38966 layer_factory.hpp:77] Creating layer bn_scale4
I1011 15:06:38.966116 38966 net.cpp:124] Setting up bn_scale4
I1011 15:06:38.966125 38966 net.cpp:131] Top shape: 1 87 176 176 (2694912)
I1011 15:06:38.966128 38966 net.cpp:139] Memory required for data: 71120928
I1011 15:06:38.966135 38966 layer_factory.hpp:77] Creating layer relu3
I1011 15:06:38.966140 38966 net.cpp:86] Creating Layer relu3
I1011 15:06:38.966145 38966 net.cpp:408] relu3 <- conv4
I1011 15:06:38.966150 38966 net.cpp:369] relu3 -> conv4 (in-place)
I1011 15:06:38.966154 38966 net.cpp:124] Setting up relu3
I1011 15:06:38.966159 38966 net.cpp:131] Top shape: 1 87 176 176 (2694912)
I1011 15:06:38.966162 38966 net.cpp:139] Memory required for data: 81900576
I1011 15:06:38.966166 38966 layer_factory.hpp:77] Creating layer conv5
I1011 15:06:38.966173 38966 net.cpp:86] Creating Layer conv5
I1011 15:06:38.966177 38966 net.cpp:408] conv5 <- conv4
I1011 15:06:38.966183 38966 net.cpp:382] conv5 -> conv5
I1011 15:06:38.966369 38966 net.cpp:124] Setting up conv5
I1011 15:06:38.966377 38966 net.cpp:131] Top shape: 1 87 88 88 (673728)
I1011 15:06:38.966380 38966 net.cpp:139] Memory required for data: 84595488
I1011 15:06:38.966385 38966 layer_factory.hpp:77] Creating layer batch_norm5
I1011 15:06:38.966390 38966 net.cpp:86] Creating Layer batch_norm5
I1011 15:06:38.966394 38966 net.cpp:408] batch_norm5 <- conv5
I1011 15:06:38.966399 38966 net.cpp:369] batch_norm5 -> conv5 (in-place)
I1011 15:06:38.966579 38966 net.cpp:124] Setting up batch_norm5
I1011 15:06:38.966590 38966 net.cpp:131] Top shape: 1 87 88 88 (673728)
I1011 15:06:38.966594 38966 net.cpp:139] Memory required for data: 87290400
I1011 15:06:38.966603 38966 layer_factory.hpp:77] Creating layer bn_scale5
I1011 15:06:38.966608 38966 net.cpp:86] Creating Layer bn_scale5
I1011 15:06:38.966611 38966 net.cpp:408] bn_scale5 <- conv5
I1011 15:06:38.966617 38966 net.cpp:369] bn_scale5 -> conv5 (in-place)
I1011 15:06:38.966652 38966 layer_factory.hpp:77] Creating layer bn_scale5
I1011 15:06:38.966771 38966 net.cpp:124] Setting up bn_scale5
I1011 15:06:38.966780 38966 net.cpp:131] Top shape: 1 87 88 88 (673728)
I1011 15:06:38.966784 38966 net.cpp:139] Memory required for data: 89985312
I1011 15:06:38.966789 38966 layer_factory.hpp:77] Creating layer relu4
I1011 15:06:38.966795 38966 net.cpp:86] Creating Layer relu4
I1011 15:06:38.966799 38966 net.cpp:408] relu4 <- conv5
I1011 15:06:38.966804 38966 net.cpp:369] relu4 -> conv5 (in-place)
I1011 15:06:38.966809 38966 net.cpp:124] Setting up relu4
I1011 15:06:38.966814 38966 net.cpp:131] Top shape: 1 87 88 88 (673728)
I1011 15:06:38.966817 38966 net.cpp:139] Memory required for data: 92680224
I1011 15:06:38.966821 38966 layer_factory.hpp:77] Creating layer conv6
I1011 15:06:38.966828 38966 net.cpp:86] Creating Layer conv6
I1011 15:06:38.966832 38966 net.cpp:408] conv6 <- conv5
I1011 15:06:38.966838 38966 net.cpp:382] conv6 -> conv6
I1011 15:06:38.967037 38966 net.cpp:124] Setting up conv6
I1011 15:06:38.967046 38966 net.cpp:131] Top shape: 1 22 88 88 (170368)
I1011 15:06:38.967051 38966 net.cpp:139] Memory required for data: 93361696
I1011 15:06:38.967056 38966 layer_factory.hpp:77] Creating layer batch_norm6
I1011 15:06:38.967061 38966 net.cpp:86] Creating Layer batch_norm6
I1011 15:06:38.967065 38966 net.cpp:408] batch_norm6 <- conv6
I1011 15:06:38.967070 38966 net.cpp:369] batch_norm6 -> conv6 (in-place)
I1011 15:06:38.967269 38966 net.cpp:124] Setting up batch_norm6
I1011 15:06:38.967279 38966 net.cpp:131] Top shape: 1 22 88 88 (170368)
I1011 15:06:38.967283 38966 net.cpp:139] Memory required for data: 94043168
I1011 15:06:38.967293 38966 layer_factory.hpp:77] Creating layer bn_scale6
I1011 15:06:38.967298 38966 net.cpp:86] Creating Layer bn_scale6
I1011 15:06:38.967303 38966 net.cpp:408] bn_scale6 <- conv6
I1011 15:06:38.967308 38966 net.cpp:369] bn_scale6 -> conv6 (in-place)
I1011 15:06:38.967344 38966 layer_factory.hpp:77] Creating layer bn_scale6
I1011 15:06:38.967473 38966 net.cpp:124] Setting up bn_scale6
I1011 15:06:38.967483 38966 net.cpp:131] Top shape: 1 22 88 88 (170368)
I1011 15:06:38.967485 38966 net.cpp:139] Memory required for data: 94724640
I1011 15:06:38.967492 38966 layer_factory.hpp:77] Creating layer conv6_bn_scale6_0_split
I1011 15:06:38.967499 38966 net.cpp:86] Creating Layer conv6_bn_scale6_0_split
I1011 15:06:38.967504 38966 net.cpp:408] conv6_bn_scale6_0_split <- conv6
I1011 15:06:38.967509 38966 net.cpp:382] conv6_bn_scale6_0_split -> conv6_bn_scale6_0_split_0
I1011 15:06:38.967517 38966 net.cpp:382] conv6_bn_scale6_0_split -> conv6_bn_scale6_0_split_1
I1011 15:06:38.967551 38966 net.cpp:124] Setting up conv6_bn_scale6_0_split
I1011 15:06:38.967559 38966 net.cpp:131] Top shape: 1 22 88 88 (170368)
I1011 15:06:38.967564 38966 net.cpp:131] Top shape: 1 22 88 88 (170368)
I1011 15:06:38.967567 38966 net.cpp:139] Memory required for data: 96087584
I1011 15:06:38.967571 38966 layer_factory.hpp:77] Creating layer conv7
I1011 15:06:38.967579 38966 net.cpp:86] Creating Layer conv7
I1011 15:06:38.967583 38966 net.cpp:408] conv7 <- conv6_bn_scale6_0_split_0
I1011 15:06:38.967589 38966 net.cpp:382] conv7 -> conv7
I1011 15:06:38.967800 38966 net.cpp:124] Setting up conv7
I1011 15:06:38.967808 38966 net.cpp:131] Top shape: 1 130 88 88 (1006720)
I1011 15:06:38.967813 38966 net.cpp:139] Memory required for data: 100114464
I1011 15:06:38.967818 38966 layer_factory.hpp:77] Creating layer batch_norm7
I1011 15:06:38.967823 38966 net.cpp:86] Creating Layer batch_norm7
I1011 15:06:38.967828 38966 net.cpp:408] batch_norm7 <- conv7
I1011 15:06:38.967833 38966 net.cpp:369] batch_norm7 -> conv7 (in-place)
I1011 15:06:38.968027 38966 net.cpp:124] Setting up batch_norm7
I1011 15:06:38.968036 38966 net.cpp:131] Top shape: 1 130 88 88 (1006720)
I1011 15:06:38.968040 38966 net.cpp:139] Memory required for data: 104141344
I1011 15:06:38.968048 38966 layer_factory.hpp:77] Creating layer bn_scale7
I1011 15:06:38.968055 38966 net.cpp:86] Creating Layer bn_scale7
I1011 15:06:38.968058 38966 net.cpp:408] bn_scale7 <- conv7
I1011 15:06:38.968065 38966 net.cpp:369] bn_scale7 -> conv7 (in-place)
I1011 15:06:38.968101 38966 layer_factory.hpp:77] Creating layer bn_scale7
I1011 15:06:38.968225 38966 net.cpp:124] Setting up bn_scale7
I1011 15:06:38.968236 38966 net.cpp:131] Top shape: 1 130 88 88 (1006720)
I1011 15:06:38.968240 38966 net.cpp:139] Memory required for data: 108168224
I1011 15:06:38.968246 38966 layer_factory.hpp:77] Creating layer relu5
I1011 15:06:38.968251 38966 net.cpp:86] Creating Layer relu5
I1011 15:06:38.968255 38966 net.cpp:408] relu5 <- conv7
I1011 15:06:38.968261 38966 net.cpp:369] relu5 -> conv7 (in-place)
I1011 15:06:38.968266 38966 net.cpp:124] Setting up relu5
I1011 15:06:38.968271 38966 net.cpp:131] Top shape: 1 130 88 88 (1006720)
I1011 15:06:38.968274 38966 net.cpp:139] Memory required for data: 112195104
I1011 15:06:38.968278 38966 layer_factory.hpp:77] Creating layer conv8
I1011 15:06:38.968287 38966 net.cpp:86] Creating Layer conv8
I1011 15:06:38.968291 38966 net.cpp:408] conv8 <- conv7
I1011 15:06:38.968299 38966 net.cpp:382] conv8 -> conv8
I1011 15:06:38.968500 38966 net.cpp:124] Setting up conv8
I1011 15:06:38.968509 38966 net.cpp:131] Top shape: 1 130 88 88 (1006720)
I1011 15:06:38.968513 38966 net.cpp:139] Memory required for data: 116221984
I1011 15:06:38.968518 38966 layer_factory.hpp:77] Creating layer batch_norm8
I1011 15:06:38.968523 38966 net.cpp:86] Creating Layer batch_norm8
I1011 15:06:38.968528 38966 net.cpp:408] batch_norm8 <- conv8
I1011 15:06:38.968533 38966 net.cpp:369] batch_norm8 -> conv8 (in-place)
I1011 15:06:38.968726 38966 net.cpp:124] Setting up batch_norm8
I1011 15:06:38.968735 38966 net.cpp:131] Top shape: 1 130 88 88 (1006720)
I1011 15:06:38.968739 38966 net.cpp:139] Memory required for data: 120248864
I1011 15:06:38.968746 38966 layer_factory.hpp:77] Creating layer bn_scale8
I1011 15:06:38.968755 38966 net.cpp:86] Creating Layer bn_scale8
I1011 15:06:38.968758 38966 net.cpp:408] bn_scale8 <- conv8
I1011 15:06:38.968773 38966 net.cpp:369] bn_scale8 -> conv8 (in-place)
I1011 15:06:38.968811 38966 layer_factory.hpp:77] Creating layer bn_scale8
I1011 15:06:38.968933 38966 net.cpp:124] Setting up bn_scale8
I1011 15:06:38.968942 38966 net.cpp:131] Top shape: 1 130 88 88 (1006720)
I1011 15:06:38.968946 38966 net.cpp:139] Memory required for data: 124275744
I1011 15:06:38.968952 38966 layer_factory.hpp:77] Creating layer relu6
I1011 15:06:38.968958 38966 net.cpp:86] Creating Layer relu6
I1011 15:06:38.968962 38966 net.cpp:408] relu6 <- conv8
I1011 15:06:38.968973 38966 net.cpp:369] relu6 -> conv8 (in-place)
I1011 15:06:38.968981 38966 net.cpp:124] Setting up relu6
I1011 15:06:38.968986 38966 net.cpp:131] Top shape: 1 130 88 88 (1006720)
I1011 15:06:38.968989 38966 net.cpp:139] Memory required for data: 128302624
I1011 15:06:38.968993 38966 layer_factory.hpp:77] Creating layer conv9
I1011 15:06:38.969007 38966 net.cpp:86] Creating Layer conv9
I1011 15:06:38.969013 38966 net.cpp:408] conv9 <- conv8
I1011 15:06:38.969019 38966 net.cpp:382] conv9 -> conv9
I1011 15:06:38.969250 38966 net.cpp:124] Setting up conv9
I1011 15:06:38.969259 38966 net.cpp:131] Top shape: 1 22 88 88 (170368)
I1011 15:06:38.969264 38966 net.cpp:139] Memory required for data: 128984096
I1011 15:06:38.969269 38966 layer_factory.hpp:77] Creating layer batch_norm9
I1011 15:06:38.969276 38966 net.cpp:86] Creating Layer batch_norm9
I1011 15:06:38.969283 38966 net.cpp:408] batch_norm9 <- conv9
I1011 15:06:38.969290 38966 net.cpp:369] batch_norm9 -> conv9 (in-place)
I1011 15:06:38.969496 38966 net.cpp:124] Setting up batch_norm9
I1011 15:06:38.969503 38966 net.cpp:131] Top shape: 1 22 88 88 (170368)
I1011 15:06:38.969506 38966 net.cpp:139] Memory required for data: 129665568
I1011 15:06:38.969514 38966 layer_factory.hpp:77] Creating layer bn_scale9
I1011 15:06:38.969521 38966 net.cpp:86] Creating Layer bn_scale9
I1011 15:06:38.969524 38966 net.cpp:408] bn_scale9 <- conv9
I1011 15:06:38.969532 38966 net.cpp:369] bn_scale9 -> conv9 (in-place)
I1011 15:06:38.969566 38966 layer_factory.hpp:77] Creating layer bn_scale9
I1011 15:06:38.969689 38966 net.cpp:124] Setting up bn_scale9
I1011 15:06:38.969699 38966 net.cpp:131] Top shape: 1 22 88 88 (170368)
I1011 15:06:38.969703 38966 net.cpp:139] Memory required for data: 130347040
I1011 15:06:38.969709 38966 layer_factory.hpp:77] Creating layer add1
I1011 15:06:38.969715 38966 net.cpp:86] Creating Layer add1
I1011 15:06:38.969719 38966 net.cpp:408] add1 <- conv6_bn_scale6_0_split_1
I1011 15:06:38.969724 38966 net.cpp:408] add1 <- conv9
I1011 15:06:38.969729 38966 net.cpp:382] add1 -> add1
I1011 15:06:38.970047 38966 net.cpp:124] Setting up add1
I1011 15:06:38.970055 38966 net.cpp:131] Top shape: 1 22 88 88 (170368)
I1011 15:06:38.970059 38966 net.cpp:139] Memory required for data: 131028512
I1011 15:06:38.970063 38966 layer_factory.hpp:77] Creating layer conv10
I1011 15:06:38.970074 38966 net.cpp:86] Creating Layer conv10
I1011 15:06:38.970080 38966 net.cpp:408] conv10 <- add1
I1011 15:06:38.970088 38966 net.cpp:382] conv10 -> conv10
I1011 15:06:38.970306 38966 net.cpp:124] Setting up conv10
I1011 15:06:38.970315 38966 net.cpp:131] Top shape: 1 130 88 88 (1006720)
I1011 15:06:38.970319 38966 net.cpp:139] Memory required for data: 135055392
I1011 15:06:38.970324 38966 layer_factory.hpp:77] Creating layer batch_norm10
I1011 15:06:38.970333 38966 net.cpp:86] Creating Layer batch_norm10
I1011 15:06:38.970340 38966 net.cpp:408] batch_norm10 <- conv10
I1011 15:06:38.970345 38966 net.cpp:369] batch_norm10 -> conv10 (in-place)
I1011 15:06:38.970541 38966 net.cpp:124] Setting up batch_norm10
I1011 15:06:38.970549 38966 net.cpp:131] Top shape: 1 130 88 88 (1006720)
I1011 15:06:38.970552 38966 net.cpp:139] Memory required for data: 139082272
I1011 15:06:38.970561 38966 layer_factory.hpp:77] Creating layer bn_scale10
I1011 15:06:38.970566 38966 net.cpp:86] Creating Layer bn_scale10
I1011 15:06:38.970571 38966 net.cpp:408] bn_scale10 <- conv10
I1011 15:06:38.970582 38966 net.cpp:369] bn_scale10 -> conv10 (in-place)
I1011 15:06:38.970630 38966 layer_factory.hpp:77] Creating layer bn_scale10
I1011 15:06:38.970753 38966 net.cpp:124] Setting up bn_scale10
I1011 15:06:38.970764 38966 net.cpp:131] Top shape: 1 130 88 88 (1006720)
I1011 15:06:38.970768 38966 net.cpp:139] Memory required for data: 143109152
I1011 15:06:38.970774 38966 layer_factory.hpp:77] Creating layer relu7
I1011 15:06:38.970780 38966 net.cpp:86] Creating Layer relu7
I1011 15:06:38.970784 38966 net.cpp:408] relu7 <- conv10
I1011 15:06:38.970789 38966 net.cpp:369] relu7 -> conv10 (in-place)
I1011 15:06:38.970795 38966 net.cpp:124] Setting up relu7
I1011 15:06:38.970800 38966 net.cpp:131] Top shape: 1 130 88 88 (1006720)
I1011 15:06:38.970803 38966 net.cpp:139] Memory required for data: 147136032
I1011 15:06:38.970808 38966 layer_factory.hpp:77] Creating layer conv11
I1011 15:06:38.970815 38966 net.cpp:86] Creating Layer conv11
I1011 15:06:38.970819 38966 net.cpp:408] conv11 <- conv10
I1011 15:06:38.970831 38966 net.cpp:382] conv11 -> conv11
I1011 15:06:38.971037 38966 net.cpp:124] Setting up conv11
I1011 15:06:38.971046 38966 net.cpp:131] Top shape: 1 130 44 44 (251680)
I1011 15:06:38.971050 38966 net.cpp:139] Memory required for data: 148142752
I1011 15:06:38.971055 38966 layer_factory.hpp:77] Creating layer batch_norm11
I1011 15:06:38.971061 38966 net.cpp:86] Creating Layer batch_norm11
I1011 15:06:38.971065 38966 net.cpp:408] batch_norm11 <- conv11
I1011 15:06:38.971071 38966 net.cpp:369] batch_norm11 -> conv11 (in-place)
I1011 15:06:38.971267 38966 net.cpp:124] Setting up batch_norm11
I1011 15:06:38.971276 38966 net.cpp:131] Top shape: 1 130 44 44 (251680)
I1011 15:06:38.971280 38966 net.cpp:139] Memory required for data: 149149472
I1011 15:06:38.971287 38966 layer_factory.hpp:77] Creating layer bn_scale11
I1011 15:06:38.971297 38966 net.cpp:86] Creating Layer bn_scale11
I1011 15:06:38.971300 38966 net.cpp:408] bn_scale11 <- conv11
I1011 15:06:38.971305 38966 net.cpp:369] bn_scale11 -> conv11 (in-place)
I1011 15:06:38.971343 38966 layer_factory.hpp:77] Creating layer bn_scale11
I1011 15:06:38.971459 38966 net.cpp:124] Setting up bn_scale11
I1011 15:06:38.971467 38966 net.cpp:131] Top shape: 1 130 44 44 (251680)
I1011 15:06:38.971472 38966 net.cpp:139] Memory required for data: 150156192
I1011 15:06:38.971487 38966 layer_factory.hpp:77] Creating layer relu8
I1011 15:06:38.971494 38966 net.cpp:86] Creating Layer relu8
I1011 15:06:38.971498 38966 net.cpp:408] relu8 <- conv11
I1011 15:06:38.971504 38966 net.cpp:369] relu8 -> conv11 (in-place)
I1011 15:06:38.971509 38966 net.cpp:124] Setting up relu8
I1011 15:06:38.971514 38966 net.cpp:131] Top shape: 1 130 44 44 (251680)
I1011 15:06:38.971518 38966 net.cpp:139] Memory required for data: 151162912
I1011 15:06:38.971521 38966 layer_factory.hpp:77] Creating layer conv12
I1011 15:06:38.971529 38966 net.cpp:86] Creating Layer conv12
I1011 15:06:38.971532 38966 net.cpp:408] conv12 <- conv11
I1011 15:06:38.971540 38966 net.cpp:382] conv12 -> conv12
I1011 15:06:38.971776 38966 net.cpp:124] Setting up conv12
I1011 15:06:38.971786 38966 net.cpp:131] Top shape: 1 32 44 44 (61952)
I1011 15:06:38.971789 38966 net.cpp:139] Memory required for data: 151410720
I1011 15:06:38.971794 38966 layer_factory.hpp:77] Creating layer batch_norm12
I1011 15:06:38.971802 38966 net.cpp:86] Creating Layer batch_norm12
I1011 15:06:38.971807 38966 net.cpp:408] batch_norm12 <- conv12
I1011 15:06:38.971812 38966 net.cpp:369] batch_norm12 -> conv12 (in-place)
I1011 15:06:38.972004 38966 net.cpp:124] Setting up batch_norm12
I1011 15:06:38.972013 38966 net.cpp:131] Top shape: 1 32 44 44 (61952)
I1011 15:06:38.972018 38966 net.cpp:139] Memory required for data: 151658528
I1011 15:06:38.972024 38966 layer_factory.hpp:77] Creating layer bn_scale12
I1011 15:06:38.972036 38966 net.cpp:86] Creating Layer bn_scale12
I1011 15:06:38.972041 38966 net.cpp:408] bn_scale12 <- conv12
I1011 15:06:38.972046 38966 net.cpp:369] bn_scale12 -> conv12 (in-place)
I1011 15:06:38.972084 38966 layer_factory.hpp:77] Creating layer bn_scale12
I1011 15:06:38.972204 38966 net.cpp:124] Setting up bn_scale12
I1011 15:06:38.972225 38966 net.cpp:131] Top shape: 1 32 44 44 (61952)
I1011 15:06:38.972229 38966 net.cpp:139] Memory required for data: 151906336
I1011 15:06:38.972236 38966 layer_factory.hpp:77] Creating layer conv12_bn_scale12_0_split
I1011 15:06:38.972242 38966 net.cpp:86] Creating Layer conv12_bn_scale12_0_split
I1011 15:06:38.972247 38966 net.cpp:408] conv12_bn_scale12_0_split <- conv12
I1011 15:06:38.972255 38966 net.cpp:382] conv12_bn_scale12_0_split -> conv12_bn_scale12_0_split_0
I1011 15:06:38.972263 38966 net.cpp:382] conv12_bn_scale12_0_split -> conv12_bn_scale12_0_split_1
I1011 15:06:38.972304 38966 net.cpp:124] Setting up conv12_bn_scale12_0_split
I1011 15:06:38.972312 38966 net.cpp:131] Top shape: 1 32 44 44 (61952)
I1011 15:06:38.972317 38966 net.cpp:131] Top shape: 1 32 44 44 (61952)
I1011 15:06:38.972321 38966 net.cpp:139] Memory required for data: 152401952
I1011 15:06:38.972324 38966 layer_factory.hpp:77] Creating layer conv13
I1011 15:06:38.972332 38966 net.cpp:86] Creating Layer conv13
I1011 15:06:38.972337 38966 net.cpp:408] conv13 <- conv12_bn_scale12_0_split_0
I1011 15:06:38.972343 38966 net.cpp:382] conv13 -> conv13
I1011 15:06:38.972590 38966 net.cpp:124] Setting up conv13
I1011 15:06:38.972599 38966 net.cpp:131] Top shape: 1 173 44 44 (334928)
I1011 15:06:38.972602 38966 net.cpp:139] Memory required for data: 153741664
I1011 15:06:38.972609 38966 layer_factory.hpp:77] Creating layer batch_norm13
I1011 15:06:38.972613 38966 net.cpp:86] Creating Layer batch_norm13
I1011 15:06:38.972617 38966 net.cpp:408] batch_norm13 <- conv13
I1011 15:06:38.972625 38966 net.cpp:369] batch_norm13 -> conv13 (in-place)
I1011 15:06:38.972818 38966 net.cpp:124] Setting up batch_norm13
I1011 15:06:38.972827 38966 net.cpp:131] Top shape: 1 173 44 44 (334928)
I1011 15:06:38.972831 38966 net.cpp:139] Memory required for data: 155081376
I1011 15:06:38.972838 38966 layer_factory.hpp:77] Creating layer bn_scale13
I1011 15:06:38.972844 38966 net.cpp:86] Creating Layer bn_scale13
I1011 15:06:38.972848 38966 net.cpp:408] bn_scale13 <- conv13
I1011 15:06:38.972853 38966 net.cpp:369] bn_scale13 -> conv13 (in-place)
I1011 15:06:38.972889 38966 layer_factory.hpp:77] Creating layer bn_scale13
I1011 15:06:38.973003 38966 net.cpp:124] Setting up bn_scale13
I1011 15:06:38.973011 38966 net.cpp:131] Top shape: 1 173 44 44 (334928)
I1011 15:06:38.973016 38966 net.cpp:139] Memory required for data: 156421088
I1011 15:06:38.973021 38966 layer_factory.hpp:77] Creating layer relu9
I1011 15:06:38.973027 38966 net.cpp:86] Creating Layer relu9
I1011 15:06:38.973031 38966 net.cpp:408] relu9 <- conv13
I1011 15:06:38.973038 38966 net.cpp:369] relu9 -> conv13 (in-place)
I1011 15:06:38.973044 38966 net.cpp:124] Setting up relu9
I1011 15:06:38.973048 38966 net.cpp:131] Top shape: 1 173 44 44 (334928)
I1011 15:06:38.973052 38966 net.cpp:139] Memory required for data: 157760800
I1011 15:06:38.973055 38966 layer_factory.hpp:77] Creating layer conv14
I1011 15:06:38.973064 38966 net.cpp:86] Creating Layer conv14
I1011 15:06:38.973068 38966 net.cpp:408] conv14 <- conv13
I1011 15:06:38.973074 38966 net.cpp:382] conv14 -> conv14
I1011 15:06:38.973292 38966 net.cpp:124] Setting up conv14
I1011 15:06:38.973302 38966 net.cpp:131] Top shape: 1 173 44 44 (334928)
I1011 15:06:38.973306 38966 net.cpp:139] Memory required for data: 159100512
I1011 15:06:38.973311 38966 layer_factory.hpp:77] Creating layer batch_norm14
I1011 15:06:38.973320 38966 net.cpp:86] Creating Layer batch_norm14
I1011 15:06:38.973323 38966 net.cpp:408] batch_norm14 <- conv14
I1011 15:06:38.973328 38966 net.cpp:369] batch_norm14 -> conv14 (in-place)
I1011 15:06:38.973534 38966 net.cpp:124] Setting up batch_norm14
I1011 15:06:38.973546 38966 net.cpp:131] Top shape: 1 173 44 44 (334928)
I1011 15:06:38.973549 38966 net.cpp:139] Memory required for data: 160440224
I1011 15:06:38.973557 38966 layer_factory.hpp:77] Creating layer bn_scale14
I1011 15:06:38.973563 38966 net.cpp:86] Creating Layer bn_scale14
I1011 15:06:38.973568 38966 net.cpp:408] bn_scale14 <- conv14
I1011 15:06:38.973587 38966 net.cpp:369] bn_scale14 -> conv14 (in-place)
I1011 15:06:38.973628 38966 layer_factory.hpp:77] Creating layer bn_scale14
I1011 15:06:38.973752 38966 net.cpp:124] Setting up bn_scale14
I1011 15:06:38.973762 38966 net.cpp:131] Top shape: 1 173 44 44 (334928)
I1011 15:06:38.973764 38966 net.cpp:139] Memory required for data: 161779936
I1011 15:06:38.973771 38966 layer_factory.hpp:77] Creating layer relu10
I1011 15:06:38.973778 38966 net.cpp:86] Creating Layer relu10
I1011 15:06:38.973781 38966 net.cpp:408] relu10 <- conv14
I1011 15:06:38.973790 38966 net.cpp:369] relu10 -> conv14 (in-place)
I1011 15:06:38.973796 38966 net.cpp:124] Setting up relu10
I1011 15:06:38.973801 38966 net.cpp:131] Top shape: 1 173 44 44 (334928)
I1011 15:06:38.973804 38966 net.cpp:139] Memory required for data: 163119648
I1011 15:06:38.973809 38966 layer_factory.hpp:77] Creating layer conv15
I1011 15:06:38.973819 38966 net.cpp:86] Creating Layer conv15
I1011 15:06:38.973824 38966 net.cpp:408] conv15 <- conv14
I1011 15:06:38.973829 38966 net.cpp:382] conv15 -> conv15
I1011 15:06:38.974076 38966 net.cpp:124] Setting up conv15
I1011 15:06:38.974086 38966 net.cpp:131] Top shape: 1 32 44 44 (61952)
I1011 15:06:38.974089 38966 net.cpp:139] Memory required for data: 163367456
I1011 15:06:38.974094 38966 layer_factory.hpp:77] Creating layer batch_norm15
I1011 15:06:38.974100 38966 net.cpp:86] Creating Layer batch_norm15
I1011 15:06:38.974105 38966 net.cpp:408] batch_norm15 <- conv15
I1011 15:06:38.974110 38966 net.cpp:369] batch_norm15 -> conv15 (in-place)
I1011 15:06:38.974308 38966 net.cpp:124] Setting up batch_norm15
I1011 15:06:38.974316 38966 net.cpp:131] Top shape: 1 32 44 44 (61952)
I1011 15:06:38.974320 38966 net.cpp:139] Memory required for data: 163615264
I1011 15:06:38.974328 38966 layer_factory.hpp:77] Creating layer bn_scale15
I1011 15:06:38.974334 38966 net.cpp:86] Creating Layer bn_scale15
I1011 15:06:38.974339 38966 net.cpp:408] bn_scale15 <- conv15
I1011 15:06:38.974344 38966 net.cpp:369] bn_scale15 -> conv15 (in-place)
I1011 15:06:38.974382 38966 layer_factory.hpp:77] Creating layer bn_scale15
I1011 15:06:38.974508 38966 net.cpp:124] Setting up bn_scale15
I1011 15:06:38.974516 38966 net.cpp:131] Top shape: 1 32 44 44 (61952)
I1011 15:06:38.974519 38966 net.cpp:139] Memory required for data: 163863072
I1011 15:06:38.974526 38966 layer_factory.hpp:77] Creating layer add2
I1011 15:06:38.974532 38966 net.cpp:86] Creating Layer add2
I1011 15:06:38.974536 38966 net.cpp:408] add2 <- conv12_bn_scale12_0_split_1
I1011 15:06:38.974541 38966 net.cpp:408] add2 <- conv15
I1011 15:06:38.974550 38966 net.cpp:382] add2 -> add2
I1011 15:06:38.974572 38966 net.cpp:124] Setting up add2
I1011 15:06:38.974581 38966 net.cpp:131] Top shape: 1 32 44 44 (61952)
I1011 15:06:38.974584 38966 net.cpp:139] Memory required for data: 164110880
I1011 15:06:38.974587 38966 layer_factory.hpp:77] Creating layer add2_add2_0_split
I1011 15:06:38.974596 38966 net.cpp:86] Creating Layer add2_add2_0_split
I1011 15:06:38.974601 38966 net.cpp:408] add2_add2_0_split <- add2
I1011 15:06:38.974606 38966 net.cpp:382] add2_add2_0_split -> add2_add2_0_split_0
I1011 15:06:38.974613 38966 net.cpp:382] add2_add2_0_split -> add2_add2_0_split_1
I1011 15:06:38.974649 38966 net.cpp:124] Setting up add2_add2_0_split
I1011 15:06:38.974658 38966 net.cpp:131] Top shape: 1 32 44 44 (61952)
I1011 15:06:38.974661 38966 net.cpp:131] Top shape: 1 32 44 44 (61952)
I1011 15:06:38.974665 38966 net.cpp:139] Memory required for data: 164606496
I1011 15:06:38.974669 38966 layer_factory.hpp:77] Creating layer conv16
I1011 15:06:38.974678 38966 net.cpp:86] Creating Layer conv16
I1011 15:06:38.974683 38966 net.cpp:408] conv16 <- add2_add2_0_split_0
I1011 15:06:38.974691 38966 net.cpp:382] conv16 -> conv16
I1011 15:06:38.974941 38966 net.cpp:124] Setting up conv16
I1011 15:06:38.974951 38966 net.cpp:131] Top shape: 1 173 44 44 (334928)
I1011 15:06:38.974954 38966 net.cpp:139] Memory required for data: 165946208
I1011 15:06:38.974959 38966 layer_factory.hpp:77] Creating layer batch_norm16
I1011 15:06:38.974980 38966 net.cpp:86] Creating Layer batch_norm16
I1011 15:06:38.974987 38966 net.cpp:408] batch_norm16 <- conv16
I1011 15:06:38.974992 38966 net.cpp:369] batch_norm16 -> conv16 (in-place)
I1011 15:06:38.975189 38966 net.cpp:124] Setting up batch_norm16
I1011 15:06:38.975198 38966 net.cpp:131] Top shape: 1 173 44 44 (334928)
I1011 15:06:38.975203 38966 net.cpp:139] Memory required for data: 167285920
I1011 15:06:38.975210 38966 layer_factory.hpp:77] Creating layer bn_scale16
I1011 15:06:38.975215 38966 net.cpp:86] Creating Layer bn_scale16
I1011 15:06:38.975220 38966 net.cpp:408] bn_scale16 <- conv16
I1011 15:06:38.975225 38966 net.cpp:369] bn_scale16 -> conv16 (in-place)
I1011 15:06:38.975275 38966 layer_factory.hpp:77] Creating layer bn_scale16
I1011 15:06:38.975409 38966 net.cpp:124] Setting up bn_scale16
I1011 15:06:38.975420 38966 net.cpp:131] Top shape: 1 173 44 44 (334928)
I1011 15:06:38.975425 38966 net.cpp:139] Memory required for data: 168625632
I1011 15:06:38.975430 38966 layer_factory.hpp:77] Creating layer relu11
I1011 15:06:38.975448 38966 net.cpp:86] Creating Layer relu11
I1011 15:06:38.975455 38966 net.cpp:408] relu11 <- conv16
I1011 15:06:38.975461 38966 net.cpp:369] relu11 -> conv16 (in-place)
I1011 15:06:38.975466 38966 net.cpp:124] Setting up relu11
I1011 15:06:38.975471 38966 net.cpp:131] Top shape: 1 173 44 44 (334928)
I1011 15:06:38.975476 38966 net.cpp:139] Memory required for data: 169965344
I1011 15:06:38.975479 38966 layer_factory.hpp:77] Creating layer conv17
I1011 15:06:38.975486 38966 net.cpp:86] Creating Layer conv17
I1011 15:06:38.975491 38966 net.cpp:408] conv17 <- conv16
I1011 15:06:38.975497 38966 net.cpp:382] conv17 -> conv17
I1011 15:06:38.975704 38966 net.cpp:124] Setting up conv17
I1011 15:06:38.975714 38966 net.cpp:131] Top shape: 1 173 44 44 (334928)
I1011 15:06:38.975718 38966 net.cpp:139] Memory required for data: 171305056
I1011 15:06:38.975723 38966 layer_factory.hpp:77] Creating layer batch_norm17
I1011 15:06:38.975735 38966 net.cpp:86] Creating Layer batch_norm17
I1011 15:06:38.975741 38966 net.cpp:408] batch_norm17 <- conv17
I1011 15:06:38.975746 38966 net.cpp:369] batch_norm17 -> conv17 (in-place)
I1011 15:06:38.975932 38966 net.cpp:124] Setting up batch_norm17
I1011 15:06:38.975941 38966 net.cpp:131] Top shape: 1 173 44 44 (334928)
I1011 15:06:38.975944 38966 net.cpp:139] Memory required for data: 172644768
I1011 15:06:38.975952 38966 layer_factory.hpp:77] Creating layer bn_scale17
I1011 15:06:38.975960 38966 net.cpp:86] Creating Layer bn_scale17
I1011 15:06:38.975965 38966 net.cpp:408] bn_scale17 <- conv17
I1011 15:06:38.975975 38966 net.cpp:369] bn_scale17 -> conv17 (in-place)
I1011 15:06:38.976009 38966 layer_factory.hpp:77] Creating layer bn_scale17
I1011 15:06:38.976130 38966 net.cpp:124] Setting up bn_scale17
I1011 15:06:38.976138 38966 net.cpp:131] Top shape: 1 173 44 44 (334928)
I1011 15:06:38.976142 38966 net.cpp:139] Memory required for data: 173984480
I1011 15:06:38.976150 38966 layer_factory.hpp:77] Creating layer relu12
I1011 15:06:38.976155 38966 net.cpp:86] Creating Layer relu12
I1011 15:06:38.976159 38966 net.cpp:408] relu12 <- conv17
I1011 15:06:38.976164 38966 net.cpp:369] relu12 -> conv17 (in-place)
I1011 15:06:38.976171 38966 net.cpp:124] Setting up relu12
I1011 15:06:38.976176 38966 net.cpp:131] Top shape: 1 173 44 44 (334928)
I1011 15:06:38.976179 38966 net.cpp:139] Memory required for data: 175324192
I1011 15:06:38.976182 38966 layer_factory.hpp:77] Creating layer conv18
I1011 15:06:38.976192 38966 net.cpp:86] Creating Layer conv18
I1011 15:06:38.976198 38966 net.cpp:408] conv18 <- conv17
I1011 15:06:38.976207 38966 net.cpp:382] conv18 -> conv18
I1011 15:06:38.976459 38966 net.cpp:124] Setting up conv18
I1011 15:06:38.976467 38966 net.cpp:131] Top shape: 1 32 44 44 (61952)
I1011 15:06:38.976471 38966 net.cpp:139] Memory required for data: 175572000
I1011 15:06:38.976476 38966 layer_factory.hpp:77] Creating layer batch_norm18
I1011 15:06:38.976483 38966 net.cpp:86] Creating Layer batch_norm18
I1011 15:06:38.976487 38966 net.cpp:408] batch_norm18 <- conv18
I1011 15:06:38.976505 38966 net.cpp:369] batch_norm18 -> conv18 (in-place)
I1011 15:06:38.976702 38966 net.cpp:124] Setting up batch_norm18
I1011 15:06:38.976711 38966 net.cpp:131] Top shape: 1 32 44 44 (61952)
I1011 15:06:38.976716 38966 net.cpp:139] Memory required for data: 175819808
I1011 15:06:38.976723 38966 layer_factory.hpp:77] Creating layer bn_scale18
I1011 15:06:38.976732 38966 net.cpp:86] Creating Layer bn_scale18
I1011 15:06:38.976737 38966 net.cpp:408] bn_scale18 <- conv18
I1011 15:06:38.976743 38966 net.cpp:369] bn_scale18 -> conv18 (in-place)
I1011 15:06:38.976780 38966 layer_factory.hpp:77] Creating layer bn_scale18
I1011 15:06:38.976902 38966 net.cpp:124] Setting up bn_scale18
I1011 15:06:38.976912 38966 net.cpp:131] Top shape: 1 32 44 44 (61952)
I1011 15:06:38.976915 38966 net.cpp:139] Memory required for data: 176067616
I1011 15:06:38.976922 38966 layer_factory.hpp:77] Creating layer add3
I1011 15:06:38.976931 38966 net.cpp:86] Creating Layer add3
I1011 15:06:38.976936 38966 net.cpp:408] add3 <- add2_add2_0_split_1
I1011 15:06:38.976941 38966 net.cpp:408] add3 <- conv18
I1011 15:06:38.976950 38966 net.cpp:382] add3 -> add3
I1011 15:06:38.976976 38966 net.cpp:124] Setting up add3
I1011 15:06:38.976984 38966 net.cpp:131] Top shape: 1 32 44 44 (61952)
I1011 15:06:38.976987 38966 net.cpp:139] Memory required for data: 176315424
I1011 15:06:38.976991 38966 layer_factory.hpp:77] Creating layer conv19
I1011 15:06:38.977001 38966 net.cpp:86] Creating Layer conv19
I1011 15:06:38.977008 38966 net.cpp:408] conv19 <- add3
I1011 15:06:38.977015 38966 net.cpp:382] conv19 -> conv19
I1011 15:06:38.977265 38966 net.cpp:124] Setting up conv19
I1011 15:06:38.977274 38966 net.cpp:131] Top shape: 1 173 44 44 (334928)
I1011 15:06:38.977278 38966 net.cpp:139] Memory required for data: 177655136
I1011 15:06:38.977283 38966 layer_factory.hpp:77] Creating layer batch_norm19
I1011 15:06:38.977289 38966 net.cpp:86] Creating Layer batch_norm19
I1011 15:06:38.977293 38966 net.cpp:408] batch_norm19 <- conv19
I1011 15:06:38.977299 38966 net.cpp:369] batch_norm19 -> conv19 (in-place)
I1011 15:06:38.977490 38966 net.cpp:124] Setting up batch_norm19
I1011 15:06:38.977499 38966 net.cpp:131] Top shape: 1 173 44 44 (334928)
I1011 15:06:38.977504 38966 net.cpp:139] Memory required for data: 178994848
I1011 15:06:38.977510 38966 layer_factory.hpp:77] Creating layer bn_scale19
I1011 15:06:38.977519 38966 net.cpp:86] Creating Layer bn_scale19
I1011 15:06:38.977525 38966 net.cpp:408] bn_scale19 <- conv19
I1011 15:06:38.977531 38966 net.cpp:369] bn_scale19 -> conv19 (in-place)
I1011 15:06:38.977567 38966 layer_factory.hpp:77] Creating layer bn_scale19
I1011 15:06:38.977686 38966 net.cpp:124] Setting up bn_scale19
I1011 15:06:38.977695 38966 net.cpp:131] Top shape: 1 173 44 44 (334928)
I1011 15:06:38.977699 38966 net.cpp:139] Memory required for data: 180334560
I1011 15:06:38.977705 38966 layer_factory.hpp:77] Creating layer relu13
I1011 15:06:38.977715 38966 net.cpp:86] Creating Layer relu13
I1011 15:06:38.977720 38966 net.cpp:408] relu13 <- conv19
I1011 15:06:38.977725 38966 net.cpp:369] relu13 -> conv19 (in-place)
I1011 15:06:38.977731 38966 net.cpp:124] Setting up relu13
I1011 15:06:38.977736 38966 net.cpp:131] Top shape: 1 173 44 44 (334928)
I1011 15:06:38.977739 38966 net.cpp:139] Memory required for data: 181674272
I1011 15:06:38.977743 38966 layer_factory.hpp:77] Creating layer conv20
I1011 15:06:38.977752 38966 net.cpp:86] Creating Layer conv20
I1011 15:06:38.977756 38966 net.cpp:408] conv20 <- conv19
I1011 15:06:38.977764 38966 net.cpp:382] conv20 -> conv20
I1011 15:06:38.977968 38966 net.cpp:124] Setting up conv20
I1011 15:06:38.977978 38966 net.cpp:131] Top shape: 1 173 22 22 (83732)
I1011 15:06:38.977982 38966 net.cpp:139] Memory required for data: 182009200
I1011 15:06:38.977988 38966 layer_factory.hpp:77] Creating layer batch_norm20
I1011 15:06:38.977994 38966 net.cpp:86] Creating Layer batch_norm20
I1011 15:06:38.977998 38966 net.cpp:408] batch_norm20 <- conv20
I1011 15:06:38.978006 38966 net.cpp:369] batch_norm20 -> conv20 (in-place)
I1011 15:06:38.978212 38966 net.cpp:124] Setting up batch_norm20
I1011 15:06:38.978221 38966 net.cpp:131] Top shape: 1 173 22 22 (83732)
I1011 15:06:38.978225 38966 net.cpp:139] Memory required for data: 182344128
I1011 15:06:38.978233 38966 layer_factory.hpp:77] Creating layer bn_scale20
I1011 15:06:38.978242 38966 net.cpp:86] Creating Layer bn_scale20
I1011 15:06:38.978246 38966 net.cpp:408] bn_scale20 <- conv20
I1011 15:06:38.978252 38966 net.cpp:369] bn_scale20 -> conv20 (in-place)
I1011 15:06:38.978289 38966 layer_factory.hpp:77] Creating layer bn_scale20
I1011 15:06:38.978408 38966 net.cpp:124] Setting up bn_scale20
I1011 15:06:38.978417 38966 net.cpp:131] Top shape: 1 173 22 22 (83732)
I1011 15:06:38.978421 38966 net.cpp:139] Memory required for data: 182679056
I1011 15:06:38.978428 38966 layer_factory.hpp:77] Creating layer relu14
I1011 15:06:38.978436 38966 net.cpp:86] Creating Layer relu14
I1011 15:06:38.978442 38966 net.cpp:408] relu14 <- conv20
I1011 15:06:38.978448 38966 net.cpp:369] relu14 -> conv20 (in-place)
I1011 15:06:38.978454 38966 net.cpp:124] Setting up relu14
I1011 15:06:38.978459 38966 net.cpp:131] Top shape: 1 173 22 22 (83732)
I1011 15:06:38.978463 38966 net.cpp:139] Memory required for data: 183013984
I1011 15:06:38.978466 38966 layer_factory.hpp:77] Creating layer conv21
I1011 15:06:38.978477 38966 net.cpp:86] Creating Layer conv21
I1011 15:06:38.978483 38966 net.cpp:408] conv21 <- conv20
I1011 15:06:38.978492 38966 net.cpp:382] conv21 -> conv21
I1011 15:06:38.978812 38966 net.cpp:124] Setting up conv21
I1011 15:06:38.978822 38966 net.cpp:131] Top shape: 1 64 22 22 (30976)
I1011 15:06:38.978826 38966 net.cpp:139] Memory required for data: 183137888
I1011 15:06:38.978832 38966 layer_factory.hpp:77] Creating layer batch_norm21
I1011 15:06:38.978839 38966 net.cpp:86] Creating Layer batch_norm21
I1011 15:06:38.978843 38966 net.cpp:408] batch_norm21 <- conv21
I1011 15:06:38.978848 38966 net.cpp:369] batch_norm21 -> conv21 (in-place)
I1011 15:06:38.979038 38966 net.cpp:124] Setting up batch_norm21
I1011 15:06:38.979048 38966 net.cpp:131] Top shape: 1 64 22 22 (30976)
I1011 15:06:38.979051 38966 net.cpp:139] Memory required for data: 183261792
I1011 15:06:38.979058 38966 layer_factory.hpp:77] Creating layer bn_scale21
I1011 15:06:38.979068 38966 net.cpp:86] Creating Layer bn_scale21
I1011 15:06:38.979071 38966 net.cpp:408] bn_scale21 <- conv21
I1011 15:06:38.979077 38966 net.cpp:369] bn_scale21 -> conv21 (in-place)
I1011 15:06:38.979115 38966 layer_factory.hpp:77] Creating layer bn_scale21
I1011 15:06:38.979230 38966 net.cpp:124] Setting up bn_scale21
I1011 15:06:38.979239 38966 net.cpp:131] Top shape: 1 64 22 22 (30976)
I1011 15:06:38.979243 38966 net.cpp:139] Memory required for data: 183385696
I1011 15:06:38.979255 38966 layer_factory.hpp:77] Creating layer conv21_bn_scale21_0_split
I1011 15:06:38.979262 38966 net.cpp:86] Creating Layer conv21_bn_scale21_0_split
I1011 15:06:38.979266 38966 net.cpp:408] conv21_bn_scale21_0_split <- conv21
I1011 15:06:38.979275 38966 net.cpp:382] conv21_bn_scale21_0_split -> conv21_bn_scale21_0_split_0
I1011 15:06:38.979290 38966 net.cpp:382] conv21_bn_scale21_0_split -> conv21_bn_scale21_0_split_1
I1011 15:06:38.979328 38966 net.cpp:124] Setting up conv21_bn_scale21_0_split
I1011 15:06:38.979336 38966 net.cpp:131] Top shape: 1 64 22 22 (30976)
I1011 15:06:38.979341 38966 net.cpp:131] Top shape: 1 64 22 22 (30976)
I1011 15:06:38.979344 38966 net.cpp:139] Memory required for data: 183633504
I1011 15:06:38.979348 38966 layer_factory.hpp:77] Creating layer conv22
I1011 15:06:38.979363 38966 net.cpp:86] Creating Layer conv22
I1011 15:06:38.979369 38966 net.cpp:408] conv22 <- conv21_bn_scale21_0_split_0
I1011 15:06:38.979377 38966 net.cpp:382] conv22 -> conv22
I1011 15:06:38.979821 38966 net.cpp:124] Setting up conv22
I1011 15:06:38.979831 38966 net.cpp:131] Top shape: 1 346 22 22 (167464)
I1011 15:06:38.979835 38966 net.cpp:139] Memory required for data: 184303360
I1011 15:06:38.979841 38966 layer_factory.hpp:77] Creating layer batch_norm22
I1011 15:06:38.979866 38966 net.cpp:86] Creating Layer batch_norm22
I1011 15:06:38.979871 38966 net.cpp:408] batch_norm22 <- conv22
I1011 15:06:38.979877 38966 net.cpp:369] batch_norm22 -> conv22 (in-place)
I1011 15:06:38.980069 38966 net.cpp:124] Setting up batch_norm22
I1011 15:06:38.980077 38966 net.cpp:131] Top shape: 1 346 22 22 (167464)
I1011 15:06:38.980082 38966 net.cpp:139] Memory required for data: 184973216
I1011 15:06:38.980101 38966 layer_factory.hpp:77] Creating layer bn_scale22
I1011 15:06:38.980110 38966 net.cpp:86] Creating Layer bn_scale22
I1011 15:06:38.980114 38966 net.cpp:408] bn_scale22 <- conv22
I1011 15:06:38.980123 38966 net.cpp:369] bn_scale22 -> conv22 (in-place)
I1011 15:06:38.980160 38966 layer_factory.hpp:77] Creating layer bn_scale22
I1011 15:06:38.980278 38966 net.cpp:124] Setting up bn_scale22
I1011 15:06:38.980289 38966 net.cpp:131] Top shape: 1 346 22 22 (167464)
I1011 15:06:38.980293 38966 net.cpp:139] Memory required for data: 185643072
I1011 15:06:38.980300 38966 layer_factory.hpp:77] Creating layer relu15
I1011 15:06:38.980310 38966 net.cpp:86] Creating Layer relu15
I1011 15:06:38.980317 38966 net.cpp:408] relu15 <- conv22
I1011 15:06:38.980332 38966 net.cpp:369] relu15 -> conv22 (in-place)
I1011 15:06:38.980345 38966 net.cpp:124] Setting up relu15
I1011 15:06:38.980355 38966 net.cpp:131] Top shape: 1 346 22 22 (167464)
I1011 15:06:38.980370 38966 net.cpp:139] Memory required for data: 186312928
I1011 15:06:38.980377 38966 layer_factory.hpp:77] Creating layer conv23
I1011 15:06:38.980391 38966 net.cpp:86] Creating Layer conv23
I1011 15:06:38.980398 38966 net.cpp:408] conv23 <- conv22
I1011 15:06:38.980415 38966 net.cpp:382] conv23 -> conv23
I1011 15:06:38.980861 38966 net.cpp:124] Setting up conv23
I1011 15:06:38.980885 38966 net.cpp:131] Top shape: 1 346 22 22 (167464)
I1011 15:06:38.980892 38966 net.cpp:139] Memory required for data: 186982784
I1011 15:06:38.980903 38966 layer_factory.hpp:77] Creating layer batch_norm23
I1011 15:06:38.980919 38966 net.cpp:86] Creating Layer batch_norm23
I1011 15:06:38.980927 38966 net.cpp:408] batch_norm23 <- conv23
I1011 15:06:38.980938 38966 net.cpp:369] batch_norm23 -> conv23 (in-place)
I1011 15:06:38.981309 38966 net.cpp:124] Setting up batch_norm23
I1011 15:06:38.981323 38966 net.cpp:131] Top shape: 1 346 22 22 (167464)
I1011 15:06:38.981328 38966 net.cpp:139] Memory required for data: 187652640
I1011 15:06:38.981340 38966 layer_factory.hpp:77] Creating layer bn_scale23
I1011 15:06:38.981350 38966 net.cpp:86] Creating Layer bn_scale23
I1011 15:06:38.981356 38966 net.cpp:408] bn_scale23 <- conv23
I1011 15:06:38.981372 38966 net.cpp:369] bn_scale23 -> conv23 (in-place)
I1011 15:06:38.981427 38966 layer_factory.hpp:77] Creating layer bn_scale23
I1011 15:06:38.981583 38966 net.cpp:124] Setting up bn_scale23
I1011 15:06:38.981600 38966 net.cpp:131] Top shape: 1 346 22 22 (167464)
I1011 15:06:38.981606 38966 net.cpp:139] Memory required for data: 188322496
I1011 15:06:38.981618 38966 layer_factory.hpp:77] Creating layer relu16
I1011 15:06:38.981629 38966 net.cpp:86] Creating Layer relu16
I1011 15:06:38.981637 38966 net.cpp:408] relu16 <- conv23
I1011 15:06:38.981647 38966 net.cpp:369] relu16 -> conv23 (in-place)
I1011 15:06:38.981657 38966 net.cpp:124] Setting up relu16
I1011 15:06:38.981683 38966 net.cpp:131] Top shape: 1 346 22 22 (167464)
I1011 15:06:38.981690 38966 net.cpp:139] Memory required for data: 188992352
I1011 15:06:38.981698 38966 layer_factory.hpp:77] Creating layer conv24
I1011 15:06:38.981714 38966 net.cpp:86] Creating Layer conv24
I1011 15:06:38.981734 38966 net.cpp:408] conv24 <- conv23
I1011 15:06:38.981750 38966 net.cpp:382] conv24 -> conv24
I1011 15:06:38.982224 38966 net.cpp:124] Setting up conv24
I1011 15:06:38.982239 38966 net.cpp:131] Top shape: 1 64 22 22 (30976)
I1011 15:06:38.982244 38966 net.cpp:139] Memory required for data: 189116256
I1011 15:06:38.982254 38966 layer_factory.hpp:77] Creating layer batch_norm24
I1011 15:06:38.982268 38966 net.cpp:86] Creating Layer batch_norm24
I1011 15:06:38.982275 38966 net.cpp:408] batch_norm24 <- conv24
I1011 15:06:38.982295 38966 net.cpp:369] batch_norm24 -> conv24 (in-place)
I1011 15:06:38.982568 38966 net.cpp:124] Setting up batch_norm24
I1011 15:06:38.982580 38966 net.cpp:131] Top shape: 1 64 22 22 (30976)
I1011 15:06:38.982587 38966 net.cpp:139] Memory required for data: 189240160
I1011 15:06:38.982601 38966 layer_factory.hpp:77] Creating layer bn_scale24
I1011 15:06:38.982625 38966 net.cpp:86] Creating Layer bn_scale24
I1011 15:06:38.982640 38966 net.cpp:408] bn_scale24 <- conv24
I1011 15:06:38.982651 38966 net.cpp:369] bn_scale24 -> conv24 (in-place)
I1011 15:06:38.982707 38966 layer_factory.hpp:77] Creating layer bn_scale24
I1011 15:06:38.982865 38966 net.cpp:124] Setting up bn_scale24
I1011 15:06:38.982879 38966 net.cpp:131] Top shape: 1 64 22 22 (30976)
I1011 15:06:38.982885 38966 net.cpp:139] Memory required for data: 189364064
I1011 15:06:38.982897 38966 layer_factory.hpp:77] Creating layer add4
I1011 15:06:38.982913 38966 net.cpp:86] Creating Layer add4
I1011 15:06:38.982923 38966 net.cpp:408] add4 <- conv21_bn_scale21_0_split_1
I1011 15:06:38.982931 38966 net.cpp:408] add4 <- conv24
I1011 15:06:38.982941 38966 net.cpp:382] add4 -> add4
I1011 15:06:38.982981 38966 net.cpp:124] Setting up add4
I1011 15:06:38.982993 38966 net.cpp:131] Top shape: 1 64 22 22 (30976)
I1011 15:06:38.983000 38966 net.cpp:139] Memory required for data: 189487968
I1011 15:06:38.983006 38966 layer_factory.hpp:77] Creating layer add4_add4_0_split
I1011 15:06:38.983016 38966 net.cpp:86] Creating Layer add4_add4_0_split
I1011 15:06:38.983024 38966 net.cpp:408] add4_add4_0_split <- add4
I1011 15:06:38.983036 38966 net.cpp:382] add4_add4_0_split -> add4_add4_0_split_0
I1011 15:06:38.983048 38966 net.cpp:382] add4_add4_0_split -> add4_add4_0_split_1
I1011 15:06:38.983099 38966 net.cpp:124] Setting up add4_add4_0_split
I1011 15:06:38.983110 38966 net.cpp:131] Top shape: 1 64 22 22 (30976)
I1011 15:06:38.983119 38966 net.cpp:131] Top shape: 1 64 22 22 (30976)
I1011 15:06:38.983124 38966 net.cpp:139] Memory required for data: 189735776
I1011 15:06:38.983131 38966 layer_factory.hpp:77] Creating layer conv25
I1011 15:06:38.983146 38966 net.cpp:86] Creating Layer conv25
I1011 15:06:38.983155 38966 net.cpp:408] conv25 <- add4_add4_0_split_0
I1011 15:06:38.983167 38966 net.cpp:382] conv25 -> conv25
I1011 15:06:38.983878 38966 net.cpp:124] Setting up conv25
I1011 15:06:38.983911 38966 net.cpp:131] Top shape: 1 327 22 22 (158268)
I1011 15:06:38.983919 38966 net.cpp:139] Memory required for data: 190368848
I1011 15:06:38.983930 38966 layer_factory.hpp:77] Creating layer batch_norm25
I1011 15:06:38.983943 38966 net.cpp:86] Creating Layer batch_norm25
I1011 15:06:38.983952 38966 net.cpp:408] batch_norm25 <- conv25
I1011 15:06:38.983973 38966 net.cpp:369] batch_norm25 -> conv25 (in-place)
I1011 15:06:38.984364 38966 net.cpp:124] Setting up batch_norm25
I1011 15:06:38.984376 38966 net.cpp:131] Top shape: 1 327 22 22 (158268)
I1011 15:06:38.984385 38966 net.cpp:139] Memory required for data: 191001920
I1011 15:06:38.984400 38966 layer_factory.hpp:77] Creating layer bn_scale25
I1011 15:06:38.984411 38966 net.cpp:86] Creating Layer bn_scale25
I1011 15:06:38.984417 38966 net.cpp:408] bn_scale25 <- conv25
I1011 15:06:38.984423 38966 net.cpp:369] bn_scale25 -> conv25 (in-place)
I1011 15:06:38.984464 38966 layer_factory.hpp:77] Creating layer bn_scale25
I1011 15:06:38.984581 38966 net.cpp:124] Setting up bn_scale25
I1011 15:06:38.984588 38966 net.cpp:131] Top shape: 1 327 22 22 (158268)
I1011 15:06:38.984592 38966 net.cpp:139] Memory required for data: 191634992
I1011 15:06:38.984599 38966 layer_factory.hpp:77] Creating layer relu17
I1011 15:06:38.984604 38966 net.cpp:86] Creating Layer relu17
I1011 15:06:38.984608 38966 net.cpp:408] relu17 <- conv25
I1011 15:06:38.984616 38966 net.cpp:369] relu17 -> conv25 (in-place)
I1011 15:06:38.984622 38966 net.cpp:124] Setting up relu17
I1011 15:06:38.984627 38966 net.cpp:131] Top shape: 1 327 22 22 (158268)
I1011 15:06:38.984630 38966 net.cpp:139] Memory required for data: 192268064
I1011 15:06:38.984647 38966 layer_factory.hpp:77] Creating layer conv26
I1011 15:06:38.984654 38966 net.cpp:86] Creating Layer conv26
I1011 15:06:38.984658 38966 net.cpp:408] conv26 <- conv25
I1011 15:06:38.984668 38966 net.cpp:382] conv26 -> conv26
I1011 15:06:38.984899 38966 net.cpp:124] Setting up conv26
I1011 15:06:38.984905 38966 net.cpp:131] Top shape: 1 327 22 22 (158268)
I1011 15:06:38.984908 38966 net.cpp:139] Memory required for data: 192901136
I1011 15:06:38.984913 38966 layer_factory.hpp:77] Creating layer batch_norm26
I1011 15:06:38.984921 38966 net.cpp:86] Creating Layer batch_norm26
I1011 15:06:38.984925 38966 net.cpp:408] batch_norm26 <- conv26
I1011 15:06:38.984930 38966 net.cpp:369] batch_norm26 -> conv26 (in-place)
I1011 15:06:38.985095 38966 net.cpp:124] Setting up batch_norm26
I1011 15:06:38.985101 38966 net.cpp:131] Top shape: 1 327 22 22 (158268)
I1011 15:06:38.985105 38966 net.cpp:139] Memory required for data: 193534208
I1011 15:06:38.985111 38966 layer_factory.hpp:77] Creating layer bn_scale26
I1011 15:06:38.985116 38966 net.cpp:86] Creating Layer bn_scale26
I1011 15:06:38.985121 38966 net.cpp:408] bn_scale26 <- conv26
I1011 15:06:38.985127 38966 net.cpp:369] bn_scale26 -> conv26 (in-place)
I1011 15:06:38.985443 38966 layer_factory.hpp:77] Creating layer bn_scale26
I1011 15:06:38.985651 38966 net.cpp:124] Setting up bn_scale26
I1011 15:06:38.985672 38966 net.cpp:131] Top shape: 1 327 22 22 (158268)
I1011 15:06:38.985680 38966 net.cpp:139] Memory required for data: 194167280
I1011 15:06:38.985692 38966 layer_factory.hpp:77] Creating layer relu18
I1011 15:06:38.985702 38966 net.cpp:86] Creating Layer relu18
I1011 15:06:38.985708 38966 net.cpp:408] relu18 <- conv26
I1011 15:06:38.985723 38966 net.cpp:369] relu18 -> conv26 (in-place)
I1011 15:06:38.985734 38966 net.cpp:124] Setting up relu18
I1011 15:06:38.985743 38966 net.cpp:131] Top shape: 1 327 22 22 (158268)
I1011 15:06:38.985749 38966 net.cpp:139] Memory required for data: 194800352
I1011 15:06:38.985756 38966 layer_factory.hpp:77] Creating layer conv27
I1011 15:06:38.985769 38966 net.cpp:86] Creating Layer conv27
I1011 15:06:38.985776 38966 net.cpp:408] conv27 <- conv26
I1011 15:06:38.985790 38966 net.cpp:382] conv27 -> conv27
I1011 15:06:38.986279 38966 net.cpp:124] Setting up conv27
I1011 15:06:38.986291 38966 net.cpp:131] Top shape: 1 64 22 22 (30976)
I1011 15:06:38.986297 38966 net.cpp:139] Memory required for data: 194924256
I1011 15:06:38.986305 38966 layer_factory.hpp:77] Creating layer batch_norm27
I1011 15:06:38.986315 38966 net.cpp:86] Creating Layer batch_norm27
I1011 15:06:38.986321 38966 net.cpp:408] batch_norm27 <- conv27
I1011 15:06:38.986330 38966 net.cpp:369] batch_norm27 -> conv27 (in-place)
I1011 15:06:38.986521 38966 net.cpp:124] Setting up batch_norm27
I1011 15:06:38.986532 38966 net.cpp:131] Top shape: 1 64 22 22 (30976)
I1011 15:06:38.986537 38966 net.cpp:139] Memory required for data: 195048160
I1011 15:06:38.986549 38966 layer_factory.hpp:77] Creating layer bn_scale27
I1011 15:06:38.986564 38966 net.cpp:86] Creating Layer bn_scale27
I1011 15:06:38.986573 38966 net.cpp:408] bn_scale27 <- conv27
I1011 15:06:38.986582 38966 net.cpp:369] bn_scale27 -> conv27 (in-place)
I1011 15:06:38.986630 38966 layer_factory.hpp:77] Creating layer bn_scale27
I1011 15:06:38.986750 38966 net.cpp:124] Setting up bn_scale27
I1011 15:06:38.986762 38966 net.cpp:131] Top shape: 1 64 22 22 (30976)
I1011 15:06:38.986768 38966 net.cpp:139] Memory required for data: 195172064
I1011 15:06:38.986776 38966 layer_factory.hpp:77] Creating layer add5
I1011 15:06:38.986789 38966 net.cpp:86] Creating Layer add5
I1011 15:06:38.986799 38966 net.cpp:408] add5 <- add4_add4_0_split_1
I1011 15:06:38.986805 38966 net.cpp:408] add5 <- conv27
I1011 15:06:38.986814 38966 net.cpp:382] add5 -> add5
I1011 15:06:38.986848 38966 net.cpp:124] Setting up add5
I1011 15:06:38.986858 38966 net.cpp:131] Top shape: 1 64 22 22 (30976)
I1011 15:06:38.986865 38966 net.cpp:139] Memory required for data: 195295968
I1011 15:06:38.986871 38966 layer_factory.hpp:77] Creating layer add5_add5_0_split
I1011 15:06:38.986891 38966 net.cpp:86] Creating Layer add5_add5_0_split
I1011 15:06:38.986901 38966 net.cpp:408] add5_add5_0_split <- add5
I1011 15:06:38.986915 38966 net.cpp:382] add5_add5_0_split -> add5_add5_0_split_0
I1011 15:06:38.986928 38966 net.cpp:382] add5_add5_0_split -> add5_add5_0_split_1
I1011 15:06:38.986974 38966 net.cpp:124] Setting up add5_add5_0_split
I1011 15:06:38.986985 38966 net.cpp:131] Top shape: 1 64 22 22 (30976)
I1011 15:06:38.986992 38966 net.cpp:131] Top shape: 1 64 22 22 (30976)
I1011 15:06:38.986997 38966 net.cpp:139] Memory required for data: 195543776
I1011 15:06:38.987002 38966 layer_factory.hpp:77] Creating layer conv28
I1011 15:06:38.987012 38966 net.cpp:86] Creating Layer conv28
I1011 15:06:38.987017 38966 net.cpp:408] conv28 <- add5_add5_0_split_0
I1011 15:06:38.987027 38966 net.cpp:382] conv28 -> conv28
I1011 15:06:38.987440 38966 net.cpp:124] Setting up conv28
I1011 15:06:38.987453 38966 net.cpp:131] Top shape: 1 327 22 22 (158268)
I1011 15:06:38.987459 38966 net.cpp:139] Memory required for data: 196176848
I1011 15:06:38.987468 38966 layer_factory.hpp:77] Creating layer batch_norm28
I1011 15:06:38.987476 38966 net.cpp:86] Creating Layer batch_norm28
I1011 15:06:38.987485 38966 net.cpp:408] batch_norm28 <- conv28
I1011 15:06:38.987498 38966 net.cpp:369] batch_norm28 -> conv28 (in-place)
I1011 15:06:38.987694 38966 net.cpp:124] Setting up batch_norm28
I1011 15:06:38.987706 38966 net.cpp:131] Top shape: 1 327 22 22 (158268)
I1011 15:06:38.987711 38966 net.cpp:139] Memory required for data: 196809920
I1011 15:06:38.987723 38966 layer_factory.hpp:77] Creating layer bn_scale28
I1011 15:06:38.987732 38966 net.cpp:86] Creating Layer bn_scale28
I1011 15:06:38.987740 38966 net.cpp:408] bn_scale28 <- conv28
I1011 15:06:38.987748 38966 net.cpp:369] bn_scale28 -> conv28 (in-place)
I1011 15:06:38.987792 38966 layer_factory.hpp:77] Creating layer bn_scale28
I1011 15:06:38.987903 38966 net.cpp:124] Setting up bn_scale28
I1011 15:06:38.987915 38966 net.cpp:131] Top shape: 1 327 22 22 (158268)
I1011 15:06:38.987920 38966 net.cpp:139] Memory required for data: 197442992
I1011 15:06:38.987929 38966 layer_factory.hpp:77] Creating layer relu19
I1011 15:06:38.987939 38966 net.cpp:86] Creating Layer relu19
I1011 15:06:38.987946 38966 net.cpp:408] relu19 <- conv28
I1011 15:06:38.987958 38966 net.cpp:369] relu19 -> conv28 (in-place)
I1011 15:06:38.987969 38966 net.cpp:124] Setting up relu19
I1011 15:06:38.987979 38966 net.cpp:131] Top shape: 1 327 22 22 (158268)
I1011 15:06:38.987987 38966 net.cpp:139] Memory required for data: 198076064
I1011 15:06:38.987991 38966 layer_factory.hpp:77] Creating layer conv29
I1011 15:06:38.988010 38966 net.cpp:86] Creating Layer conv29
I1011 15:06:38.988018 38966 net.cpp:408] conv29 <- conv28
I1011 15:06:38.988027 38966 net.cpp:382] conv29 -> conv29
I1011 15:06:38.988236 38966 net.cpp:124] Setting up conv29
I1011 15:06:38.988248 38966 net.cpp:131] Top shape: 1 327 22 22 (158268)
I1011 15:06:38.988253 38966 net.cpp:139] Memory required for data: 198709136
I1011 15:06:38.988261 38966 layer_factory.hpp:77] Creating layer batch_norm29
I1011 15:06:38.988276 38966 net.cpp:86] Creating Layer batch_norm29
I1011 15:06:38.988284 38966 net.cpp:408] batch_norm29 <- conv29
I1011 15:06:38.988293 38966 net.cpp:369] batch_norm29 -> conv29 (in-place)
I1011 15:06:38.988478 38966 net.cpp:124] Setting up batch_norm29
I1011 15:06:38.988503 38966 net.cpp:131] Top shape: 1 327 22 22 (158268)
I1011 15:06:38.988510 38966 net.cpp:139] Memory required for data: 199342208
I1011 15:06:38.988524 38966 layer_factory.hpp:77] Creating layer bn_scale29
I1011 15:06:38.988534 38966 net.cpp:86] Creating Layer bn_scale29
I1011 15:06:38.988543 38966 net.cpp:408] bn_scale29 <- conv29
I1011 15:06:38.988556 38966 net.cpp:369] bn_scale29 -> conv29 (in-place)
I1011 15:06:38.988620 38966 layer_factory.hpp:77] Creating layer bn_scale29
I1011 15:06:38.988821 38966 net.cpp:124] Setting up bn_scale29
I1011 15:06:38.988834 38966 net.cpp:131] Top shape: 1 327 22 22 (158268)
I1011 15:06:38.988840 38966 net.cpp:139] Memory required for data: 199975280
I1011 15:06:38.988873 38966 layer_factory.hpp:77] Creating layer relu20
I1011 15:06:38.988883 38966 net.cpp:86] Creating Layer relu20
I1011 15:06:38.988890 38966 net.cpp:408] relu20 <- conv29
I1011 15:06:38.988909 38966 net.cpp:369] relu20 -> conv29 (in-place)
I1011 15:06:38.988920 38966 net.cpp:124] Setting up relu20
I1011 15:06:38.988929 38966 net.cpp:131] Top shape: 1 327 22 22 (158268)
I1011 15:06:38.988935 38966 net.cpp:139] Memory required for data: 200608352
I1011 15:06:38.988942 38966 layer_factory.hpp:77] Creating layer conv30
I1011 15:06:38.988958 38966 net.cpp:86] Creating Layer conv30
I1011 15:06:38.988965 38966 net.cpp:408] conv30 <- conv29
I1011 15:06:38.988977 38966 net.cpp:382] conv30 -> conv30
I1011 15:06:38.989552 38966 net.cpp:124] Setting up conv30
I1011 15:06:38.989564 38966 net.cpp:131] Top shape: 1 64 22 22 (30976)
I1011 15:06:38.989569 38966 net.cpp:139] Memory required for data: 200732256
I1011 15:06:38.989578 38966 layer_factory.hpp:77] Creating layer batch_norm30
I1011 15:06:38.989586 38966 net.cpp:86] Creating Layer batch_norm30
I1011 15:06:38.989593 38966 net.cpp:408] batch_norm30 <- conv30
I1011 15:06:38.989601 38966 net.cpp:369] batch_norm30 -> conv30 (in-place)
I1011 15:06:38.989789 38966 net.cpp:124] Setting up batch_norm30
I1011 15:06:38.989799 38966 net.cpp:131] Top shape: 1 64 22 22 (30976)
I1011 15:06:38.989804 38966 net.cpp:139] Memory required for data: 200856160
I1011 15:06:38.989816 38966 layer_factory.hpp:77] Creating layer bn_scale30
I1011 15:06:38.989827 38966 net.cpp:86] Creating Layer bn_scale30
I1011 15:06:38.989835 38966 net.cpp:408] bn_scale30 <- conv30
I1011 15:06:38.989842 38966 net.cpp:369] bn_scale30 -> conv30 (in-place)
I1011 15:06:38.989889 38966 layer_factory.hpp:77] Creating layer bn_scale30
I1011 15:06:38.990010 38966 net.cpp:124] Setting up bn_scale30
I1011 15:06:38.990021 38966 net.cpp:131] Top shape: 1 64 22 22 (30976)
I1011 15:06:38.990026 38966 net.cpp:139] Memory required for data: 200980064
I1011 15:06:38.990036 38966 layer_factory.hpp:77] Creating layer add6
I1011 15:06:38.990046 38966 net.cpp:86] Creating Layer add6
I1011 15:06:38.990056 38966 net.cpp:408] add6 <- add5_add5_0_split_1
I1011 15:06:38.990063 38966 net.cpp:408] add6 <- conv30
I1011 15:06:38.990075 38966 net.cpp:382] add6 -> add6
I1011 15:06:38.990109 38966 net.cpp:124] Setting up add6
I1011 15:06:38.990119 38966 net.cpp:131] Top shape: 1 64 22 22 (30976)
I1011 15:06:38.990125 38966 net.cpp:139] Memory required for data: 201103968
I1011 15:06:38.990130 38966 layer_factory.hpp:77] Creating layer conv31
I1011 15:06:38.990146 38966 net.cpp:86] Creating Layer conv31
I1011 15:06:38.990154 38966 net.cpp:408] conv31 <- add6
I1011 15:06:38.990164 38966 net.cpp:382] conv31 -> conv31
I1011 15:06:38.990555 38966 net.cpp:124] Setting up conv31
I1011 15:06:38.990566 38966 net.cpp:131] Top shape: 1 327 22 22 (158268)
I1011 15:06:38.990571 38966 net.cpp:139] Memory required for data: 201737040
I1011 15:06:38.990579 38966 layer_factory.hpp:77] Creating layer batch_norm31
I1011 15:06:38.990592 38966 net.cpp:86] Creating Layer batch_norm31
I1011 15:06:38.990599 38966 net.cpp:408] batch_norm31 <- conv31
I1011 15:06:38.990607 38966 net.cpp:369] batch_norm31 -> conv31 (in-place)
I1011 15:06:38.990788 38966 net.cpp:124] Setting up batch_norm31
I1011 15:06:38.990798 38966 net.cpp:131] Top shape: 1 327 22 22 (158268)
I1011 15:06:38.990804 38966 net.cpp:139] Memory required for data: 202370112
I1011 15:06:38.990816 38966 layer_factory.hpp:77] Creating layer bn_scale31
I1011 15:06:38.990833 38966 net.cpp:86] Creating Layer bn_scale31
I1011 15:06:38.990840 38966 net.cpp:408] bn_scale31 <- conv31
I1011 15:06:38.990849 38966 net.cpp:369] bn_scale31 -> conv31 (in-place)
I1011 15:06:38.990893 38966 layer_factory.hpp:77] Creating layer bn_scale31
I1011 15:06:38.991008 38966 net.cpp:124] Setting up bn_scale31
I1011 15:06:38.991019 38966 net.cpp:131] Top shape: 1 327 22 22 (158268)
I1011 15:06:38.991025 38966 net.cpp:139] Memory required for data: 203003184
I1011 15:06:38.991034 38966 layer_factory.hpp:77] Creating layer relu21
I1011 15:06:38.991060 38966 net.cpp:86] Creating Layer relu21
I1011 15:06:38.991068 38966 net.cpp:408] relu21 <- conv31
I1011 15:06:38.991080 38966 net.cpp:369] relu21 -> conv31 (in-place)
I1011 15:06:38.991092 38966 net.cpp:124] Setting up relu21
I1011 15:06:38.991102 38966 net.cpp:131] Top shape: 1 327 22 22 (158268)
I1011 15:06:38.991108 38966 net.cpp:139] Memory required for data: 203636256
I1011 15:06:38.991114 38966 layer_factory.hpp:77] Creating layer conv32
I1011 15:06:38.991124 38966 net.cpp:86] Creating Layer conv32
I1011 15:06:38.991132 38966 net.cpp:408] conv32 <- conv31
I1011 15:06:38.991148 38966 net.cpp:382] conv32 -> conv32
I1011 15:06:38.991364 38966 net.cpp:124] Setting up conv32
I1011 15:06:38.991375 38966 net.cpp:131] Top shape: 1 327 22 22 (158268)
I1011 15:06:38.991381 38966 net.cpp:139] Memory required for data: 204269328
I1011 15:06:38.991389 38966 layer_factory.hpp:77] Creating layer batch_norm32
I1011 15:06:38.991410 38966 net.cpp:86] Creating Layer batch_norm32
I1011 15:06:38.991416 38966 net.cpp:408] batch_norm32 <- conv32
I1011 15:06:38.991425 38966 net.cpp:369] batch_norm32 -> conv32 (in-place)
I1011 15:06:38.991606 38966 net.cpp:124] Setting up batch_norm32
I1011 15:06:38.991616 38966 net.cpp:131] Top shape: 1 327 22 22 (158268)
I1011 15:06:38.991622 38966 net.cpp:139] Memory required for data: 204902400
I1011 15:06:38.991634 38966 layer_factory.hpp:77] Creating layer bn_scale32
I1011 15:06:38.991657 38966 net.cpp:86] Creating Layer bn_scale32
I1011 15:06:38.991664 38966 net.cpp:408] bn_scale32 <- conv32
I1011 15:06:38.991677 38966 net.cpp:369] bn_scale32 -> conv32 (in-place)
I1011 15:06:38.991720 38966 layer_factory.hpp:77] Creating layer bn_scale32
I1011 15:06:38.991830 38966 net.cpp:124] Setting up bn_scale32
I1011 15:06:38.991842 38966 net.cpp:131] Top shape: 1 327 22 22 (158268)
I1011 15:06:38.991847 38966 net.cpp:139] Memory required for data: 205535472
I1011 15:06:38.991856 38966 layer_factory.hpp:77] Creating layer relu22
I1011 15:06:38.991868 38966 net.cpp:86] Creating Layer relu22
I1011 15:06:38.991876 38966 net.cpp:408] relu22 <- conv32
I1011 15:06:38.991884 38966 net.cpp:369] relu22 -> conv32 (in-place)
I1011 15:06:38.991896 38966 net.cpp:124] Setting up relu22
I1011 15:06:38.991905 38966 net.cpp:131] Top shape: 1 327 22 22 (158268)
I1011 15:06:38.991914 38966 net.cpp:139] Memory required for data: 206168544
I1011 15:06:38.991933 38966 layer_factory.hpp:77] Creating layer conv33
I1011 15:06:38.991945 38966 net.cpp:86] Creating Layer conv33
I1011 15:06:38.991952 38966 net.cpp:408] conv33 <- conv32
I1011 15:06:38.991966 38966 net.cpp:382] conv33 -> conv33
I1011 15:06:38.992429 38966 net.cpp:124] Setting up conv33
I1011 15:06:38.992440 38966 net.cpp:131] Top shape: 1 87 22 22 (42108)
I1011 15:06:38.992445 38966 net.cpp:139] Memory required for data: 206336976
I1011 15:06:38.992453 38966 layer_factory.hpp:77] Creating layer batch_norm33
I1011 15:06:38.992465 38966 net.cpp:86] Creating Layer batch_norm33
I1011 15:06:38.992475 38966 net.cpp:408] batch_norm33 <- conv33
I1011 15:06:38.992486 38966 net.cpp:369] batch_norm33 -> conv33 (in-place)
I1011 15:06:38.992672 38966 net.cpp:124] Setting up batch_norm33
I1011 15:06:38.992697 38966 net.cpp:131] Top shape: 1 87 22 22 (42108)
I1011 15:06:38.992703 38966 net.cpp:139] Memory required for data: 206505408
I1011 15:06:38.992718 38966 layer_factory.hpp:77] Creating layer bn_scale33
I1011 15:06:38.992729 38966 net.cpp:86] Creating Layer bn_scale33
I1011 15:06:38.992736 38966 net.cpp:408] bn_scale33 <- conv33
I1011 15:06:38.992746 38966 net.cpp:369] bn_scale33 -> conv33 (in-place)
I1011 15:06:38.992813 38966 layer_factory.hpp:77] Creating layer bn_scale33
I1011 15:06:38.993005 38966 net.cpp:124] Setting up bn_scale33
I1011 15:06:38.993021 38966 net.cpp:131] Top shape: 1 87 22 22 (42108)
I1011 15:06:38.993026 38966 net.cpp:139] Memory required for data: 206673840
I1011 15:06:38.993038 38966 layer_factory.hpp:77] Creating layer conv33_bn_scale33_0_split
I1011 15:06:38.993048 38966 net.cpp:86] Creating Layer conv33_bn_scale33_0_split
I1011 15:06:38.993074 38966 net.cpp:408] conv33_bn_scale33_0_split <- conv33
I1011 15:06:38.993085 38966 net.cpp:382] conv33_bn_scale33_0_split -> conv33_bn_scale33_0_split_0
I1011 15:06:38.993103 38966 net.cpp:382] conv33_bn_scale33_0_split -> conv33_bn_scale33_0_split_1
I1011 15:06:38.993166 38966 net.cpp:124] Setting up conv33_bn_scale33_0_split
I1011 15:06:38.993177 38966 net.cpp:131] Top shape: 1 87 22 22 (42108)
I1011 15:06:38.993186 38966 net.cpp:131] Top shape: 1 87 22 22 (42108)
I1011 15:06:38.993192 38966 net.cpp:139] Memory required for data: 207010704
I1011 15:06:38.993199 38966 layer_factory.hpp:77] Creating layer conv34
I1011 15:06:38.993216 38966 net.cpp:86] Creating Layer conv34
I1011 15:06:38.993224 38966 net.cpp:408] conv34 <- conv33_bn_scale33_0_split_0
I1011 15:06:38.993235 38966 net.cpp:382] conv34 -> conv34
I1011 15:06:38.995020 38966 net.cpp:124] Setting up conv34
I1011 15:06:38.995035 38966 net.cpp:131] Top shape: 1 461 22 22 (223124)
I1011 15:06:38.995039 38966 net.cpp:139] Memory required for data: 207903200
I1011 15:06:38.995044 38966 layer_factory.hpp:77] Creating layer batch_norm34
I1011 15:06:38.995054 38966 net.cpp:86] Creating Layer batch_norm34
I1011 15:06:38.995057 38966 net.cpp:408] batch_norm34 <- conv34
I1011 15:06:38.995062 38966 net.cpp:369] batch_norm34 -> conv34 (in-place)
I1011 15:06:38.995244 38966 net.cpp:124] Setting up batch_norm34
I1011 15:06:38.995262 38966 net.cpp:131] Top shape: 1 461 22 22 (223124)
I1011 15:06:38.995265 38966 net.cpp:139] Memory required for data: 208795696
I1011 15:06:38.995272 38966 layer_factory.hpp:77] Creating layer bn_scale34
I1011 15:06:38.995278 38966 net.cpp:86] Creating Layer bn_scale34
I1011 15:06:38.995282 38966 net.cpp:408] bn_scale34 <- conv34
I1011 15:06:38.995290 38966 net.cpp:369] bn_scale34 -> conv34 (in-place)
I1011 15:06:38.995326 38966 layer_factory.hpp:77] Creating layer bn_scale34
I1011 15:06:38.995432 38966 net.cpp:124] Setting up bn_scale34
I1011 15:06:38.995440 38966 net.cpp:131] Top shape: 1 461 22 22 (223124)
I1011 15:06:38.995442 38966 net.cpp:139] Memory required for data: 209688192
I1011 15:06:38.995448 38966 layer_factory.hpp:77] Creating layer relu23
I1011 15:06:38.995453 38966 net.cpp:86] Creating Layer relu23
I1011 15:06:38.995457 38966 net.cpp:408] relu23 <- conv34
I1011 15:06:38.995465 38966 net.cpp:369] relu23 -> conv34 (in-place)
I1011 15:06:38.995470 38966 net.cpp:124] Setting up relu23
I1011 15:06:38.995473 38966 net.cpp:131] Top shape: 1 461 22 22 (223124)
I1011 15:06:38.995476 38966 net.cpp:139] Memory required for data: 210580688
I1011 15:06:38.995481 38966 layer_factory.hpp:77] Creating layer conv35
I1011 15:06:38.995489 38966 net.cpp:86] Creating Layer conv35
I1011 15:06:38.995493 38966 net.cpp:408] conv35 <- conv34
I1011 15:06:38.995498 38966 net.cpp:382] conv35 -> conv35
I1011 15:06:38.995702 38966 net.cpp:124] Setting up conv35
I1011 15:06:38.995712 38966 net.cpp:131] Top shape: 1 461 22 22 (223124)
I1011 15:06:38.995714 38966 net.cpp:139] Memory required for data: 211473184
I1011 15:06:38.995718 38966 layer_factory.hpp:77] Creating layer batch_norm35
I1011 15:06:38.995724 38966 net.cpp:86] Creating Layer batch_norm35
I1011 15:06:38.995728 38966 net.cpp:408] batch_norm35 <- conv35
I1011 15:06:38.995733 38966 net.cpp:369] batch_norm35 -> conv35 (in-place)
I1011 15:06:38.995900 38966 net.cpp:124] Setting up batch_norm35
I1011 15:06:38.995908 38966 net.cpp:131] Top shape: 1 461 22 22 (223124)
I1011 15:06:38.995911 38966 net.cpp:139] Memory required for data: 212365680
I1011 15:06:38.995918 38966 layer_factory.hpp:77] Creating layer bn_scale35
I1011 15:06:38.995923 38966 net.cpp:86] Creating Layer bn_scale35
I1011 15:06:38.995926 38966 net.cpp:408] bn_scale35 <- conv35
I1011 15:06:38.995930 38966 net.cpp:369] bn_scale35 -> conv35 (in-place)
I1011 15:06:38.995962 38966 layer_factory.hpp:77] Creating layer bn_scale35
I1011 15:06:38.996063 38966 net.cpp:124] Setting up bn_scale35
I1011 15:06:38.996070 38966 net.cpp:131] Top shape: 1 461 22 22 (223124)
I1011 15:06:38.996074 38966 net.cpp:139] Memory required for data: 213258176
I1011 15:06:38.996091 38966 layer_factory.hpp:77] Creating layer relu24
I1011 15:06:38.996096 38966 net.cpp:86] Creating Layer relu24
I1011 15:06:38.996100 38966 net.cpp:408] relu24 <- conv35
I1011 15:06:38.996107 38966 net.cpp:369] relu24 -> conv35 (in-place)
I1011 15:06:38.996112 38966 net.cpp:124] Setting up relu24
I1011 15:06:38.996117 38966 net.cpp:131] Top shape: 1 461 22 22 (223124)
I1011 15:06:38.996120 38966 net.cpp:139] Memory required for data: 214150672
I1011 15:06:38.996124 38966 layer_factory.hpp:77] Creating layer conv36
I1011 15:06:38.996129 38966 net.cpp:86] Creating Layer conv36
I1011 15:06:38.996134 38966 net.cpp:408] conv36 <- conv35
I1011 15:06:38.996140 38966 net.cpp:382] conv36 -> conv36
I1011 15:06:38.996861 38966 net.cpp:124] Setting up conv36
I1011 15:06:38.996870 38966 net.cpp:131] Top shape: 1 87 22 22 (42108)
I1011 15:06:38.996884 38966 net.cpp:139] Memory required for data: 214319104
I1011 15:06:38.996891 38966 layer_factory.hpp:77] Creating layer batch_norm36
I1011 15:06:38.996897 38966 net.cpp:86] Creating Layer batch_norm36
I1011 15:06:38.996901 38966 net.cpp:408] batch_norm36 <- conv36
I1011 15:06:38.996904 38966 net.cpp:369] batch_norm36 -> conv36 (in-place)
I1011 15:06:38.997081 38966 net.cpp:124] Setting up batch_norm36
I1011 15:06:38.997088 38966 net.cpp:131] Top shape: 1 87 22 22 (42108)
I1011 15:06:38.997092 38966 net.cpp:139] Memory required for data: 214487536
I1011 15:06:38.997097 38966 layer_factory.hpp:77] Creating layer bn_scale36
I1011 15:06:38.997102 38966 net.cpp:86] Creating Layer bn_scale36
I1011 15:06:38.997107 38966 net.cpp:408] bn_scale36 <- conv36
I1011 15:06:38.997112 38966 net.cpp:369] bn_scale36 -> conv36 (in-place)
I1011 15:06:38.997143 38966 layer_factory.hpp:77] Creating layer bn_scale36
I1011 15:06:38.997259 38966 net.cpp:124] Setting up bn_scale36
I1011 15:06:38.997267 38966 net.cpp:131] Top shape: 1 87 22 22 (42108)
I1011 15:06:38.997269 38966 net.cpp:139] Memory required for data: 214655968
I1011 15:06:38.997275 38966 layer_factory.hpp:77] Creating layer add7
I1011 15:06:38.997280 38966 net.cpp:86] Creating Layer add7
I1011 15:06:38.997284 38966 net.cpp:408] add7 <- conv33_bn_scale33_0_split_1
I1011 15:06:38.997288 38966 net.cpp:408] add7 <- conv36
I1011 15:06:38.997295 38966 net.cpp:382] add7 -> add7
I1011 15:06:38.997318 38966 net.cpp:124] Setting up add7
I1011 15:06:38.997326 38966 net.cpp:131] Top shape: 1 87 22 22 (42108)
I1011 15:06:38.997329 38966 net.cpp:139] Memory required for data: 214824400
I1011 15:06:38.997334 38966 layer_factory.hpp:77] Creating layer add7_add7_0_split
I1011 15:06:38.997339 38966 net.cpp:86] Creating Layer add7_add7_0_split
I1011 15:06:38.997341 38966 net.cpp:408] add7_add7_0_split <- add7
I1011 15:06:38.997346 38966 net.cpp:382] add7_add7_0_split -> add7_add7_0_split_0
I1011 15:06:38.997354 38966 net.cpp:382] add7_add7_0_split -> add7_add7_0_split_1
I1011 15:06:38.997386 38966 net.cpp:124] Setting up add7_add7_0_split
I1011 15:06:38.997393 38966 net.cpp:131] Top shape: 1 87 22 22 (42108)
I1011 15:06:38.997397 38966 net.cpp:131] Top shape: 1 87 22 22 (42108)
I1011 15:06:38.997400 38966 net.cpp:139] Memory required for data: 215161264
I1011 15:06:38.997403 38966 layer_factory.hpp:77] Creating layer conv37
I1011 15:06:38.997412 38966 net.cpp:86] Creating Layer conv37
I1011 15:06:38.997417 38966 net.cpp:408] conv37 <- add7_add7_0_split_0
I1011 15:06:38.997423 38966 net.cpp:382] conv37 -> conv37
I1011 15:06:38.998005 38966 net.cpp:124] Setting up conv37
I1011 15:06:38.998013 38966 net.cpp:131] Top shape: 1 461 22 22 (223124)
I1011 15:06:38.998028 38966 net.cpp:139] Memory required for data: 216053760
I1011 15:06:38.998031 38966 layer_factory.hpp:77] Creating layer batch_norm37
I1011 15:06:38.998037 38966 net.cpp:86] Creating Layer batch_norm37
I1011 15:06:38.998040 38966 net.cpp:408] batch_norm37 <- conv37
I1011 15:06:38.998045 38966 net.cpp:369] batch_norm37 -> conv37 (in-place)
I1011 15:06:38.998204 38966 net.cpp:124] Setting up batch_norm37
I1011 15:06:38.998212 38966 net.cpp:131] Top shape: 1 461 22 22 (223124)
I1011 15:06:38.998224 38966 net.cpp:139] Memory required for data: 216946256
I1011 15:06:38.998231 38966 layer_factory.hpp:77] Creating layer bn_scale37
I1011 15:06:38.998239 38966 net.cpp:86] Creating Layer bn_scale37
I1011 15:06:38.998242 38966 net.cpp:408] bn_scale37 <- conv37
I1011 15:06:38.998246 38966 net.cpp:369] bn_scale37 -> conv37 (in-place)
I1011 15:06:38.998279 38966 layer_factory.hpp:77] Creating layer bn_scale37
I1011 15:06:38.998391 38966 net.cpp:124] Setting up bn_scale37
I1011 15:06:38.998399 38966 net.cpp:131] Top shape: 1 461 22 22 (223124)
I1011 15:06:38.998404 38966 net.cpp:139] Memory required for data: 217838752
I1011 15:06:38.998409 38966 layer_factory.hpp:77] Creating layer relu25
I1011 15:06:38.998415 38966 net.cpp:86] Creating Layer relu25
I1011 15:06:38.998419 38966 net.cpp:408] relu25 <- conv37
I1011 15:06:38.998423 38966 net.cpp:369] relu25 -> conv37 (in-place)
I1011 15:06:38.998428 38966 net.cpp:124] Setting up relu25
I1011 15:06:38.998432 38966 net.cpp:131] Top shape: 1 461 22 22 (223124)
I1011 15:06:38.998435 38966 net.cpp:139] Memory required for data: 218731248
I1011 15:06:38.998438 38966 layer_factory.hpp:77] Creating layer conv38
I1011 15:06:38.998447 38966 net.cpp:86] Creating Layer conv38
I1011 15:06:38.998452 38966 net.cpp:408] conv38 <- conv37
I1011 15:06:38.998461 38966 net.cpp:382] conv38 -> conv38
I1011 15:06:38.998668 38966 net.cpp:124] Setting up conv38
I1011 15:06:38.998677 38966 net.cpp:131] Top shape: 1 461 22 22 (223124)
I1011 15:06:38.998679 38966 net.cpp:139] Memory required for data: 219623744
I1011 15:06:38.998684 38966 layer_factory.hpp:77] Creating layer batch_norm38
I1011 15:06:38.998689 38966 net.cpp:86] Creating Layer batch_norm38
I1011 15:06:38.998693 38966 net.cpp:408] batch_norm38 <- conv38
I1011 15:06:38.998703 38966 net.cpp:369] batch_norm38 -> conv38 (in-place)
I1011 15:06:38.998883 38966 net.cpp:124] Setting up batch_norm38
I1011 15:06:38.998890 38966 net.cpp:131] Top shape: 1 461 22 22 (223124)
I1011 15:06:38.998893 38966 net.cpp:139] Memory required for data: 220516240
I1011 15:06:38.998900 38966 layer_factory.hpp:77] Creating layer bn_scale38
I1011 15:06:38.998905 38966 net.cpp:86] Creating Layer bn_scale38
I1011 15:06:38.998909 38966 net.cpp:408] bn_scale38 <- conv38
I1011 15:06:38.998914 38966 net.cpp:369] bn_scale38 -> conv38 (in-place)
I1011 15:06:38.998947 38966 layer_factory.hpp:77] Creating layer bn_scale38
I1011 15:06:38.999049 38966 net.cpp:124] Setting up bn_scale38
I1011 15:06:38.999058 38966 net.cpp:131] Top shape: 1 461 22 22 (223124)
I1011 15:06:38.999060 38966 net.cpp:139] Memory required for data: 221408736
I1011 15:06:38.999065 38966 layer_factory.hpp:77] Creating layer relu26
I1011 15:06:38.999073 38966 net.cpp:86] Creating Layer relu26
I1011 15:06:38.999076 38966 net.cpp:408] relu26 <- conv38
I1011 15:06:38.999080 38966 net.cpp:369] relu26 -> conv38 (in-place)
I1011 15:06:38.999085 38966 net.cpp:124] Setting up relu26
I1011 15:06:38.999090 38966 net.cpp:131] Top shape: 1 461 22 22 (223124)
I1011 15:06:38.999094 38966 net.cpp:139] Memory required for data: 222301232
I1011 15:06:38.999096 38966 layer_factory.hpp:77] Creating layer conv39
I1011 15:06:38.999104 38966 net.cpp:86] Creating Layer conv39
I1011 15:06:38.999109 38966 net.cpp:408] conv39 <- conv38
I1011 15:06:38.999114 38966 net.cpp:382] conv39 -> conv39
I1011 15:06:38.999696 38966 net.cpp:124] Setting up conv39
I1011 15:06:38.999706 38966 net.cpp:131] Top shape: 1 87 22 22 (42108)
I1011 15:06:38.999720 38966 net.cpp:139] Memory required for data: 222469664
I1011 15:06:38.999724 38966 layer_factory.hpp:77] Creating layer batch_norm39
I1011 15:06:38.999732 38966 net.cpp:86] Creating Layer batch_norm39
I1011 15:06:38.999735 38966 net.cpp:408] batch_norm39 <- conv39
I1011 15:06:38.999739 38966 net.cpp:369] batch_norm39 -> conv39 (in-place)
I1011 15:06:38.999903 38966 net.cpp:124] Setting up batch_norm39
I1011 15:06:38.999910 38966 net.cpp:131] Top shape: 1 87 22 22 (42108)
I1011 15:06:38.999913 38966 net.cpp:139] Memory required for data: 222638096
I1011 15:06:38.999930 38966 layer_factory.hpp:77] Creating layer bn_scale39
I1011 15:06:38.999938 38966 net.cpp:86] Creating Layer bn_scale39
I1011 15:06:38.999943 38966 net.cpp:408] bn_scale39 <- conv39
I1011 15:06:38.999946 38966 net.cpp:369] bn_scale39 -> conv39 (in-place)
I1011 15:06:38.999980 38966 layer_factory.hpp:77] Creating layer bn_scale39
I1011 15:06:39.000094 38966 net.cpp:124] Setting up bn_scale39
I1011 15:06:39.000102 38966 net.cpp:131] Top shape: 1 87 22 22 (42108)
I1011 15:06:39.000105 38966 net.cpp:139] Memory required for data: 222806528
I1011 15:06:39.000111 38966 layer_factory.hpp:77] Creating layer add8
I1011 15:06:39.000116 38966 net.cpp:86] Creating Layer add8
I1011 15:06:39.000120 38966 net.cpp:408] add8 <- add7_add7_0_split_1
I1011 15:06:39.000124 38966 net.cpp:408] add8 <- conv39
I1011 15:06:39.000131 38966 net.cpp:382] add8 -> add8
I1011 15:06:39.000159 38966 net.cpp:124] Setting up add8
I1011 15:06:39.000166 38966 net.cpp:131] Top shape: 1 87 22 22 (42108)
I1011 15:06:39.000169 38966 net.cpp:139] Memory required for data: 222974960
I1011 15:06:39.000174 38966 layer_factory.hpp:77] Creating layer conv40
I1011 15:06:39.000182 38966 net.cpp:86] Creating Layer conv40
I1011 15:06:39.000187 38966 net.cpp:408] conv40 <- add8
I1011 15:06:39.000193 38966 net.cpp:382] conv40 -> conv40
I1011 15:06:39.000864 38966 net.cpp:124] Setting up conv40
I1011 15:06:39.000872 38966 net.cpp:131] Top shape: 1 576 22 22 (278784)
I1011 15:06:39.000875 38966 net.cpp:139] Memory required for data: 224090096
I1011 15:06:39.000880 38966 layer_factory.hpp:77] Creating layer batch_norm40
I1011 15:06:39.000887 38966 net.cpp:86] Creating Layer batch_norm40
I1011 15:06:39.000891 38966 net.cpp:408] batch_norm40 <- conv40
I1011 15:06:39.000895 38966 net.cpp:369] batch_norm40 -> conv40 (in-place)
I1011 15:06:39.001067 38966 net.cpp:124] Setting up batch_norm40
I1011 15:06:39.001075 38966 net.cpp:131] Top shape: 1 576 22 22 (278784)
I1011 15:06:39.001078 38966 net.cpp:139] Memory required for data: 225205232
I1011 15:06:39.001085 38966 layer_factory.hpp:77] Creating layer bn_scale40
I1011 15:06:39.001089 38966 net.cpp:86] Creating Layer bn_scale40
I1011 15:06:39.001093 38966 net.cpp:408] bn_scale40 <- conv40
I1011 15:06:39.001099 38966 net.cpp:369] bn_scale40 -> conv40 (in-place)
I1011 15:06:39.001128 38966 layer_factory.hpp:77] Creating layer bn_scale40
I1011 15:06:39.001229 38966 net.cpp:124] Setting up bn_scale40
I1011 15:06:39.001237 38966 net.cpp:131] Top shape: 1 576 22 22 (278784)
I1011 15:06:39.001240 38966 net.cpp:139] Memory required for data: 226320368
I1011 15:06:39.001245 38966 layer_factory.hpp:77] Creating layer relu27
I1011 15:06:39.001250 38966 net.cpp:86] Creating Layer relu27
I1011 15:06:39.001255 38966 net.cpp:408] relu27 <- conv40
I1011 15:06:39.001258 38966 net.cpp:369] relu27 -> conv40 (in-place)
I1011 15:06:39.001263 38966 net.cpp:124] Setting up relu27
I1011 15:06:39.001267 38966 net.cpp:131] Top shape: 1 576 22 22 (278784)
I1011 15:06:39.001271 38966 net.cpp:139] Memory required for data: 227435504
I1011 15:06:39.001273 38966 layer_factory.hpp:77] Creating layer conv40_relu27_0_split
I1011 15:06:39.001281 38966 net.cpp:86] Creating Layer conv40_relu27_0_split
I1011 15:06:39.001284 38966 net.cpp:408] conv40_relu27_0_split <- conv40
I1011 15:06:39.001289 38966 net.cpp:382] conv40_relu27_0_split -> conv40_relu27_0_split_0
I1011 15:06:39.001297 38966 net.cpp:382] conv40_relu27_0_split -> conv40_relu27_0_split_1
I1011 15:06:39.001330 38966 net.cpp:124] Setting up conv40_relu27_0_split
I1011 15:06:39.001338 38966 net.cpp:131] Top shape: 1 576 22 22 (278784)
I1011 15:06:39.001341 38966 net.cpp:131] Top shape: 1 576 22 22 (278784)
I1011 15:06:39.001344 38966 net.cpp:139] Memory required for data: 229665776
I1011 15:06:39.001348 38966 layer_factory.hpp:77] Creating layer conv41
I1011 15:06:39.001353 38966 net.cpp:86] Creating Layer conv41
I1011 15:06:39.001358 38966 net.cpp:408] conv41 <- conv40_relu27_0_split_0
I1011 15:06:39.001364 38966 net.cpp:382] conv41 -> conv41
I1011 15:06:39.001579 38966 net.cpp:124] Setting up conv41
I1011 15:06:39.001597 38966 net.cpp:131] Top shape: 1 576 11 11 (69696)
I1011 15:06:39.001601 38966 net.cpp:139] Memory required for data: 229944560
I1011 15:06:39.001605 38966 layer_factory.hpp:77] Creating layer batch_norm41
I1011 15:06:39.001611 38966 net.cpp:86] Creating Layer batch_norm41
I1011 15:06:39.001615 38966 net.cpp:408] batch_norm41 <- conv41
I1011 15:06:39.001622 38966 net.cpp:369] batch_norm41 -> conv41 (in-place)
I1011 15:06:39.001796 38966 net.cpp:124] Setting up batch_norm41
I1011 15:06:39.001804 38966 net.cpp:131] Top shape: 1 576 11 11 (69696)
I1011 15:06:39.001807 38966 net.cpp:139] Memory required for data: 230223344
I1011 15:06:39.001813 38966 layer_factory.hpp:77] Creating layer bn_scale41
I1011 15:06:39.001818 38966 net.cpp:86] Creating Layer bn_scale41
I1011 15:06:39.001822 38966 net.cpp:408] bn_scale41 <- conv41
I1011 15:06:39.001827 38966 net.cpp:369] bn_scale41 -> conv41 (in-place)
I1011 15:06:39.001860 38966 layer_factory.hpp:77] Creating layer bn_scale41
I1011 15:06:39.001966 38966 net.cpp:124] Setting up bn_scale41
I1011 15:06:39.001974 38966 net.cpp:131] Top shape: 1 576 11 11 (69696)
I1011 15:06:39.001977 38966 net.cpp:139] Memory required for data: 230502128
I1011 15:06:39.001982 38966 layer_factory.hpp:77] Creating layer relu28
I1011 15:06:39.001989 38966 net.cpp:86] Creating Layer relu28
I1011 15:06:39.001993 38966 net.cpp:408] relu28 <- conv41
I1011 15:06:39.001997 38966 net.cpp:369] relu28 -> conv41 (in-place)
I1011 15:06:39.002002 38966 net.cpp:124] Setting up relu28
I1011 15:06:39.002007 38966 net.cpp:131] Top shape: 1 576 11 11 (69696)
I1011 15:06:39.002009 38966 net.cpp:139] Memory required for data: 230780912
I1011 15:06:39.002012 38966 layer_factory.hpp:77] Creating layer conv42
I1011 15:06:39.002024 38966 net.cpp:86] Creating Layer conv42
I1011 15:06:39.002028 38966 net.cpp:408] conv42 <- conv41
I1011 15:06:39.002036 38966 net.cpp:382] conv42 -> conv42
I1011 15:06:39.002919 38966 net.cpp:124] Setting up conv42
I1011 15:06:39.002928 38966 net.cpp:131] Top shape: 1 128 11 11 (15488)
I1011 15:06:39.002941 38966 net.cpp:139] Memory required for data: 230842864
I1011 15:06:39.002946 38966 layer_factory.hpp:77] Creating layer batch_norm42
I1011 15:06:39.002954 38966 net.cpp:86] Creating Layer batch_norm42
I1011 15:06:39.002957 38966 net.cpp:408] batch_norm42 <- conv42
I1011 15:06:39.002961 38966 net.cpp:369] batch_norm42 -> conv42 (in-place)
I1011 15:06:39.003113 38966 net.cpp:124] Setting up batch_norm42
I1011 15:06:39.003120 38966 net.cpp:131] Top shape: 1 128 11 11 (15488)
I1011 15:06:39.003123 38966 net.cpp:139] Memory required for data: 230904816
I1011 15:06:39.003129 38966 layer_factory.hpp:77] Creating layer bn_scale42
I1011 15:06:39.003134 38966 net.cpp:86] Creating Layer bn_scale42
I1011 15:06:39.003137 38966 net.cpp:408] bn_scale42 <- conv42
I1011 15:06:39.003142 38966 net.cpp:369] bn_scale42 -> conv42 (in-place)
I1011 15:06:39.003185 38966 layer_factory.hpp:77] Creating layer bn_scale42
I1011 15:06:39.003296 38966 net.cpp:124] Setting up bn_scale42
I1011 15:06:39.003304 38966 net.cpp:131] Top shape: 1 128 11 11 (15488)
I1011 15:06:39.003309 38966 net.cpp:139] Memory required for data: 230966768
I1011 15:06:39.003314 38966 layer_factory.hpp:77] Creating layer conv42_bn_scale42_0_split
I1011 15:06:39.003319 38966 net.cpp:86] Creating Layer conv42_bn_scale42_0_split
I1011 15:06:39.003322 38966 net.cpp:408] conv42_bn_scale42_0_split <- conv42
I1011 15:06:39.003329 38966 net.cpp:382] conv42_bn_scale42_0_split -> conv42_bn_scale42_0_split_0
I1011 15:06:39.003336 38966 net.cpp:382] conv42_bn_scale42_0_split -> conv42_bn_scale42_0_split_1
I1011 15:06:39.003370 38966 net.cpp:124] Setting up conv42_bn_scale42_0_split
I1011 15:06:39.003376 38966 net.cpp:131] Top shape: 1 128 11 11 (15488)
I1011 15:06:39.003381 38966 net.cpp:131] Top shape: 1 128 11 11 (15488)
I1011 15:06:39.003383 38966 net.cpp:139] Memory required for data: 231090672
I1011 15:06:39.003386 38966 layer_factory.hpp:77] Creating layer conv43
I1011 15:06:39.003397 38966 net.cpp:86] Creating Layer conv43
I1011 15:06:39.003412 38966 net.cpp:408] conv43 <- conv42_bn_scale42_0_split_0
I1011 15:06:39.003418 38966 net.cpp:382] conv43 -> conv43
I1011 15:06:39.005079 38966 net.cpp:124] Setting up conv43
I1011 15:06:39.005092 38966 net.cpp:131] Top shape: 1 768 11 11 (92928)
I1011 15:06:39.005097 38966 net.cpp:139] Memory required for data: 231462384
I1011 15:06:39.005105 38966 layer_factory.hpp:77] Creating layer batch_norm43
I1011 15:06:39.005118 38966 net.cpp:86] Creating Layer batch_norm43
I1011 15:06:39.005138 38966 net.cpp:408] batch_norm43 <- conv43
I1011 15:06:39.005147 38966 net.cpp:369] batch_norm43 -> conv43 (in-place)
I1011 15:06:39.005332 38966 net.cpp:124] Setting up batch_norm43
I1011 15:06:39.005343 38966 net.cpp:131] Top shape: 1 768 11 11 (92928)
I1011 15:06:39.005348 38966 net.cpp:139] Memory required for data: 231834096
I1011 15:06:39.005367 38966 layer_factory.hpp:77] Creating layer bn_scale43
I1011 15:06:39.005375 38966 net.cpp:86] Creating Layer bn_scale43
I1011 15:06:39.005380 38966 net.cpp:408] bn_scale43 <- conv43
I1011 15:06:39.005388 38966 net.cpp:369] bn_scale43 -> conv43 (in-place)
I1011 15:06:39.005439 38966 layer_factory.hpp:77] Creating layer bn_scale43
I1011 15:06:39.005555 38966 net.cpp:124] Setting up bn_scale43
I1011 15:06:39.005568 38966 net.cpp:131] Top shape: 1 768 11 11 (92928)
I1011 15:06:39.005573 38966 net.cpp:139] Memory required for data: 232205808
I1011 15:06:39.005602 38966 layer_factory.hpp:77] Creating layer relu29
I1011 15:06:39.005614 38966 net.cpp:86] Creating Layer relu29
I1011 15:06:39.005620 38966 net.cpp:408] relu29 <- conv43
I1011 15:06:39.005628 38966 net.cpp:369] relu29 -> conv43 (in-place)
I1011 15:06:39.005642 38966 net.cpp:124] Setting up relu29
I1011 15:06:39.005651 38966 net.cpp:131] Top shape: 1 768 11 11 (92928)
I1011 15:06:39.005657 38966 net.cpp:139] Memory required for data: 232577520
I1011 15:06:39.005663 38966 layer_factory.hpp:77] Creating layer conv44
I1011 15:06:39.005673 38966 net.cpp:86] Creating Layer conv44
I1011 15:06:39.005679 38966 net.cpp:408] conv44 <- conv43
I1011 15:06:39.005693 38966 net.cpp:382] conv44 -> conv44
I1011 15:06:39.005939 38966 net.cpp:124] Setting up conv44
I1011 15:06:39.005954 38966 net.cpp:131] Top shape: 1 768 11 11 (92928)
I1011 15:06:39.005959 38966 net.cpp:139] Memory required for data: 232949232
I1011 15:06:39.005969 38966 layer_factory.hpp:77] Creating layer batch_norm44
I1011 15:06:39.005977 38966 net.cpp:86] Creating Layer batch_norm44
I1011 15:06:39.005985 38966 net.cpp:408] batch_norm44 <- conv44
I1011 15:06:39.005998 38966 net.cpp:369] batch_norm44 -> conv44 (in-place)
I1011 15:06:39.006173 38966 net.cpp:124] Setting up batch_norm44
I1011 15:06:39.006184 38966 net.cpp:131] Top shape: 1 768 11 11 (92928)
I1011 15:06:39.006189 38966 net.cpp:139] Memory required for data: 233320944
I1011 15:06:39.006201 38966 layer_factory.hpp:77] Creating layer bn_scale44
I1011 15:06:39.006214 38966 net.cpp:86] Creating Layer bn_scale44
I1011 15:06:39.006223 38966 net.cpp:408] bn_scale44 <- conv44
I1011 15:06:39.006232 38966 net.cpp:369] bn_scale44 -> conv44 (in-place)
I1011 15:06:39.006278 38966 layer_factory.hpp:77] Creating layer bn_scale44
I1011 15:06:39.006388 38966 net.cpp:124] Setting up bn_scale44
I1011 15:06:39.006400 38966 net.cpp:131] Top shape: 1 768 11 11 (92928)
I1011 15:06:39.006405 38966 net.cpp:139] Memory required for data: 233692656
I1011 15:06:39.006415 38966 layer_factory.hpp:77] Creating layer relu30
I1011 15:06:39.006424 38966 net.cpp:86] Creating Layer relu30
I1011 15:06:39.006430 38966 net.cpp:408] relu30 <- conv44
I1011 15:06:39.006443 38966 net.cpp:369] relu30 -> conv44 (in-place)
I1011 15:06:39.006453 38966 net.cpp:124] Setting up relu30
I1011 15:06:39.006462 38966 net.cpp:131] Top shape: 1 768 11 11 (92928)
I1011 15:06:39.006469 38966 net.cpp:139] Memory required for data: 234064368
I1011 15:06:39.006474 38966 layer_factory.hpp:77] Creating layer conv45
I1011 15:06:39.006489 38966 net.cpp:86] Creating Layer conv45
I1011 15:06:39.006496 38966 net.cpp:408] conv45 <- conv44
I1011 15:06:39.006507 38966 net.cpp:382] conv45 -> conv45
I1011 15:06:39.008730 38966 net.cpp:124] Setting up conv45
I1011 15:06:39.008746 38966 net.cpp:131] Top shape: 1 128 11 11 (15488)
I1011 15:06:39.008751 38966 net.cpp:139] Memory required for data: 234126320
I1011 15:06:39.008771 38966 layer_factory.hpp:77] Creating layer batch_norm45
I1011 15:06:39.008785 38966 net.cpp:86] Creating Layer batch_norm45
I1011 15:06:39.008792 38966 net.cpp:408] batch_norm45 <- conv45
I1011 15:06:39.008801 38966 net.cpp:369] batch_norm45 -> conv45 (in-place)
I1011 15:06:39.008980 38966 net.cpp:124] Setting up batch_norm45
I1011 15:06:39.008991 38966 net.cpp:131] Top shape: 1 128 11 11 (15488)
I1011 15:06:39.008996 38966 net.cpp:139] Memory required for data: 234188272
I1011 15:06:39.009008 38966 layer_factory.hpp:77] Creating layer bn_scale45
I1011 15:06:39.009018 38966 net.cpp:86] Creating Layer bn_scale45
I1011 15:06:39.009027 38966 net.cpp:408] bn_scale45 <- conv45
I1011 15:06:39.009035 38966 net.cpp:369] bn_scale45 -> conv45 (in-place)
I1011 15:06:39.009097 38966 layer_factory.hpp:77] Creating layer bn_scale45
I1011 15:06:39.009208 38966 net.cpp:124] Setting up bn_scale45
I1011 15:06:39.009219 38966 net.cpp:131] Top shape: 1 128 11 11 (15488)
I1011 15:06:39.009224 38966 net.cpp:139] Memory required for data: 234250224
I1011 15:06:39.009235 38966 layer_factory.hpp:77] Creating layer add9
I1011 15:06:39.009248 38966 net.cpp:86] Creating Layer add9
I1011 15:06:39.009256 38966 net.cpp:408] add9 <- conv42_bn_scale42_0_split_1
I1011 15:06:39.009264 38966 net.cpp:408] add9 <- conv45
I1011 15:06:39.009277 38966 net.cpp:382] add9 -> add9
I1011 15:06:39.009308 38966 net.cpp:124] Setting up add9
I1011 15:06:39.009317 38966 net.cpp:131] Top shape: 1 128 11 11 (15488)
I1011 15:06:39.009323 38966 net.cpp:139] Memory required for data: 234312176
I1011 15:06:39.009328 38966 layer_factory.hpp:77] Creating layer add9_add9_0_split
I1011 15:06:39.009342 38966 net.cpp:86] Creating Layer add9_add9_0_split
I1011 15:06:39.009351 38966 net.cpp:408] add9_add9_0_split <- add9
I1011 15:06:39.009361 38966 net.cpp:382] add9_add9_0_split -> add9_add9_0_split_0
I1011 15:06:39.009377 38966 net.cpp:382] add9_add9_0_split -> add9_add9_0_split_1
I1011 15:06:39.009420 38966 net.cpp:124] Setting up add9_add9_0_split
I1011 15:06:39.009430 38966 net.cpp:131] Top shape: 1 128 11 11 (15488)
I1011 15:06:39.009438 38966 net.cpp:131] Top shape: 1 128 11 11 (15488)
I1011 15:06:39.009443 38966 net.cpp:139] Memory required for data: 234436080
I1011 15:06:39.009449 38966 layer_factory.hpp:77] Creating layer conv46
I1011 15:06:39.009461 38966 net.cpp:86] Creating Layer conv46
I1011 15:06:39.009469 38966 net.cpp:408] conv46 <- add9_add9_0_split_0
I1011 15:06:39.009483 38966 net.cpp:382] conv46 -> conv46
I1011 15:06:39.010648 38966 net.cpp:124] Setting up conv46
I1011 15:06:39.010660 38966 net.cpp:131] Top shape: 1 768 11 11 (92928)
I1011 15:06:39.010666 38966 net.cpp:139] Memory required for data: 234807792
I1011 15:06:39.010674 38966 layer_factory.hpp:77] Creating layer batch_norm46
I1011 15:06:39.010686 38966 net.cpp:86] Creating Layer batch_norm46
I1011 15:06:39.010695 38966 net.cpp:408] batch_norm46 <- conv46
I1011 15:06:39.010709 38966 net.cpp:369] batch_norm46 -> conv46 (in-place)
I1011 15:06:39.010885 38966 net.cpp:124] Setting up batch_norm46
I1011 15:06:39.010895 38966 net.cpp:131] Top shape: 1 768 11 11 (92928)
I1011 15:06:39.010900 38966 net.cpp:139] Memory required for data: 235179504
I1011 15:06:39.010912 38966 layer_factory.hpp:77] Creating layer bn_scale46
I1011 15:06:39.010926 38966 net.cpp:86] Creating Layer bn_scale46
I1011 15:06:39.010934 38966 net.cpp:408] bn_scale46 <- conv46
I1011 15:06:39.010943 38966 net.cpp:369] bn_scale46 -> conv46 (in-place)
I1011 15:06:39.010987 38966 layer_factory.hpp:77] Creating layer bn_scale46
I1011 15:06:39.011096 38966 net.cpp:124] Setting up bn_scale46
I1011 15:06:39.011107 38966 net.cpp:131] Top shape: 1 768 11 11 (92928)
I1011 15:06:39.011112 38966 net.cpp:139] Memory required for data: 235551216
I1011 15:06:39.011123 38966 layer_factory.hpp:77] Creating layer relu31
I1011 15:06:39.011144 38966 net.cpp:86] Creating Layer relu31
I1011 15:06:39.011154 38966 net.cpp:408] relu31 <- conv46
I1011 15:06:39.011166 38966 net.cpp:369] relu31 -> conv46 (in-place)
I1011 15:06:39.011178 38966 net.cpp:124] Setting up relu31
I1011 15:06:39.011188 38966 net.cpp:131] Top shape: 1 768 11 11 (92928)
I1011 15:06:39.011194 38966 net.cpp:139] Memory required for data: 235922928
I1011 15:06:39.011200 38966 layer_factory.hpp:77] Creating layer conv47
I1011 15:06:39.011214 38966 net.cpp:86] Creating Layer conv47
I1011 15:06:39.011221 38966 net.cpp:408] conv47 <- conv46
I1011 15:06:39.011231 38966 net.cpp:382] conv47 -> conv47
I1011 15:06:39.011489 38966 net.cpp:124] Setting up conv47
I1011 15:06:39.011502 38966 net.cpp:131] Top shape: 1 768 11 11 (92928)
I1011 15:06:39.011507 38966 net.cpp:139] Memory required for data: 236294640
I1011 15:06:39.011515 38966 layer_factory.hpp:77] Creating layer batch_norm47
I1011 15:06:39.011525 38966 net.cpp:86] Creating Layer batch_norm47
I1011 15:06:39.011533 38966 net.cpp:408] batch_norm47 <- conv47
I1011 15:06:39.011543 38966 net.cpp:369] batch_norm47 -> conv47 (in-place)
I1011 15:06:39.011739 38966 net.cpp:124] Setting up batch_norm47
I1011 15:06:39.011749 38966 net.cpp:131] Top shape: 1 768 11 11 (92928)
I1011 15:06:39.011754 38966 net.cpp:139] Memory required for data: 236666352
I1011 15:06:39.011766 38966 layer_factory.hpp:77] Creating layer bn_scale47
I1011 15:06:39.011776 38966 net.cpp:86] Creating Layer bn_scale47
I1011 15:06:39.011783 38966 net.cpp:408] bn_scale47 <- conv47
I1011 15:06:39.011798 38966 net.cpp:369] bn_scale47 -> conv47 (in-place)
I1011 15:06:39.011842 38966 layer_factory.hpp:77] Creating layer bn_scale47
I1011 15:06:39.011951 38966 net.cpp:124] Setting up bn_scale47
I1011 15:06:39.011962 38966 net.cpp:131] Top shape: 1 768 11 11 (92928)
I1011 15:06:39.011967 38966 net.cpp:139] Memory required for data: 237038064
I1011 15:06:39.011977 38966 layer_factory.hpp:77] Creating layer relu32
I1011 15:06:39.011991 38966 net.cpp:86] Creating Layer relu32
I1011 15:06:39.011999 38966 net.cpp:408] relu32 <- conv47
I1011 15:06:39.012008 38966 net.cpp:369] relu32 -> conv47 (in-place)
I1011 15:06:39.012022 38966 net.cpp:124] Setting up relu32
I1011 15:06:39.012032 38966 net.cpp:131] Top shape: 1 768 11 11 (92928)
I1011 15:06:39.012038 38966 net.cpp:139] Memory required for data: 237409776
I1011 15:06:39.012044 38966 layer_factory.hpp:77] Creating layer conv48
I1011 15:06:39.012059 38966 net.cpp:86] Creating Layer conv48
I1011 15:06:39.012066 38966 net.cpp:408] conv48 <- conv47
I1011 15:06:39.012079 38966 net.cpp:382] conv48 -> conv48
I1011 15:06:39.013244 38966 net.cpp:124] Setting up conv48
I1011 15:06:39.013257 38966 net.cpp:131] Top shape: 1 128 11 11 (15488)
I1011 15:06:39.013262 38966 net.cpp:139] Memory required for data: 237471728
I1011 15:06:39.013269 38966 layer_factory.hpp:77] Creating layer batch_norm48
I1011 15:06:39.013283 38966 net.cpp:86] Creating Layer batch_norm48
I1011 15:06:39.013290 38966 net.cpp:408] batch_norm48 <- conv48
I1011 15:06:39.013298 38966 net.cpp:369] batch_norm48 -> conv48 (in-place)
I1011 15:06:39.013495 38966 net.cpp:124] Setting up batch_norm48
I1011 15:06:39.013510 38966 net.cpp:131] Top shape: 1 128 11 11 (15488)
I1011 15:06:39.013515 38966 net.cpp:139] Memory required for data: 237533680
I1011 15:06:39.013527 38966 layer_factory.hpp:77] Creating layer bn_scale48
I1011 15:06:39.013537 38966 net.cpp:86] Creating Layer bn_scale48
I1011 15:06:39.013545 38966 net.cpp:408] bn_scale48 <- conv48
I1011 15:06:39.013552 38966 net.cpp:369] bn_scale48 -> conv48 (in-place)
I1011 15:06:39.013597 38966 layer_factory.hpp:77] Creating layer bn_scale48
I1011 15:06:39.013706 38966 net.cpp:124] Setting up bn_scale48
I1011 15:06:39.013717 38966 net.cpp:131] Top shape: 1 128 11 11 (15488)
I1011 15:06:39.013722 38966 net.cpp:139] Memory required for data: 237595632
I1011 15:06:39.013732 38966 layer_factory.hpp:77] Creating layer add10
I1011 15:06:39.013741 38966 net.cpp:86] Creating Layer add10
I1011 15:06:39.013748 38966 net.cpp:408] add10 <- add9_add9_0_split_1
I1011 15:06:39.013772 38966 net.cpp:408] add10 <- conv48
I1011 15:06:39.013789 38966 net.cpp:382] add10 -> add10
I1011 15:06:39.013830 38966 net.cpp:124] Setting up add10
I1011 15:06:39.013840 38966 net.cpp:131] Top shape: 1 128 11 11 (15488)
I1011 15:06:39.013845 38966 net.cpp:139] Memory required for data: 237657584
I1011 15:06:39.013851 38966 layer_factory.hpp:77] Creating layer conv49
I1011 15:06:39.013869 38966 net.cpp:86] Creating Layer conv49
I1011 15:06:39.013878 38966 net.cpp:408] conv49 <- add10
I1011 15:06:39.013890 38966 net.cpp:382] conv49 -> conv49
I1011 15:06:39.015573 38966 net.cpp:124] Setting up conv49
I1011 15:06:39.015585 38966 net.cpp:131] Top shape: 1 768 11 11 (92928)
I1011 15:06:39.015591 38966 net.cpp:139] Memory required for data: 238029296
I1011 15:06:39.015600 38966 layer_factory.hpp:77] Creating layer batch_norm49
I1011 15:06:39.015610 38966 net.cpp:86] Creating Layer batch_norm49
I1011 15:06:39.015617 38966 net.cpp:408] batch_norm49 <- conv49
I1011 15:06:39.015626 38966 net.cpp:369] batch_norm49 -> conv49 (in-place)
I1011 15:06:39.015807 38966 net.cpp:124] Setting up batch_norm49
I1011 15:06:39.015818 38966 net.cpp:131] Top shape: 1 768 11 11 (92928)
I1011 15:06:39.015823 38966 net.cpp:139] Memory required for data: 238401008
I1011 15:06:39.015836 38966 layer_factory.hpp:77] Creating layer bn_scale49
I1011 15:06:39.015846 38966 net.cpp:86] Creating Layer bn_scale49
I1011 15:06:39.015853 38966 net.cpp:408] bn_scale49 <- conv49
I1011 15:06:39.015866 38966 net.cpp:369] bn_scale49 -> conv49 (in-place)
I1011 15:06:39.015908 38966 layer_factory.hpp:77] Creating layer bn_scale49
I1011 15:06:39.016018 38966 net.cpp:124] Setting up bn_scale49
I1011 15:06:39.016028 38966 net.cpp:131] Top shape: 1 768 11 11 (92928)
I1011 15:06:39.016034 38966 net.cpp:139] Memory required for data: 238772720
I1011 15:06:39.016044 38966 layer_factory.hpp:77] Creating layer relu33
I1011 15:06:39.016058 38966 net.cpp:86] Creating Layer relu33
I1011 15:06:39.016067 38966 net.cpp:408] relu33 <- conv49
I1011 15:06:39.016074 38966 net.cpp:369] relu33 -> conv49 (in-place)
I1011 15:06:39.016083 38966 net.cpp:124] Setting up relu33
I1011 15:06:39.016093 38966 net.cpp:131] Top shape: 1 768 11 11 (92928)
I1011 15:06:39.016099 38966 net.cpp:139] Memory required for data: 239144432
I1011 15:06:39.016105 38966 layer_factory.hpp:77] Creating layer conv50
I1011 15:06:39.016119 38966 net.cpp:86] Creating Layer conv50
I1011 15:06:39.016126 38966 net.cpp:408] conv50 <- conv49
I1011 15:06:39.016139 38966 net.cpp:382] conv50 -> conv50
I1011 15:06:39.016383 38966 net.cpp:124] Setting up conv50
I1011 15:06:39.016394 38966 net.cpp:131] Top shape: 1 768 11 11 (92928)
I1011 15:06:39.016400 38966 net.cpp:139] Memory required for data: 239516144
I1011 15:06:39.016407 38966 layer_factory.hpp:77] Creating layer batch_norm50
I1011 15:06:39.016422 38966 net.cpp:86] Creating Layer batch_norm50
I1011 15:06:39.016429 38966 net.cpp:408] batch_norm50 <- conv50
I1011 15:06:39.016438 38966 net.cpp:369] batch_norm50 -> conv50 (in-place)
I1011 15:06:39.016610 38966 net.cpp:124] Setting up batch_norm50
I1011 15:06:39.016620 38966 net.cpp:131] Top shape: 1 768 11 11 (92928)
I1011 15:06:39.016625 38966 net.cpp:139] Memory required for data: 239887856
I1011 15:06:39.016638 38966 layer_factory.hpp:77] Creating layer bn_scale50
I1011 15:06:39.016646 38966 net.cpp:86] Creating Layer bn_scale50
I1011 15:06:39.016654 38966 net.cpp:408] bn_scale50 <- conv50
I1011 15:06:39.016662 38966 net.cpp:369] bn_scale50 -> conv50 (in-place)
I1011 15:06:39.016711 38966 layer_factory.hpp:77] Creating layer bn_scale50
I1011 15:06:39.016822 38966 net.cpp:124] Setting up bn_scale50
I1011 15:06:39.016832 38966 net.cpp:131] Top shape: 1 768 11 11 (92928)
I1011 15:06:39.016839 38966 net.cpp:139] Memory required for data: 240259568
I1011 15:06:39.016847 38966 layer_factory.hpp:77] Creating layer relu34
I1011 15:06:39.016862 38966 net.cpp:86] Creating Layer relu34
I1011 15:06:39.016870 38966 net.cpp:408] relu34 <- conv50
I1011 15:06:39.016882 38966 net.cpp:369] relu34 -> conv50 (in-place)
I1011 15:06:39.016904 38966 net.cpp:124] Setting up relu34
I1011 15:06:39.016916 38966 net.cpp:131] Top shape: 1 768 11 11 (92928)
I1011 15:06:39.016922 38966 net.cpp:139] Memory required for data: 240631280
I1011 15:06:39.016928 38966 layer_factory.hpp:77] Creating layer conv51
I1011 15:06:39.016939 38966 net.cpp:86] Creating Layer conv51
I1011 15:06:39.016947 38966 net.cpp:408] conv51 <- conv50
I1011 15:06:39.016960 38966 net.cpp:382] conv51 -> conv51
I1011 15:06:39.020370 38966 net.cpp:124] Setting up conv51
I1011 15:06:39.020386 38966 net.cpp:131] Top shape: 1 224 11 11 (27104)
I1011 15:06:39.020392 38966 net.cpp:139] Memory required for data: 240739696
I1011 15:06:39.020401 38966 layer_factory.hpp:77] Creating layer batch_norm51
I1011 15:06:39.020411 38966 net.cpp:86] Creating Layer batch_norm51
I1011 15:06:39.020418 38966 net.cpp:408] batch_norm51 <- conv51
I1011 15:06:39.020431 38966 net.cpp:369] batch_norm51 -> conv51 (in-place)
I1011 15:06:39.020630 38966 net.cpp:124] Setting up batch_norm51
I1011 15:06:39.020642 38966 net.cpp:131] Top shape: 1 224 11 11 (27104)
I1011 15:06:39.020648 38966 net.cpp:139] Memory required for data: 240848112
I1011 15:06:39.020659 38966 layer_factory.hpp:77] Creating layer bn_scale51
I1011 15:06:39.020669 38966 net.cpp:86] Creating Layer bn_scale51
I1011 15:06:39.020676 38966 net.cpp:408] bn_scale51 <- conv51
I1011 15:06:39.020684 38966 net.cpp:369] bn_scale51 -> conv51 (in-place)
I1011 15:06:39.020732 38966 layer_factory.hpp:77] Creating layer bn_scale51
I1011 15:06:39.020851 38966 net.cpp:124] Setting up bn_scale51
I1011 15:06:39.020862 38966 net.cpp:131] Top shape: 1 224 11 11 (27104)
I1011 15:06:39.020867 38966 net.cpp:139] Memory required for data: 240956528
I1011 15:06:39.020877 38966 layer_factory.hpp:77] Creating layer conv52
I1011 15:06:39.020895 38966 net.cpp:86] Creating Layer conv52
I1011 15:06:39.020901 38966 net.cpp:408] conv52 <- conv51
I1011 15:06:39.020915 38966 net.cpp:382] conv52 -> conv52
I1011 15:06:39.022500 38966 net.cpp:124] Setting up conv52
I1011 15:06:39.022512 38966 net.cpp:131] Top shape: 1 640 11 11 (77440)
I1011 15:06:39.022518 38966 net.cpp:139] Memory required for data: 241266288
I1011 15:06:39.022526 38966 layer_factory.hpp:77] Creating layer batch_norm52
I1011 15:06:39.022536 38966 net.cpp:86] Creating Layer batch_norm52
I1011 15:06:39.022543 38966 net.cpp:408] batch_norm52 <- conv52
I1011 15:06:39.022554 38966 net.cpp:369] batch_norm52 -> conv52 (in-place)
I1011 15:06:39.022725 38966 net.cpp:124] Setting up batch_norm52
I1011 15:06:39.022748 38966 net.cpp:131] Top shape: 1 640 11 11 (77440)
I1011 15:06:39.022753 38966 net.cpp:139] Memory required for data: 241576048
I1011 15:06:39.022765 38966 layer_factory.hpp:77] Creating layer bn_scale52
I1011 15:06:39.022778 38966 net.cpp:86] Creating Layer bn_scale52
I1011 15:06:39.022786 38966 net.cpp:408] bn_scale52 <- conv52
I1011 15:06:39.022795 38966 net.cpp:369] bn_scale52 -> conv52 (in-place)
I1011 15:06:39.022840 38966 layer_factory.hpp:77] Creating layer bn_scale52
I1011 15:06:39.022948 38966 net.cpp:124] Setting up bn_scale52
I1011 15:06:39.022959 38966 net.cpp:131] Top shape: 1 640 11 11 (77440)
I1011 15:06:39.022964 38966 net.cpp:139] Memory required for data: 241885808
I1011 15:06:39.022974 38966 layer_factory.hpp:77] Creating layer relu35
I1011 15:06:39.022982 38966 net.cpp:86] Creating Layer relu35
I1011 15:06:39.022989 38966 net.cpp:408] relu35 <- conv52
I1011 15:06:39.023000 38966 net.cpp:369] relu35 -> conv52 (in-place)
I1011 15:06:39.023011 38966 net.cpp:124] Setting up relu35
I1011 15:06:39.023021 38966 net.cpp:131] Top shape: 1 640 11 11 (77440)
I1011 15:06:39.023027 38966 net.cpp:139] Memory required for data: 242195568
I1011 15:06:39.023033 38966 layer_factory.hpp:77] Creating layer yolo/conv1/dw
I1011 15:06:39.023048 38966 net.cpp:86] Creating Layer yolo/conv1/dw
I1011 15:06:39.023056 38966 net.cpp:408] yolo/conv1/dw <- conv52
I1011 15:06:39.023066 38966 net.cpp:382] yolo/conv1/dw -> yolo/conv1/dw
I1011 15:06:39.023309 38966 net.cpp:124] Setting up yolo/conv1/dw
I1011 15:06:39.023334 38966 net.cpp:131] Top shape: 1 640 11 11 (77440)
I1011 15:06:39.023339 38966 net.cpp:139] Memory required for data: 242505328
I1011 15:06:39.023347 38966 layer_factory.hpp:77] Creating layer yolo/conv1/dw/bn
I1011 15:06:39.023357 38966 net.cpp:86] Creating Layer yolo/conv1/dw/bn
I1011 15:06:39.023365 38966 net.cpp:408] yolo/conv1/dw/bn <- yolo/conv1/dw
I1011 15:06:39.023375 38966 net.cpp:369] yolo/conv1/dw/bn -> yolo/conv1/dw (in-place)
I1011 15:06:39.023561 38966 net.cpp:124] Setting up yolo/conv1/dw/bn
I1011 15:06:39.023571 38966 net.cpp:131] Top shape: 1 640 11 11 (77440)
I1011 15:06:39.023576 38966 net.cpp:139] Memory required for data: 242815088
I1011 15:06:39.023588 38966 layer_factory.hpp:77] Creating layer yolo/conv1/dw/scale
I1011 15:06:39.023602 38966 net.cpp:86] Creating Layer yolo/conv1/dw/scale
I1011 15:06:39.023622 38966 net.cpp:408] yolo/conv1/dw/scale <- yolo/conv1/dw
I1011 15:06:39.023630 38966 net.cpp:369] yolo/conv1/dw/scale -> yolo/conv1/dw (in-place)
I1011 15:06:39.023679 38966 layer_factory.hpp:77] Creating layer yolo/conv1/dw/scale
I1011 15:06:39.023797 38966 net.cpp:124] Setting up yolo/conv1/dw/scale
I1011 15:06:39.023808 38966 net.cpp:131] Top shape: 1 640 11 11 (77440)
I1011 15:06:39.023813 38966 net.cpp:139] Memory required for data: 243124848
I1011 15:06:39.023823 38966 layer_factory.hpp:77] Creating layer yolo/conv1/dw/relu
I1011 15:06:39.023833 38966 net.cpp:86] Creating Layer yolo/conv1/dw/relu
I1011 15:06:39.023840 38966 net.cpp:408] yolo/conv1/dw/relu <- yolo/conv1/dw
I1011 15:06:39.023849 38966 net.cpp:369] yolo/conv1/dw/relu -> yolo/conv1/dw (in-place)
I1011 15:06:39.023859 38966 net.cpp:124] Setting up yolo/conv1/dw/relu
I1011 15:06:39.023869 38966 net.cpp:131] Top shape: 1 640 11 11 (77440)
I1011 15:06:39.023874 38966 net.cpp:139] Memory required for data: 243434608
I1011 15:06:39.023880 38966 layer_factory.hpp:77] Creating layer yolo/conv1
I1011 15:06:39.023895 38966 net.cpp:86] Creating Layer yolo/conv1
I1011 15:06:39.023902 38966 net.cpp:408] yolo/conv1 <- yolo/conv1/dw
I1011 15:06:39.023916 38966 net.cpp:382] yolo/conv1 -> yolo/conv1
I1011 15:06:39.028692 38966 net.cpp:124] Setting up yolo/conv1
I1011 15:06:39.028708 38966 net.cpp:131] Top shape: 1 576 11 11 (69696)
I1011 15:06:39.028714 38966 net.cpp:139] Memory required for data: 243713392
I1011 15:06:39.028723 38966 layer_factory.hpp:77] Creating layer yolo/conv1/bn
I1011 15:06:39.028733 38966 net.cpp:86] Creating Layer yolo/conv1/bn
I1011 15:06:39.028739 38966 net.cpp:408] yolo/conv1/bn <- yolo/conv1
I1011 15:06:39.028751 38966 net.cpp:369] yolo/conv1/bn -> yolo/conv1 (in-place)
I1011 15:06:39.028939 38966 net.cpp:124] Setting up yolo/conv1/bn
I1011 15:06:39.028949 38966 net.cpp:131] Top shape: 1 576 11 11 (69696)
I1011 15:06:39.028954 38966 net.cpp:139] Memory required for data: 243992176
I1011 15:06:39.028965 38966 layer_factory.hpp:77] Creating layer yolo/conv1/scale
I1011 15:06:39.028977 38966 net.cpp:86] Creating Layer yolo/conv1/scale
I1011 15:06:39.028985 38966 net.cpp:408] yolo/conv1/scale <- yolo/conv1
I1011 15:06:39.028997 38966 net.cpp:369] yolo/conv1/scale -> yolo/conv1 (in-place)
I1011 15:06:39.029042 38966 layer_factory.hpp:77] Creating layer yolo/conv1/scale
I1011 15:06:39.029161 38966 net.cpp:124] Setting up yolo/conv1/scale
I1011 15:06:39.029172 38966 net.cpp:131] Top shape: 1 576 11 11 (69696)
I1011 15:06:39.029177 38966 net.cpp:139] Memory required for data: 244270960
I1011 15:06:39.029187 38966 layer_factory.hpp:77] Creating layer yolo/conv1/relu
I1011 15:06:39.029196 38966 net.cpp:86] Creating Layer yolo/conv1/relu
I1011 15:06:39.029206 38966 net.cpp:408] yolo/conv1/relu <- yolo/conv1
I1011 15:06:39.029213 38966 net.cpp:369] yolo/conv1/relu -> yolo/conv1 (in-place)
I1011 15:06:39.029227 38966 net.cpp:124] Setting up yolo/conv1/relu
I1011 15:06:39.029235 38966 net.cpp:131] Top shape: 1 576 11 11 (69696)
I1011 15:06:39.029240 38966 net.cpp:139] Memory required for data: 244549744
I1011 15:06:39.029245 38966 layer_factory.hpp:77] Creating layer yolo/conv1_yolo/conv1/relu_0_split
I1011 15:06:39.029289 38966 net.cpp:86] Creating Layer yolo/conv1_yolo/conv1/relu_0_split
I1011 15:06:39.029295 38966 net.cpp:408] yolo/conv1_yolo/conv1/relu_0_split <- yolo/conv1
I1011 15:06:39.029304 38966 net.cpp:382] yolo/conv1_yolo/conv1/relu_0_split -> yolo/conv1_yolo/conv1/relu_0_split_0
I1011 15:06:39.029322 38966 net.cpp:382] yolo/conv1_yolo/conv1/relu_0_split -> yolo/conv1_yolo/conv1/relu_0_split_1
I1011 15:06:39.029371 38966 net.cpp:124] Setting up yolo/conv1_yolo/conv1/relu_0_split
I1011 15:06:39.029381 38966 net.cpp:131] Top shape: 1 576 11 11 (69696)
I1011 15:06:39.029388 38966 net.cpp:131] Top shape: 1 576 11 11 (69696)
I1011 15:06:39.029394 38966 net.cpp:139] Memory required for data: 245107312
I1011 15:06:39.029400 38966 layer_factory.hpp:77] Creating layer upsample
I1011 15:06:39.029413 38966 net.cpp:86] Creating Layer upsample
I1011 15:06:39.029422 38966 net.cpp:408] upsample <- yolo/conv1_yolo/conv1/relu_0_split_0
I1011 15:06:39.029436 38966 net.cpp:382] upsample -> upsample
I1011 15:06:39.029619 38966 net.cpp:124] Setting up upsample
I1011 15:06:39.029630 38966 net.cpp:131] Top shape: 1 576 21 21 (254016)
I1011 15:06:39.029635 38966 net.cpp:139] Memory required for data: 246123376
I1011 15:06:39.029644 38966 layer_factory.hpp:77] Creating layer maxpool
I1011 15:06:39.029656 38966 net.cpp:86] Creating Layer maxpool
I1011 15:06:39.029664 38966 net.cpp:408] maxpool <- upsample
I1011 15:06:39.029681 38966 net.cpp:382] maxpool -> maxpool
I1011 15:06:39.029726 38966 net.cpp:124] Setting up maxpool
I1011 15:06:39.029736 38966 net.cpp:131] Top shape: 1 576 22 22 (278784)
I1011 15:06:39.029742 38966 net.cpp:139] Memory required for data: 247238512
I1011 15:06:39.029747 38966 layer_factory.hpp:77] Creating layer yolo/conv2/dw
I1011 15:06:39.029762 38966 net.cpp:86] Creating Layer yolo/conv2/dw
I1011 15:06:39.029769 38966 net.cpp:408] yolo/conv2/dw <- conv40_relu27_0_split_1
I1011 15:06:39.029779 38966 net.cpp:382] yolo/conv2/dw -> yolo/conv2/dw
I1011 15:06:39.030014 38966 net.cpp:124] Setting up yolo/conv2/dw
I1011 15:06:39.030025 38966 net.cpp:131] Top shape: 1 576 22 22 (278784)
I1011 15:06:39.030031 38966 net.cpp:139] Memory required for data: 248353648
I1011 15:06:39.030040 38966 layer_factory.hpp:77] Creating layer yolo/conv2/dw/bn
I1011 15:06:39.030050 38966 net.cpp:86] Creating Layer yolo/conv2/dw/bn
I1011 15:06:39.030057 38966 net.cpp:408] yolo/conv2/dw/bn <- yolo/conv2/dw
I1011 15:06:39.030071 38966 net.cpp:369] yolo/conv2/dw/bn -> yolo/conv2/dw (in-place)
I1011 15:06:39.030268 38966 net.cpp:124] Setting up yolo/conv2/dw/bn
I1011 15:06:39.030278 38966 net.cpp:131] Top shape: 1 576 22 22 (278784)
I1011 15:06:39.030284 38966 net.cpp:139] Memory required for data: 249468784
I1011 15:06:39.030295 38966 layer_factory.hpp:77] Creating layer yolo/conv2/dw/scale
I1011 15:06:39.030306 38966 net.cpp:86] Creating Layer yolo/conv2/dw/scale
I1011 15:06:39.030326 38966 net.cpp:408] yolo/conv2/dw/scale <- yolo/conv2/dw
I1011 15:06:39.030335 38966 net.cpp:369] yolo/conv2/dw/scale -> yolo/conv2/dw (in-place)
I1011 15:06:39.030382 38966 layer_factory.hpp:77] Creating layer yolo/conv2/dw/scale
I1011 15:06:39.030499 38966 net.cpp:124] Setting up yolo/conv2/dw/scale
I1011 15:06:39.030512 38966 net.cpp:131] Top shape: 1 576 22 22 (278784)
I1011 15:06:39.030519 38966 net.cpp:139] Memory required for data: 250583920
I1011 15:06:39.030529 38966 layer_factory.hpp:77] Creating layer yolo/conv2/dw/relu
I1011 15:06:39.030537 38966 net.cpp:86] Creating Layer yolo/conv2/dw/relu
I1011 15:06:39.030545 38966 net.cpp:408] yolo/conv2/dw/relu <- yolo/conv2/dw
I1011 15:06:39.030553 38966 net.cpp:369] yolo/conv2/dw/relu -> yolo/conv2/dw (in-place)
I1011 15:06:39.030563 38966 net.cpp:124] Setting up yolo/conv2/dw/relu
I1011 15:06:39.030572 38966 net.cpp:131] Top shape: 1 576 22 22 (278784)
I1011 15:06:39.030578 38966 net.cpp:139] Memory required for data: 251699056
I1011 15:06:39.030583 38966 layer_factory.hpp:77] Creating layer yolo/conv2
I1011 15:06:39.030598 38966 net.cpp:86] Creating Layer yolo/conv2
I1011 15:06:39.030606 38966 net.cpp:408] yolo/conv2 <- yolo/conv2/dw
I1011 15:06:39.030630 38966 net.cpp:382] yolo/conv2 -> yolo/conv2
I1011 15:06:39.035079 38966 net.cpp:124] Setting up yolo/conv2
I1011 15:06:39.035095 38966 net.cpp:131] Top shape: 1 576 22 22 (278784)
I1011 15:06:39.035101 38966 net.cpp:139] Memory required for data: 252814192
I1011 15:06:39.035109 38966 layer_factory.hpp:77] Creating layer yolo/conv2/bn
I1011 15:06:39.035120 38966 net.cpp:86] Creating Layer yolo/conv2/bn
I1011 15:06:39.035130 38966 net.cpp:408] yolo/conv2/bn <- yolo/conv2
I1011 15:06:39.035142 38966 net.cpp:369] yolo/conv2/bn -> yolo/conv2 (in-place)
I1011 15:06:39.035358 38966 net.cpp:124] Setting up yolo/conv2/bn
I1011 15:06:39.035372 38966 net.cpp:131] Top shape: 1 576 22 22 (278784)
I1011 15:06:39.035377 38966 net.cpp:139] Memory required for data: 253929328
I1011 15:06:39.035388 38966 layer_factory.hpp:77] Creating layer yolo/conv2/scale
I1011 15:06:39.035401 38966 net.cpp:86] Creating Layer yolo/conv2/scale
I1011 15:06:39.035409 38966 net.cpp:408] yolo/conv2/scale <- yolo/conv2
I1011 15:06:39.035419 38966 net.cpp:369] yolo/conv2/scale -> yolo/conv2 (in-place)
I1011 15:06:39.035470 38966 layer_factory.hpp:77] Creating layer yolo/conv2/scale
I1011 15:06:39.035589 38966 net.cpp:124] Setting up yolo/conv2/scale
I1011 15:06:39.035603 38966 net.cpp:131] Top shape: 1 576 22 22 (278784)
I1011 15:06:39.035609 38966 net.cpp:139] Memory required for data: 255044464
I1011 15:06:39.035619 38966 layer_factory.hpp:77] Creating layer yolo/conv2/relu
I1011 15:06:39.035630 38966 net.cpp:86] Creating Layer yolo/conv2/relu
I1011 15:06:39.035640 38966 net.cpp:408] yolo/conv2/relu <- yolo/conv2
I1011 15:06:39.035648 38966 net.cpp:369] yolo/conv2/relu -> yolo/conv2 (in-place)
I1011 15:06:39.035660 38966 net.cpp:124] Setting up yolo/conv2/relu
I1011 15:06:39.035670 38966 net.cpp:131] Top shape: 1 576 22 22 (278784)
I1011 15:06:39.035676 38966 net.cpp:139] Memory required for data: 256159600
I1011 15:06:39.035681 38966 layer_factory.hpp:77] Creating layer yolo/conv2/sum
I1011 15:06:39.035693 38966 net.cpp:86] Creating Layer yolo/conv2/sum
I1011 15:06:39.035701 38966 net.cpp:408] yolo/conv2/sum <- maxpool
I1011 15:06:39.035708 38966 net.cpp:408] yolo/conv2/sum <- yolo/conv2
I1011 15:06:39.035717 38966 net.cpp:382] yolo/conv2/sum -> yolo/conv2/sum
I1011 15:06:39.035753 38966 net.cpp:124] Setting up yolo/conv2/sum
I1011 15:06:39.035763 38966 net.cpp:131] Top shape: 1 576 22 22 (278784)
I1011 15:06:39.035768 38966 net.cpp:139] Memory required for data: 257274736
I1011 15:06:39.035774 38966 layer_factory.hpp:77] Creating layer yolo/conv3/dw
I1011 15:06:39.035789 38966 net.cpp:86] Creating Layer yolo/conv3/dw
I1011 15:06:39.035796 38966 net.cpp:408] yolo/conv3/dw <- yolo/conv2/sum
I1011 15:06:39.035806 38966 net.cpp:382] yolo/conv3/dw -> yolo/conv3/dw
I1011 15:06:39.036042 38966 net.cpp:124] Setting up yolo/conv3/dw
I1011 15:06:39.036053 38966 net.cpp:131] Top shape: 1 576 22 22 (278784)
I1011 15:06:39.036058 38966 net.cpp:139] Memory required for data: 258389872
I1011 15:06:39.036067 38966 layer_factory.hpp:77] Creating layer yolo/conv3/dw/bn
I1011 15:06:39.036082 38966 net.cpp:86] Creating Layer yolo/conv3/dw/bn
I1011 15:06:39.036090 38966 net.cpp:408] yolo/conv3/dw/bn <- yolo/conv3/dw
I1011 15:06:39.036099 38966 net.cpp:369] yolo/conv3/dw/bn -> yolo/conv3/dw (in-place)
I1011 15:06:39.036293 38966 net.cpp:124] Setting up yolo/conv3/dw/bn
I1011 15:06:39.036316 38966 net.cpp:131] Top shape: 1 576 22 22 (278784)
I1011 15:06:39.036321 38966 net.cpp:139] Memory required for data: 259505008
I1011 15:06:39.036334 38966 layer_factory.hpp:77] Creating layer yolo/conv3/dw/scale
I1011 15:06:39.036347 38966 net.cpp:86] Creating Layer yolo/conv3/dw/scale
I1011 15:06:39.036355 38966 net.cpp:408] yolo/conv3/dw/scale <- yolo/conv3/dw
I1011 15:06:39.036365 38966 net.cpp:369] yolo/conv3/dw/scale -> yolo/conv3/dw (in-place)
I1011 15:06:39.036412 38966 layer_factory.hpp:77] Creating layer yolo/conv3/dw/scale
I1011 15:06:39.036530 38966 net.cpp:124] Setting up yolo/conv3/dw/scale
I1011 15:06:39.036541 38966 net.cpp:131] Top shape: 1 576 22 22 (278784)
I1011 15:06:39.036561 38966 net.cpp:139] Memory required for data: 260620144
I1011 15:06:39.036574 38966 layer_factory.hpp:77] Creating layer yolo/conv3/dw/relu
I1011 15:06:39.036588 38966 net.cpp:86] Creating Layer yolo/conv3/dw/relu
I1011 15:06:39.036597 38966 net.cpp:408] yolo/conv3/dw/relu <- yolo/conv3/dw
I1011 15:06:39.036605 38966 net.cpp:369] yolo/conv3/dw/relu -> yolo/conv3/dw (in-place)
I1011 15:06:39.036618 38966 net.cpp:124] Setting up yolo/conv3/dw/relu
I1011 15:06:39.036628 38966 net.cpp:131] Top shape: 1 576 22 22 (278784)
I1011 15:06:39.036633 38966 net.cpp:139] Memory required for data: 261735280
I1011 15:06:39.036639 38966 layer_factory.hpp:77] Creating layer yolo/conv3
I1011 15:06:39.036654 38966 net.cpp:86] Creating Layer yolo/conv3
I1011 15:06:39.036661 38966 net.cpp:408] yolo/conv3 <- yolo/conv3/dw
I1011 15:06:39.036674 38966 net.cpp:382] yolo/conv3 -> yolo/conv3
I1011 15:06:39.041085 38966 net.cpp:124] Setting up yolo/conv3
I1011 15:06:39.041101 38966 net.cpp:131] Top shape: 1 576 22 22 (278784)
I1011 15:06:39.041107 38966 net.cpp:139] Memory required for data: 262850416
I1011 15:06:39.041115 38966 layer_factory.hpp:77] Creating layer yolo/conv3/bn
I1011 15:06:39.041129 38966 net.cpp:86] Creating Layer yolo/conv3/bn
I1011 15:06:39.041137 38966 net.cpp:408] yolo/conv3/bn <- yolo/conv3
I1011 15:06:39.041146 38966 net.cpp:369] yolo/conv3/bn -> yolo/conv3 (in-place)
I1011 15:06:39.041347 38966 net.cpp:124] Setting up yolo/conv3/bn
I1011 15:06:39.041358 38966 net.cpp:131] Top shape: 1 576 22 22 (278784)
I1011 15:06:39.041363 38966 net.cpp:139] Memory required for data: 263965552
I1011 15:06:39.041375 38966 layer_factory.hpp:77] Creating layer yolo/conv3/scale
I1011 15:06:39.041391 38966 net.cpp:86] Creating Layer yolo/conv3/scale
I1011 15:06:39.041400 38966 net.cpp:408] yolo/conv3/scale <- yolo/conv3
I1011 15:06:39.041409 38966 net.cpp:369] yolo/conv3/scale -> yolo/conv3 (in-place)
I1011 15:06:39.041456 38966 layer_factory.hpp:77] Creating layer yolo/conv3/scale
I1011 15:06:39.041575 38966 net.cpp:124] Setting up yolo/conv3/scale
I1011 15:06:39.041586 38966 net.cpp:131] Top shape: 1 576 22 22 (278784)
I1011 15:06:39.041592 38966 net.cpp:139] Memory required for data: 265080688
I1011 15:06:39.041601 38966 layer_factory.hpp:77] Creating layer yolo/conv3/relu
I1011 15:06:39.041615 38966 net.cpp:86] Creating Layer yolo/conv3/relu
I1011 15:06:39.041623 38966 net.cpp:408] yolo/conv3/relu <- yolo/conv3
I1011 15:06:39.041632 38966 net.cpp:369] yolo/conv3/relu -> yolo/conv3 (in-place)
I1011 15:06:39.041641 38966 net.cpp:124] Setting up yolo/conv3/relu
I1011 15:06:39.041651 38966 net.cpp:131] Top shape: 1 576 22 22 (278784)
I1011 15:06:39.041657 38966 net.cpp:139] Memory required for data: 266195824
I1011 15:06:39.041662 38966 layer_factory.hpp:77] Creating layer yolo/conv4
I1011 15:06:39.041678 38966 net.cpp:86] Creating Layer yolo/conv4
I1011 15:06:39.041687 38966 net.cpp:408] yolo/conv4 <- yolo/conv1_yolo/conv1/relu_0_split_1
I1011 15:06:39.041700 38966 net.cpp:382] yolo/conv4 -> yolo/conv4
I1011 15:06:39.042266 38966 net.cpp:124] Setting up yolo/conv4
I1011 15:06:39.042290 38966 net.cpp:131] Top shape: 1 18 11 11 (2178)
I1011 15:06:39.042299 38966 net.cpp:139] Memory required for data: 266204536
I1011 15:06:39.042310 38966 layer_factory.hpp:77] Creating layer yolo/conv5
I1011 15:06:39.042326 38966 net.cpp:86] Creating Layer yolo/conv5
I1011 15:06:39.042335 38966 net.cpp:408] yolo/conv5 <- yolo/conv3
I1011 15:06:39.042351 38966 net.cpp:382] yolo/conv5 -> yolo/conv5
I1011 15:06:39.042865 38966 net.cpp:124] Setting up yolo/conv5
I1011 15:06:39.042873 38966 net.cpp:131] Top shape: 1 18 22 22 (8712)
I1011 15:06:39.042876 38966 net.cpp:139] Memory required for data: 266239384
I1011 15:06:39.042882 38966 layer_factory.hpp:77] Creating layer detection_out
I1011 15:06:39.042891 38966 net.cpp:86] Creating Layer detection_out
I1011 15:06:39.042894 38966 net.cpp:408] detection_out <- yolo/conv4
I1011 15:06:39.042898 38966 net.cpp:408] detection_out <- yolo/conv5
I1011 15:06:39.042904 38966 net.cpp:382] detection_out -> detection_out
I1011 15:06:39.042950 38966 net.cpp:124] Setting up detection_out
I1011 15:06:39.042958 38966 net.cpp:131] Top shape: 1 1 1 7 (7)
I1011 15:06:39.042960 38966 net.cpp:139] Memory required for data: 266239412
I1011 15:06:39.042964 38966 layer_factory.hpp:77] Creating layer detection_eval
I1011 15:06:39.042971 38966 net.cpp:86] Creating Layer detection_eval
I1011 15:06:39.042974 38966 net.cpp:408] detection_eval <- detection_out
I1011 15:06:39.042979 38966 net.cpp:408] detection_eval <- label
I1011 15:06:39.042987 38966 net.cpp:382] detection_eval -> detection_eval
I1011 15:06:39.043028 38966 net.cpp:124] Setting up detection_eval
I1011 15:06:39.043036 38966 net.cpp:131] Top shape: 1 1 2 5 (10)
I1011 15:06:39.043040 38966 net.cpp:139] Memory required for data: 266239452
I1011 15:06:39.043043 38966 net.cpp:202] detection_eval does not need backward computation.
I1011 15:06:39.043047 38966 net.cpp:202] detection_out does not need backward computation.
I1011 15:06:39.043051 38966 net.cpp:202] yolo/conv5 does not need backward computation.
I1011 15:06:39.043056 38966 net.cpp:202] yolo/conv4 does not need backward computation.
I1011 15:06:39.043058 38966 net.cpp:202] yolo/conv3/relu does not need backward computation.
I1011 15:06:39.043061 38966 net.cpp:202] yolo/conv3/scale does not need backward computation.
I1011 15:06:39.043066 38966 net.cpp:202] yolo/conv3/bn does not need backward computation.
I1011 15:06:39.043068 38966 net.cpp:202] yolo/conv3 does not need backward computation.
I1011 15:06:39.043071 38966 net.cpp:202] yolo/conv3/dw/relu does not need backward computation.
I1011 15:06:39.043076 38966 net.cpp:202] yolo/conv3/dw/scale does not need backward computation.
I1011 15:06:39.043078 38966 net.cpp:202] yolo/conv3/dw/bn does not need backward computation.
I1011 15:06:39.043081 38966 net.cpp:202] yolo/conv3/dw does not need backward computation.
I1011 15:06:39.043085 38966 net.cpp:202] yolo/conv2/sum does not need backward computation.
I1011 15:06:39.043089 38966 net.cpp:202] yolo/conv2/relu does not need backward computation.
I1011 15:06:39.043092 38966 net.cpp:202] yolo/conv2/scale does not need backward computation.
I1011 15:06:39.043097 38966 net.cpp:202] yolo/conv2/bn does not need backward computation.
I1011 15:06:39.043099 38966 net.cpp:202] yolo/conv2 does not need backward computation.
I1011 15:06:39.043102 38966 net.cpp:202] yolo/conv2/dw/relu does not need backward computation.
I1011 15:06:39.043105 38966 net.cpp:202] yolo/conv2/dw/scale does not need backward computation.
I1011 15:06:39.043109 38966 net.cpp:202] yolo/conv2/dw/bn does not need backward computation.
I1011 15:06:39.043112 38966 net.cpp:202] yolo/conv2/dw does not need backward computation.
I1011 15:06:39.043115 38966 net.cpp:202] maxpool does not need backward computation.
I1011 15:06:39.043119 38966 net.cpp:202] upsample does not need backward computation.
I1011 15:06:39.043123 38966 net.cpp:202] yolo/conv1_yolo/conv1/relu_0_split does not need backward computation.
I1011 15:06:39.043126 38966 net.cpp:202] yolo/conv1/relu does not need backward computation.
I1011 15:06:39.043130 38966 net.cpp:202] yolo/conv1/scale does not need backward computation.
I1011 15:06:39.043133 38966 net.cpp:202] yolo/conv1/bn does not need backward computation.
I1011 15:06:39.043136 38966 net.cpp:202] yolo/conv1 does not need backward computation.
I1011 15:06:39.043140 38966 net.cpp:202] yolo/conv1/dw/relu does not need backward computation.
I1011 15:06:39.043143 38966 net.cpp:202] yolo/conv1/dw/scale does not need backward computation.
I1011 15:06:39.043148 38966 net.cpp:202] yolo/conv1/dw/bn does not need backward computation.
I1011 15:06:39.043150 38966 net.cpp:202] yolo/conv1/dw does not need backward computation.
I1011 15:06:39.043154 38966 net.cpp:202] relu35 does not need backward computation.
I1011 15:06:39.043157 38966 net.cpp:202] bn_scale52 does not need backward computation.
I1011 15:06:39.043160 38966 net.cpp:202] batch_norm52 does not need backward computation.
I1011 15:06:39.043164 38966 net.cpp:202] conv52 does not need backward computation.
I1011 15:06:39.043175 38966 net.cpp:202] bn_scale51 does not need backward computation.
I1011 15:06:39.043179 38966 net.cpp:202] batch_norm51 does not need backward computation.
I1011 15:06:39.043182 38966 net.cpp:202] conv51 does not need backward computation.
I1011 15:06:39.043185 38966 net.cpp:202] relu34 does not need backward computation.
I1011 15:06:39.043188 38966 net.cpp:202] bn_scale50 does not need backward computation.
I1011 15:06:39.043192 38966 net.cpp:202] batch_norm50 does not need backward computation.
I1011 15:06:39.043195 38966 net.cpp:202] conv50 does not need backward computation.
I1011 15:06:39.043198 38966 net.cpp:202] relu33 does not need backward computation.
I1011 15:06:39.043202 38966 net.cpp:202] bn_scale49 does not need backward computation.
I1011 15:06:39.043205 38966 net.cpp:202] batch_norm49 does not need backward computation.
I1011 15:06:39.043208 38966 net.cpp:202] conv49 does not need backward computation.
I1011 15:06:39.043212 38966 net.cpp:202] add10 does not need backward computation.
I1011 15:06:39.043216 38966 net.cpp:202] bn_scale48 does not need backward computation.
I1011 15:06:39.043220 38966 net.cpp:202] batch_norm48 does not need backward computation.
I1011 15:06:39.043222 38966 net.cpp:202] conv48 does not need backward computation.
I1011 15:06:39.043226 38966 net.cpp:202] relu32 does not need backward computation.
I1011 15:06:39.043229 38966 net.cpp:202] bn_scale47 does not need backward computation.
I1011 15:06:39.043232 38966 net.cpp:202] batch_norm47 does not need backward computation.
I1011 15:06:39.043236 38966 net.cpp:202] conv47 does not need backward computation.
I1011 15:06:39.043239 38966 net.cpp:202] relu31 does not need backward computation.
I1011 15:06:39.043242 38966 net.cpp:202] bn_scale46 does not need backward computation.
I1011 15:06:39.043246 38966 net.cpp:202] batch_norm46 does not need backward computation.
I1011 15:06:39.043334 38966 net.cpp:202] conv46 does not need backward computation.
I1011 15:06:39.043342 38966 net.cpp:202] add9_add9_0_split does not need backward computation.
I1011 15:06:39.043349 38966 net.cpp:202] add9 does not need backward computation.
I1011 15:06:39.043356 38966 net.cpp:202] bn_scale45 does not need backward computation.
I1011 15:06:39.043362 38966 net.cpp:202] batch_norm45 does not need backward computation.
I1011 15:06:39.043368 38966 net.cpp:202] conv45 does not need backward computation.
I1011 15:06:39.043375 38966 net.cpp:202] relu30 does not need backward computation.
I1011 15:06:39.043380 38966 net.cpp:202] bn_scale44 does not need backward computation.
I1011 15:06:39.043386 38966 net.cpp:202] batch_norm44 does not need backward computation.
I1011 15:06:39.043392 38966 net.cpp:202] conv44 does not need backward computation.
I1011 15:06:39.043398 38966 net.cpp:202] relu29 does not need backward computation.
I1011 15:06:39.043406 38966 net.cpp:202] bn_scale43 does not need backward computation.
I1011 15:06:39.043411 38966 net.cpp:202] batch_norm43 does not need backward computation.
I1011 15:06:39.043416 38966 net.cpp:202] conv43 does not need backward computation.
I1011 15:06:39.043422 38966 net.cpp:202] conv42_bn_scale42_0_split does not need backward computation.
I1011 15:06:39.043429 38966 net.cpp:202] bn_scale42 does not need backward computation.
I1011 15:06:39.043435 38966 net.cpp:202] batch_norm42 does not need backward computation.
I1011 15:06:39.043442 38966 net.cpp:202] conv42 does not need backward computation.
I1011 15:06:39.043447 38966 net.cpp:202] relu28 does not need backward computation.
I1011 15:06:39.043453 38966 net.cpp:202] bn_scale41 does not need backward computation.
I1011 15:06:39.043459 38966 net.cpp:202] batch_norm41 does not need backward computation.
I1011 15:06:39.043465 38966 net.cpp:202] conv41 does not need backward computation.
I1011 15:06:39.043471 38966 net.cpp:202] conv40_relu27_0_split does not need backward computation.
I1011 15:06:39.043478 38966 net.cpp:202] relu27 does not need backward computation.
I1011 15:06:39.043483 38966 net.cpp:202] bn_scale40 does not need backward computation.
I1011 15:06:39.043499 38966 net.cpp:202] batch_norm40 does not need backward computation.
I1011 15:06:39.043507 38966 net.cpp:202] conv40 does not need backward computation.
I1011 15:06:39.043519 38966 net.cpp:202] add8 does not need backward computation.
I1011 15:06:39.043525 38966 net.cpp:202] bn_scale39 does not need backward computation.
I1011 15:06:39.043531 38966 net.cpp:202] batch_norm39 does not need backward computation.
I1011 15:06:39.043537 38966 net.cpp:202] conv39 does not need backward computation.
I1011 15:06:39.043543 38966 net.cpp:202] relu26 does not need backward computation.
I1011 15:06:39.043550 38966 net.cpp:202] bn_scale38 does not need backward computation.
I1011 15:06:39.043555 38966 net.cpp:202] batch_norm38 does not need backward computation.
I1011 15:06:39.043560 38966 net.cpp:202] conv38 does not need backward computation.
I1011 15:06:39.043566 38966 net.cpp:202] relu25 does not need backward computation.
I1011 15:06:39.043573 38966 net.cpp:202] bn_scale37 does not need backward computation.
I1011 15:06:39.043578 38966 net.cpp:202] batch_norm37 does not need backward computation.
I1011 15:06:39.043584 38966 net.cpp:202] conv37 does not need backward computation.
I1011 15:06:39.043591 38966 net.cpp:202] add7_add7_0_split does not need backward computation.
I1011 15:06:39.043596 38966 net.cpp:202] add7 does not need backward computation.
I1011 15:06:39.043604 38966 net.cpp:202] bn_scale36 does not need backward computation.
I1011 15:06:39.043609 38966 net.cpp:202] batch_norm36 does not need backward computation.
I1011 15:06:39.043617 38966 net.cpp:202] conv36 does not need backward computation.
I1011 15:06:39.043622 38966 net.cpp:202] relu24 does not need backward computation.
I1011 15:06:39.043627 38966 net.cpp:202] bn_scale35 does not need backward computation.
I1011 15:06:39.043634 38966 net.cpp:202] batch_norm35 does not need backward computation.
I1011 15:06:39.043639 38966 net.cpp:202] conv35 does not need backward computation.
I1011 15:06:39.043645 38966 net.cpp:202] relu23 does not need backward computation.
I1011 15:06:39.043651 38966 net.cpp:202] bn_scale34 does not need backward computation.
I1011 15:06:39.043658 38966 net.cpp:202] batch_norm34 does not need backward computation.
I1011 15:06:39.043663 38966 net.cpp:202] conv34 does not need backward computation.
I1011 15:06:39.043669 38966 net.cpp:202] conv33_bn_scale33_0_split does not need backward computation.
I1011 15:06:39.043676 38966 net.cpp:202] bn_scale33 does not need backward computation.
I1011 15:06:39.043682 38966 net.cpp:202] batch_norm33 does not need backward computation.
I1011 15:06:39.043687 38966 net.cpp:202] conv33 does not need backward computation.
I1011 15:06:39.043694 38966 net.cpp:202] relu22 does not need backward computation.
I1011 15:06:39.043699 38966 net.cpp:202] bn_scale32 does not need backward computation.
I1011 15:06:39.043706 38966 net.cpp:202] batch_norm32 does not need backward computation.
I1011 15:06:39.043712 38966 net.cpp:202] conv32 does not need backward computation.
I1011 15:06:39.043718 38966 net.cpp:202] relu21 does not need backward computation.
I1011 15:06:39.043725 38966 net.cpp:202] bn_scale31 does not need backward computation.
I1011 15:06:39.043730 38966 net.cpp:202] batch_norm31 does not need backward computation.
I1011 15:06:39.043735 38966 net.cpp:202] conv31 does not need backward computation.
I1011 15:06:39.043741 38966 net.cpp:202] add6 does not need backward computation.
I1011 15:06:39.043750 38966 net.cpp:202] bn_scale30 does not need backward computation.
I1011 15:06:39.043756 38966 net.cpp:202] batch_norm30 does not need backward computation.
I1011 15:06:39.043761 38966 net.cpp:202] conv30 does not need backward computation.
I1011 15:06:39.043767 38966 net.cpp:202] relu20 does not need backward computation.
I1011 15:06:39.043773 38966 net.cpp:202] bn_scale29 does not need backward computation.
I1011 15:06:39.043779 38966 net.cpp:202] batch_norm29 does not need backward computation.
I1011 15:06:39.043785 38966 net.cpp:202] conv29 does not need backward computation.
I1011 15:06:39.043802 38966 net.cpp:202] relu19 does not need backward computation.
I1011 15:06:39.043810 38966 net.cpp:202] bn_scale28 does not need backward computation.
I1011 15:06:39.043815 38966 net.cpp:202] batch_norm28 does not need backward computation.
I1011 15:06:39.043820 38966 net.cpp:202] conv28 does not need backward computation.
I1011 15:06:39.043826 38966 net.cpp:202] add5_add5_0_split does not need backward computation.
I1011 15:06:39.043833 38966 net.cpp:202] add5 does not need backward computation.
I1011 15:06:39.043838 38966 net.cpp:202] bn_scale27 does not need backward computation.
I1011 15:06:39.043845 38966 net.cpp:202] batch_norm27 does not need backward computation.
I1011 15:06:39.043851 38966 net.cpp:202] conv27 does not need backward computation.
I1011 15:06:39.043857 38966 net.cpp:202] relu18 does not need backward computation.
I1011 15:06:39.043862 38966 net.cpp:202] bn_scale26 does not need backward computation.
I1011 15:06:39.043867 38966 net.cpp:202] batch_norm26 does not need backward computation.
I1011 15:06:39.043872 38966 net.cpp:202] conv26 does not need backward computation.
I1011 15:06:39.043877 38966 net.cpp:202] relu17 does not need backward computation.
I1011 15:06:39.043884 38966 net.cpp:202] bn_scale25 does not need backward computation.
I1011 15:06:39.043889 38966 net.cpp:202] batch_norm25 does not need backward computation.
I1011 15:06:39.043895 38966 net.cpp:202] conv25 does not need backward computation.
I1011 15:06:39.043901 38966 net.cpp:202] add4_add4_0_split does not need backward computation.
I1011 15:06:39.043906 38966 net.cpp:202] add4 does not need backward computation.
I1011 15:06:39.043911 38966 net.cpp:202] bn_scale24 does not need backward computation.
I1011 15:06:39.043916 38966 net.cpp:202] batch_norm24 does not need backward computation.
I1011 15:06:39.043921 38966 net.cpp:202] conv24 does not need backward computation.
I1011 15:06:39.043927 38966 net.cpp:202] relu16 does not need backward computation.
I1011 15:06:39.043932 38966 net.cpp:202] bn_scale23 does not need backward computation.
I1011 15:06:39.043937 38966 net.cpp:202] batch_norm23 does not need backward computation.
I1011 15:06:39.043942 38966 net.cpp:202] conv23 does not need backward computation.
I1011 15:06:39.043947 38966 net.cpp:202] relu15 does not need backward computation.
I1011 15:06:39.043952 38966 net.cpp:202] bn_scale22 does not need backward computation.
I1011 15:06:39.043958 38966 net.cpp:202] batch_norm22 does not need backward computation.
I1011 15:06:39.043964 38966 net.cpp:202] conv22 does not need backward computation.
I1011 15:06:39.043969 38966 net.cpp:202] conv21_bn_scale21_0_split does not need backward computation.
I1011 15:06:39.043974 38966 net.cpp:202] bn_scale21 does not need backward computation.
I1011 15:06:39.043979 38966 net.cpp:202] batch_norm21 does not need backward computation.
I1011 15:06:39.043984 38966 net.cpp:202] conv21 does not need backward computation.
I1011 15:06:39.043992 38966 net.cpp:202] relu14 does not need backward computation.
I1011 15:06:39.043996 38966 net.cpp:202] bn_scale20 does not need backward computation.
I1011 15:06:39.044001 38966 net.cpp:202] batch_norm20 does not need backward computation.
I1011 15:06:39.044008 38966 net.cpp:202] conv20 does not need backward computation.
I1011 15:06:39.044013 38966 net.cpp:202] relu13 does not need backward computation.
I1011 15:06:39.044018 38966 net.cpp:202] bn_scale19 does not need backward computation.
I1011 15:06:39.044023 38966 net.cpp:202] batch_norm19 does not need backward computation.
I1011 15:06:39.044028 38966 net.cpp:202] conv19 does not need backward computation.
I1011 15:06:39.044034 38966 net.cpp:202] add3 does not need backward computation.
I1011 15:06:39.044041 38966 net.cpp:202] bn_scale18 does not need backward computation.
I1011 15:06:39.044047 38966 net.cpp:202] batch_norm18 does not need backward computation.
I1011 15:06:39.044054 38966 net.cpp:202] conv18 does not need backward computation.
I1011 15:06:39.044059 38966 net.cpp:202] relu12 does not need backward computation.
I1011 15:06:39.044075 38966 net.cpp:202] bn_scale17 does not need backward computation.
I1011 15:06:39.044081 38966 net.cpp:202] batch_norm17 does not need backward computation.
I1011 15:06:39.044087 38966 net.cpp:202] conv17 does not need backward computation.
I1011 15:06:39.044093 38966 net.cpp:202] relu11 does not need backward computation.
I1011 15:06:39.044100 38966 net.cpp:202] bn_scale16 does not need backward computation.
I1011 15:06:39.044106 38966 net.cpp:202] batch_norm16 does not need backward computation.
I1011 15:06:39.044111 38966 net.cpp:202] conv16 does not need backward computation.
I1011 15:06:39.044118 38966 net.cpp:202] add2_add2_0_split does not need backward computation.
I1011 15:06:39.044124 38966 net.cpp:202] add2 does not need backward computation.
I1011 15:06:39.044131 38966 net.cpp:202] bn_scale15 does not need backward computation.
I1011 15:06:39.044137 38966 net.cpp:202] batch_norm15 does not need backward computation.
I1011 15:06:39.044143 38966 net.cpp:202] conv15 does not need backward computation.
I1011 15:06:39.044152 38966 net.cpp:202] relu10 does not need backward computation.
I1011 15:06:39.044158 38966 net.cpp:202] bn_scale14 does not need backward computation.
I1011 15:06:39.044164 38966 net.cpp:202] batch_norm14 does not need backward computation.
I1011 15:06:39.044170 38966 net.cpp:202] conv14 does not need backward computation.
I1011 15:06:39.044178 38966 net.cpp:202] relu9 does not need backward computation.
I1011 15:06:39.044183 38966 net.cpp:202] bn_scale13 does not need backward computation.
I1011 15:06:39.044189 38966 net.cpp:202] batch_norm13 does not need backward computation.
I1011 15:06:39.044194 38966 net.cpp:202] conv13 does not need backward computation.
I1011 15:06:39.044201 38966 net.cpp:202] conv12_bn_scale12_0_split does not need backward computation.
I1011 15:06:39.044207 38966 net.cpp:202] bn_scale12 does not need backward computation.
I1011 15:06:39.044214 38966 net.cpp:202] batch_norm12 does not need backward computation.
I1011 15:06:39.044219 38966 net.cpp:202] conv12 does not need backward computation.
I1011 15:06:39.044225 38966 net.cpp:202] relu8 does not need backward computation.
I1011 15:06:39.044231 38966 net.cpp:202] bn_scale11 does not need backward computation.
I1011 15:06:39.044237 38966 net.cpp:202] batch_norm11 does not need backward computation.
I1011 15:06:39.044245 38966 net.cpp:202] conv11 does not need backward computation.
I1011 15:06:39.044250 38966 net.cpp:202] relu7 does not need backward computation.
I1011 15:06:39.044256 38966 net.cpp:202] bn_scale10 does not need backward computation.
I1011 15:06:39.044262 38966 net.cpp:202] batch_norm10 does not need backward computation.
I1011 15:06:39.044268 38966 net.cpp:202] conv10 does not need backward computation.
I1011 15:06:39.044275 38966 net.cpp:202] add1 does not need backward computation.
I1011 15:06:39.044282 38966 net.cpp:202] bn_scale9 does not need backward computation.
I1011 15:06:39.044288 38966 net.cpp:202] batch_norm9 does not need backward computation.
I1011 15:06:39.044294 38966 net.cpp:202] conv9 does not need backward computation.
I1011 15:06:39.044301 38966 net.cpp:202] relu6 does not need backward computation.
I1011 15:06:39.044307 38966 net.cpp:202] bn_scale8 does not need backward computation.
I1011 15:06:39.044313 38966 net.cpp:202] batch_norm8 does not need backward computation.
I1011 15:06:39.044319 38966 net.cpp:202] conv8 does not need backward computation.
I1011 15:06:39.044325 38966 net.cpp:202] relu5 does not need backward computation.
I1011 15:06:39.044332 38966 net.cpp:202] bn_scale7 does not need backward computation.
I1011 15:06:39.044337 38966 net.cpp:202] batch_norm7 does not need backward computation.
I1011 15:06:39.044344 38966 net.cpp:202] conv7 does not need backward computation.
I1011 15:06:39.044350 38966 net.cpp:202] conv6_bn_scale6_0_split does not need backward computation.
I1011 15:06:39.044358 38966 net.cpp:202] bn_scale6 does not need backward computation.
I1011 15:06:39.044363 38966 net.cpp:202] batch_norm6 does not need backward computation.
I1011 15:06:39.044376 38966 net.cpp:202] conv6 does not need backward computation.
I1011 15:06:39.044384 38966 net.cpp:202] relu4 does not need backward computation.
I1011 15:06:39.044390 38966 net.cpp:202] bn_scale5 does not need backward computation.
I1011 15:06:39.044396 38966 net.cpp:202] batch_norm5 does not need backward computation.
I1011 15:06:39.044402 38966 net.cpp:202] conv5 does not need backward computation.
I1011 15:06:39.044409 38966 net.cpp:202] relu3 does not need backward computation.
I1011 15:06:39.044414 38966 net.cpp:202] bn_scale4 does not need backward computation.
I1011 15:06:39.044420 38966 net.cpp:202] batch_norm4 does not need backward computation.
I1011 15:06:39.044426 38966 net.cpp:202] conv4 does not need backward computation.
I1011 15:06:39.044433 38966 net.cpp:202] bn_scale3 does not need backward computation.
I1011 15:06:39.044440 38966 net.cpp:202] batch_norm3 does not need backward computation.
I1011 15:06:39.044445 38966 net.cpp:202] conv3 does not need backward computation.
I1011 15:06:39.044451 38966 net.cpp:202] relu2 does not need backward computation.
I1011 15:06:39.044457 38966 net.cpp:202] bn_scale2 does not need backward computation.
I1011 15:06:39.044463 38966 net.cpp:202] batch_norm2 does not need backward computation.
I1011 15:06:39.044469 38966 net.cpp:202] conv2 does not need backward computation.
I1011 15:06:39.044476 38966 net.cpp:202] relu1 does not need backward computation.
I1011 15:06:39.044482 38966 net.cpp:202] bn_scale1 does not need backward computation.
I1011 15:06:39.044488 38966 net.cpp:202] batch_norm1 does not need backward computation.
I1011 15:06:39.044494 38966 net.cpp:202] conv1 does not need backward computation.
I1011 15:06:39.044502 38966 net.cpp:202] data does not need backward computation.
I1011 15:06:39.044507 38966 net.cpp:244] This network produces output detection_eval
I1011 15:06:39.044610 38966 net.cpp:257] Network initialization done.
I1011 15:06:39.044998 38966 solver.cpp:70] Solver scaffolding done.
I1011 15:06:39.056614 38966 caffe.cpp:255] Starting Optimization
I1011 15:06:39.056634 38966 solver.cpp:303] Solving MobileNetV2
I1011 15:06:39.056640 38966 solver.cpp:304] Learning Rate Policy: multistep
I1011 15:06:39.063395 38966 blocking_queue.cpp:50] Waiting for data
I1011 15:06:39.904230 38966 solver.cpp:253] Iteration 0 (1.48607e-31 iter/s, 0.847504s/10 iters), loss = 367.629
I1011 15:06:39.904286 38966 solver.cpp:272]     Train net output #0: det_loss1 = 76.004 (* 1 = 76.004 loss)
I1011 15:06:39.904302 38966 solver.cpp:272]     Train net output #1: det_loss2 = 291.625 (* 1 = 291.625 loss)
I1011 15:06:39.904323 38966 sgd_solver.cpp:121] Iteration 0, lr = 0.0005
I1011 15:06:45.991000 38966 solver.cpp:253] Iteration 10 (1.64298 iter/s, 6.08649s/10 iters), loss = 60.2645
I1011 15:06:45.991060 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.4457 (* 1 = 1.4457 loss)
I1011 15:06:45.991070 38966 solver.cpp:272]     Train net output #1: det_loss2 = 17.8247 (* 1 = 17.8247 loss)
I1011 15:06:45.991076 38966 sgd_solver.cpp:121] Iteration 10, lr = 0.0005
I1011 15:06:49.147496 38966 yolov3_layer.cpp:532] noobj: 0.163475 obj: 0.0774825 iou: 0.175221 cat: 0.918541 recall: 0.0306607 recall75: 0.00534188 count: 26
I1011 15:06:53.150692 38966 solver.cpp:253] Iteration 20 (1.39677 iter/s, 7.15936s/10 iters), loss = 13.8033
I1011 15:06:53.150852 38966 solver.cpp:272]     Train net output #0: det_loss1 = 0.107711 (* 1 = 0.107711 loss)
I1011 15:06:53.150897 38966 solver.cpp:272]     Train net output #1: det_loss2 = 8.65513 (* 1 = 8.65513 loss)
I1011 15:06:53.150928 38966 sgd_solver.cpp:121] Iteration 20, lr = 0.0005
I1011 15:06:58.942760 38966 solver.cpp:253] Iteration 30 (1.72661 iter/s, 5.79171s/10 iters), loss = 9.82216
I1011 15:06:58.942826 38966 solver.cpp:272]     Train net output #0: det_loss1 = 0.0308443 (* 1 = 0.0308443 loss)
I1011 15:06:58.942842 38966 solver.cpp:272]     Train net output #1: det_loss2 = 8.51616 (* 1 = 8.51616 loss)
I1011 15:06:58.942855 38966 sgd_solver.cpp:121] Iteration 30, lr = 0.0005
I1011 15:06:59.201879 38966 yolov3_layer.cpp:532] noobj: 0.0185747 obj: 0.0168322 iou: 0.220064 cat: 0.985388 recall: 0.0539852 recall75: 0.00580247 count: 28
I1011 15:07:04.538554 38966 solver.cpp:253] Iteration 40 (1.78714 iter/s, 5.59553s/10 iters), loss = 9.0496
I1011 15:07:04.538626 38966 solver.cpp:272]     Train net output #0: det_loss1 = 0.0428637 (* 1 = 0.0428637 loss)
I1011 15:07:04.538636 38966 solver.cpp:272]     Train net output #1: det_loss2 = 11.5471 (* 1 = 11.5471 loss)
I1011 15:07:04.538646 38966 sgd_solver.cpp:121] Iteration 40, lr = 0.0005
I1011 15:07:09.259616 38966 yolov3_layer.cpp:532] noobj: 0.0116342 obj: 0.0154998 iou: 0.240213 cat: 0.991083 recall: 0.0788518 recall75: 0.00485009 count: 28
I1011 15:07:11.733388 38966 solver.cpp:253] Iteration 50 (1.38995 iter/s, 7.19451s/10 iters), loss = 9.21041
I1011 15:07:11.733456 38966 solver.cpp:272]     Train net output #0: det_loss1 = 0.0128588 (* 1 = 0.0128588 loss)
I1011 15:07:11.733466 38966 solver.cpp:272]     Train net output #1: det_loss2 = 8.14319 (* 1 = 8.14319 loss)
I1011 15:07:11.733474 38966 sgd_solver.cpp:121] Iteration 50, lr = 0.0005
I1011 15:07:17.598287 38966 solver.cpp:253] Iteration 60 (1.70514 iter/s, 5.86463s/10 iters), loss = 8.21859
I1011 15:07:17.598362 38966 solver.cpp:272]     Train net output #0: det_loss1 = 0.00861511 (* 1 = 0.00861511 loss)
I1011 15:07:17.598372 38966 solver.cpp:272]     Train net output #1: det_loss2 = 8.19165 (* 1 = 8.19165 loss)
I1011 15:07:17.598379 38966 sgd_solver.cpp:121] Iteration 60, lr = 0.0005
I1011 15:07:19.037312 38966 yolov3_layer.cpp:532] noobj: 0.00786302 obj: 0.0145958 iou: 0.246148 cat: 0.993914 recall: 0.0767399 recall75: 0.0114025 count: 27
I1011 15:07:23.452669 38966 solver.cpp:253] Iteration 70 (1.70821 iter/s, 5.8541s/10 iters), loss = 7.61284
I1011 15:07:23.452735 38966 solver.cpp:272]     Train net output #0: det_loss1 = 0.00886647 (* 1 = 0.00886647 loss)
I1011 15:07:23.452745 38966 solver.cpp:272]     Train net output #1: det_loss2 = 5.24078 (* 1 = 5.24078 loss)
I1011 15:07:23.452754 38966 sgd_solver.cpp:121] Iteration 70, lr = 0.0005
I1011 15:07:28.222971 38966 yolov3_layer.cpp:532] noobj: 0.00638712 obj: 0.0161428 iou: 0.257406 cat: 0.993369 recall: 0.105092 recall75: 0 count: 25
I1011 15:07:29.236655 38966 solver.cpp:253] Iteration 80 (1.72899 iter/s, 5.78372s/10 iters), loss = 6.61615
I1011 15:07:29.236718 38966 solver.cpp:272]     Train net output #0: det_loss1 = 0.00678535 (* 1 = 0.00678535 loss)
I1011 15:07:29.236727 38966 solver.cpp:272]     Train net output #1: det_loss2 = 4.63676 (* 1 = 4.63676 loss)
I1011 15:07:29.236735 38966 sgd_solver.cpp:121] Iteration 80, lr = 0.0005
I1011 15:07:35.742987 38966 solver.cpp:253] Iteration 90 (1.53703 iter/s, 6.50604s/10 iters), loss = 6.37444
I1011 15:07:35.743052 38966 solver.cpp:272]     Train net output #0: det_loss1 = 0.00310704 (* 1 = 0.00310704 loss)
I1011 15:07:35.743060 38966 solver.cpp:272]     Train net output #1: det_loss2 = 5.1139 (* 1 = 5.1139 loss)
I1011 15:07:35.743070 38966 sgd_solver.cpp:121] Iteration 90, lr = 0.0005
I1011 15:07:38.196714 38966 yolov3_layer.cpp:532] noobj: 0.00499164 obj: 0.0151476 iou: 0.272047 cat: 0.996473 recall: 0.113209 recall75: 0 count: 26
I1011 15:07:41.529445 38966 solver.cpp:253] Iteration 100 (1.72825 iter/s, 5.78618s/10 iters), loss = 6.18108
I1011 15:07:41.529597 38966 solver.cpp:272]     Train net output #0: det_loss1 = 0.00250745 (* 1 = 0.00250745 loss)
I1011 15:07:41.529608 38966 solver.cpp:272]     Train net output #1: det_loss2 = 7.53069 (* 1 = 7.53069 loss)
I1011 15:07:41.529615 38966 sgd_solver.cpp:121] Iteration 100, lr = 0.0005
I1011 15:07:47.539000 38966 solver.cpp:253] Iteration 110 (1.66412 iter/s, 6.0092s/10 iters), loss = 6.78012
I1011 15:07:47.539067 38966 solver.cpp:272]     Train net output #0: det_loss1 = 0.00204145 (* 1 = 0.00204145 loss)
I1011 15:07:47.539077 38966 solver.cpp:272]     Train net output #1: det_loss2 = 9.10747 (* 1 = 9.10747 loss)
I1011 15:07:47.539084 38966 sgd_solver.cpp:121] Iteration 110, lr = 0.0005
I1011 15:07:47.771989 38966 yolov3_layer.cpp:532] noobj: 0.00468388 obj: 0.0198113 iou: 0.243459 cat: 0.996681 recall: 0.0855514 recall75: 0.00222222 count: 27
I1011 15:07:52.959013 38966 solver.cpp:253] Iteration 120 (1.8451 iter/s, 5.41976s/10 iters), loss = 6.37236
I1011 15:07:52.959080 38966 solver.cpp:272]     Train net output #0: det_loss1 = 0.0014484 (* 1 = 0.0014484 loss)
I1011 15:07:52.959089 38966 solver.cpp:272]     Train net output #1: det_loss2 = 5.30074 (* 1 = 5.30074 loss)
I1011 15:07:52.959096 38966 sgd_solver.cpp:121] Iteration 120, lr = 0.0005
I1011 15:07:56.181951 38966 yolov3_layer.cpp:532] noobj: 0.00427411 obj: 0.0185191 iou: 0.25475 cat: 0.996956 recall: 0.111203 recall75: 0.00238095 count: 27
I1011 15:07:58.250586 38966 solver.cpp:253] Iteration 130 (1.88989 iter/s, 5.29132s/10 iters), loss = 6.03278
I1011 15:07:58.250659 38966 solver.cpp:272]     Train net output #0: det_loss1 = 0.00204577 (* 1 = 0.00204577 loss)
I1011 15:07:58.250670 38966 solver.cpp:272]     Train net output #1: det_loss2 = 6.08662 (* 1 = 6.08662 loss)
I1011 15:07:58.250679 38966 sgd_solver.cpp:121] Iteration 130, lr = 0.0005
I1011 15:08:04.814831 38966 solver.cpp:253] Iteration 140 (1.52347 iter/s, 6.56395s/10 iters), loss = 6.03867
I1011 15:08:04.814893 38966 solver.cpp:272]     Train net output #0: det_loss1 = 0.00150016 (* 1 = 0.00150016 loss)
I1011 15:08:04.814901 38966 solver.cpp:272]     Train net output #1: det_loss2 = 5.01234 (* 1 = 5.01234 loss)
I1011 15:08:04.814910 38966 sgd_solver.cpp:121] Iteration 140, lr = 0.0005
I1011 15:08:06.198216 38966 yolov3_layer.cpp:532] noobj: 0.00355101 obj: 0.0167426 iou: 0.302678 cat: 0.997839 recall: 0.151737 recall75: 0.00816611 count: 26
I1011 15:08:10.903898 38966 solver.cpp:253] Iteration 150 (1.64236 iter/s, 6.08879s/10 iters), loss = 6.22182
I1011 15:08:10.903956 38966 solver.cpp:272]     Train net output #0: det_loss1 = 0.00150439 (* 1 = 0.00150439 loss)
I1011 15:08:10.903966 38966 solver.cpp:272]     Train net output #1: det_loss2 = 5.99281 (* 1 = 5.99281 loss)
I1011 15:08:10.903975 38966 sgd_solver.cpp:121] Iteration 150, lr = 0.0005
I1011 15:08:16.641801 38966 yolov3_layer.cpp:532] noobj: 0.00312163 obj: 0.0165214 iou: 0.295348 cat: 0.997944 recall: 0.108508 recall75: 0.00525253 count: 28
I1011 15:08:17.637902 38966 solver.cpp:253] Iteration 160 (1.48507 iter/s, 6.7337s/10 iters), loss = 5.34029
I1011 15:08:17.637965 38966 solver.cpp:272]     Train net output #0: det_loss1 = 0.00062771 (* 1 = 0.00062771 loss)
I1011 15:08:17.637974 38966 solver.cpp:272]     Train net output #1: det_loss2 = 4.96111 (* 1 = 4.96111 loss)
I1011 15:08:17.637984 38966 sgd_solver.cpp:121] Iteration 160, lr = 0.0005
I1011 15:08:22.950336 38966 solver.cpp:253] Iteration 170 (1.88246 iter/s, 5.31219s/10 iters), loss = 5.28001
I1011 15:08:22.950389 38966 solver.cpp:272]     Train net output #0: det_loss1 = 0.000456869 (* 1 = 0.000456869 loss)
I1011 15:08:22.950398 38966 solver.cpp:272]     Train net output #1: det_loss2 = 5.41221 (* 1 = 5.41221 loss)
I1011 15:08:22.950405 38966 sgd_solver.cpp:121] Iteration 170, lr = 0.0005
I1011 15:08:25.614751 38966 yolov3_layer.cpp:532] noobj: 0.00319339 obj: 0.0231835 iou: 0.296318 cat: 0.998104 recall: 0.144947 recall75: 0.00567633 count: 27
I1011 15:08:28.866071 38966 solver.cpp:253] Iteration 180 (1.69048 iter/s, 5.91548s/10 iters), loss = 5.74392
I1011 15:08:28.866132 38966 solver.cpp:272]     Train net output #0: det_loss1 = 0.000544018 (* 1 = 0.000544018 loss)
I1011 15:08:28.866140 38966 solver.cpp:272]     Train net output #1: det_loss2 = 5.21662 (* 1 = 5.21662 loss)
I1011 15:08:28.866147 38966 sgd_solver.cpp:121] Iteration 180, lr = 0.0005
I1011 15:08:34.428102 38966 solver.cpp:253] Iteration 190 (1.79799 iter/s, 5.56177s/10 iters), loss = 5.11318
I1011 15:08:34.428174 38966 solver.cpp:272]     Train net output #0: det_loss1 = 0.000370153 (* 1 = 0.000370153 loss)
I1011 15:08:34.428185 38966 solver.cpp:272]     Train net output #1: det_loss2 = 6.09669 (* 1 = 6.09669 loss)
I1011 15:08:34.428194 38966 sgd_solver.cpp:121] Iteration 190, lr = 0.0005
I1011 15:08:34.735635 38966 yolov3_layer.cpp:532] noobj: 0.00317323 obj: 0.0269615 iou: 0.270426 cat: 0.998165 recall: 0.109743 recall75: 0.00617284 count: 27
I1011 15:08:40.088387 38966 solver.cpp:253] Iteration 200 (1.76678 iter/s, 5.66002s/10 iters), loss = 4.83831
I1011 15:08:40.088450 38966 solver.cpp:272]     Train net output #0: det_loss1 = 0.000493057 (* 1 = 0.000493057 loss)
I1011 15:08:40.088459 38966 solver.cpp:272]     Train net output #1: det_loss2 = 5.34783 (* 1 = 5.34783 loss)
I1011 15:08:40.088466 38966 sgd_solver.cpp:121] Iteration 200, lr = 0.0005
I1011 15:08:43.902015 38966 yolov3_layer.cpp:532] noobj: 0.00293513 obj: 0.0249295 iou: 0.288153 cat: 0.9985 recall: 0.12918 recall75: 0.00750237 count: 26
I1011 15:08:45.919271 38966 solver.cpp:253] Iteration 210 (1.71508 iter/s, 5.83062s/10 iters), loss = 4.93499
I1011 15:08:45.919332 38966 solver.cpp:272]     Train net output #0: det_loss1 = 0.000241928 (* 1 = 0.000241928 loss)
I1011 15:08:45.919342 38966 solver.cpp:272]     Train net output #1: det_loss2 = 5.42889 (* 1 = 5.42889 loss)
I1011 15:08:45.919348 38966 sgd_solver.cpp:121] Iteration 210, lr = 0.0005
I1011 15:08:51.961779 38966 solver.cpp:253] Iteration 220 (1.65502 iter/s, 6.04223s/10 iters), loss = 5.1377
I1011 15:08:51.962010 38966 solver.cpp:272]     Train net output #0: det_loss1 = 0.000438111 (* 1 = 0.000438111 loss)
I1011 15:08:51.962023 38966 solver.cpp:272]     Train net output #1: det_loss2 = 6.60691 (* 1 = 6.60691 loss)
I1011 15:08:51.962036 38966 sgd_solver.cpp:121] Iteration 220, lr = 0.0005
I1011 15:08:53.293635 38966 yolov3_layer.cpp:532] noobj: 0.00278305 obj: 0.0320894 iou: 0.269383 cat: 0.998692 recall: 0.126133 recall75: 0.0104959 count: 27
I1011 15:08:58.000512 38966 solver.cpp:253] Iteration 230 (1.6561 iter/s, 6.0383s/10 iters), loss = 5.70977
I1011 15:08:58.000576 38966 solver.cpp:272]     Train net output #0: det_loss1 = 0.000454836 (* 1 = 0.000454836 loss)
I1011 15:08:58.000584 38966 solver.cpp:272]     Train net output #1: det_loss2 = 9.73703 (* 1 = 9.73703 loss)
I1011 15:08:58.000592 38966 sgd_solver.cpp:121] Iteration 230, lr = 0.0005
I1011 15:09:03.738517 38966 yolov3_layer.cpp:532] noobj: 0.00226838 obj: 0.0240067 iou: 0.316511 cat: 0.998771 recall: 0.195798 recall75: 0.0214902 count: 27
I1011 15:09:04.844821 38966 solver.cpp:253] Iteration 240 (1.46113 iter/s, 6.844s/10 iters), loss = 5.38051
I1011 15:09:04.844887 38966 solver.cpp:272]     Train net output #0: det_loss1 = 0.000293969 (* 1 = 0.000293969 loss)
I1011 15:09:04.844897 38966 solver.cpp:272]     Train net output #1: det_loss2 = 4.51665 (* 1 = 4.51665 loss)
I1011 15:09:04.844905 38966 sgd_solver.cpp:121] Iteration 240, lr = 0.0005
I1011 15:09:11.466359 38966 solver.cpp:253] Iteration 250 (1.51029 iter/s, 6.62124s/10 iters), loss = 4.37404
I1011 15:09:11.466423 38966 solver.cpp:272]     Train net output #0: det_loss1 = 0.000169977 (* 1 = 0.000169977 loss)
I1011 15:09:11.466434 38966 solver.cpp:272]     Train net output #1: det_loss2 = 4.80954 (* 1 = 4.80954 loss)
I1011 15:09:11.466441 38966 sgd_solver.cpp:121] Iteration 250, lr = 0.0005
I1011 15:09:13.786367 38966 yolov3_layer.cpp:532] noobj: 0.00207633 obj: 0.0251113 iou: 0.32285 cat: 0.998179 recall: 0.192447 recall75: 0.0182326 count: 27
I1011 15:09:17.154597 38966 solver.cpp:253] Iteration 260 (1.7581 iter/s, 5.68797s/10 iters), loss = 4.60744
I1011 15:09:17.154685 38966 solver.cpp:272]     Train net output #0: det_loss1 = 0.000224902 (* 1 = 0.000224902 loss)
I1011 15:09:17.154695 38966 solver.cpp:272]     Train net output #1: det_loss2 = 4.65944 (* 1 = 4.65944 loss)
I1011 15:09:17.154706 38966 sgd_solver.cpp:121] Iteration 260, lr = 0.0005
I1011 15:09:23.868027 38966 solver.cpp:253] Iteration 270 (1.48962 iter/s, 6.71311s/10 iters), loss = 5.03633
I1011 15:09:23.868213 38966 solver.cpp:272]     Train net output #0: det_loss1 = 0.000183248 (* 1 = 0.000183248 loss)
I1011 15:09:23.868232 38966 solver.cpp:272]     Train net output #1: det_loss2 = 4.21401 (* 1 = 4.21401 loss)
I1011 15:09:23.868247 38966 sgd_solver.cpp:121] Iteration 270, lr = 0.0005
I1011 15:09:24.070858 38966 yolov3_layer.cpp:532] noobj: 0.00192754 obj: 0.025351 iou: 0.316099 cat: 0.998673 recall: 0.141003 recall75: 0.0119289 count: 25
I1011 15:09:30.573071 38966 solver.cpp:253] Iteration 280 (1.49151 iter/s, 6.70463s/10 iters), loss = 4.65561
I1011 15:09:30.573143 38966 solver.cpp:272]     Train net output #0: det_loss1 = 0.000135703 (* 1 = 0.000135703 loss)
I1011 15:09:30.573156 38966 solver.cpp:272]     Train net output #1: det_loss2 = 4.5107 (* 1 = 4.5107 loss)
I1011 15:09:30.573179 38966 sgd_solver.cpp:121] Iteration 280, lr = 0.0005
I1011 15:09:34.612252 38966 yolov3_layer.cpp:532] noobj: 0.00187032 obj: 0.0250973 iou: 0.331371 cat: 0.999063 recall: 0.18593 recall75: 0.00446429 count: 28
I1011 15:09:36.641782 38966 solver.cpp:253] Iteration 290 (1.64787 iter/s, 6.06844s/10 iters), loss = 4.33558
I1011 15:09:36.641854 38966 solver.cpp:272]     Train net output #0: det_loss1 = 9.98334e-05 (* 1 = 9.98334e-05 loss)
I1011 15:09:36.641865 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.40767 (* 1 = 3.40767 loss)
I1011 15:09:36.641875 38966 sgd_solver.cpp:121] Iteration 290, lr = 0.0005
I1011 15:09:42.459367 38966 solver.cpp:253] Iteration 300 (1.719 iter/s, 5.81732s/10 iters), loss = 4.17101
I1011 15:09:42.459435 38966 solver.cpp:272]     Train net output #0: det_loss1 = 9.71714e-05 (* 1 = 9.71714e-05 loss)
I1011 15:09:42.459445 38966 solver.cpp:272]     Train net output #1: det_loss2 = 4.97583 (* 1 = 4.97583 loss)
I1011 15:09:42.459453 38966 sgd_solver.cpp:121] Iteration 300, lr = 0.0005
I1011 15:09:44.161248 38966 yolov3_layer.cpp:532] noobj: 0.00203691 obj: 0.0314513 iou: 0.331799 cat: 0.999155 recall: 0.223305 recall75: 0.0128693 count: 27
I1011 15:09:48.916800 38966 solver.cpp:253] Iteration 310 (1.54868 iter/s, 6.45713s/10 iters), loss = 4.51602
I1011 15:09:48.916898 38966 solver.cpp:272]     Train net output #0: det_loss1 = 0.000115636 (* 1 = 0.000115636 loss)
I1011 15:09:48.916918 38966 solver.cpp:272]     Train net output #1: det_loss2 = 4.39917 (* 1 = 4.39917 loss)
I1011 15:09:48.916939 38966 sgd_solver.cpp:121] Iteration 310, lr = 0.0005
I1011 15:09:54.594142 38966 yolov3_layer.cpp:532] noobj: 0.00176928 obj: 0.0263381 iou: 0.326292 cat: 0.999321 recall: 0.181006 recall75: 0.0048172 count: 28
I1011 15:09:55.522712 38966 solver.cpp:253] Iteration 320 (1.51387 iter/s, 6.6056s/10 iters), loss = 4.92228
I1011 15:09:55.522768 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.9971e-05 (* 1 = 4.9971e-05 loss)
I1011 15:09:55.522776 38966 solver.cpp:272]     Train net output #1: det_loss2 = 4.1454 (* 1 = 4.1454 loss)
I1011 15:09:55.522783 38966 sgd_solver.cpp:121] Iteration 320, lr = 0.0005
I1011 15:10:01.529630 38966 solver.cpp:253] Iteration 330 (1.66482 iter/s, 6.00666s/10 iters), loss = 4.90361
I1011 15:10:01.529690 38966 solver.cpp:272]     Train net output #0: det_loss1 = 0.000117481 (* 1 = 0.000117481 loss)
I1011 15:10:01.529700 38966 solver.cpp:272]     Train net output #1: det_loss2 = 5.36891 (* 1 = 5.36891 loss)
I1011 15:10:01.529706 38966 sgd_solver.cpp:121] Iteration 330, lr = 0.0005
I1011 15:10:04.889932 38966 yolov3_layer.cpp:532] noobj: 0.00205166 obj: 0.0346561 iou: 0.300351 cat: 0.999169 recall: 0.18719 recall75: 0.005 count: 28
I1011 15:10:09.215119 38966 solver.cpp:253] Iteration 340 (1.30121 iter/s, 7.68516s/10 iters), loss = 4.90714
I1011 15:10:09.215183 38966 solver.cpp:272]     Train net output #0: det_loss1 = 7.27692e-05 (* 1 = 7.27692e-05 loss)
I1011 15:10:09.215190 38966 solver.cpp:272]     Train net output #1: det_loss2 = 5.47924 (* 1 = 5.47924 loss)
I1011 15:10:09.215198 38966 sgd_solver.cpp:121] Iteration 340, lr = 0.0005
I1011 15:10:16.581960 38966 solver.cpp:253] Iteration 350 (1.35749 iter/s, 7.36654s/10 iters), loss = 4.27174
I1011 15:10:16.582031 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.39669e-05 (* 1 = 4.39669e-05 loss)
I1011 15:10:16.582038 38966 solver.cpp:272]     Train net output #1: det_loss2 = 4.71099 (* 1 = 4.71099 loss)
I1011 15:10:16.582046 38966 sgd_solver.cpp:121] Iteration 350, lr = 0.0005
I1011 15:10:16.793259 38966 yolov3_layer.cpp:532] noobj: 0.00139902 obj: 0.0267971 iou: 0.359183 cat: 0.999172 recall: 0.242357 recall75: 0.0189152 count: 28
I1011 15:10:23.032138 38966 solver.cpp:253] Iteration 360 (1.55042 iter/s, 6.44988s/10 iters), loss = 4.2295
I1011 15:10:23.032205 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.30349e-05 (* 1 = 5.30349e-05 loss)
I1011 15:10:23.032217 38966 solver.cpp:272]     Train net output #1: det_loss2 = 4.7343 (* 1 = 4.7343 loss)
I1011 15:10:23.032223 38966 sgd_solver.cpp:121] Iteration 360, lr = 0.0005
I1011 15:10:27.383800 38966 yolov3_layer.cpp:532] noobj: 0.00158112 obj: 0.0316187 iou: 0.34353 cat: 0.999468 recall: 0.219854 recall75: 0.0051358 count: 27
I1011 15:10:29.830626 38966 solver.cpp:253] Iteration 370 (1.47098 iter/s, 6.79819s/10 iters), loss = 4.43676
I1011 15:10:29.830690 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.27139e-05 (* 1 = 3.27139e-05 loss)
I1011 15:10:29.830699 38966 solver.cpp:272]     Train net output #1: det_loss2 = 5.61981 (* 1 = 5.61981 loss)
I1011 15:10:29.830706 38966 sgd_solver.cpp:121] Iteration 370, lr = 0.0005
I1011 15:10:36.123603 38966 solver.cpp:253] Iteration 380 (1.58914 iter/s, 6.29269s/10 iters), loss = 4.15867
I1011 15:10:36.123664 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.61764e-05 (* 1 = 4.61764e-05 loss)
I1011 15:10:36.123675 38966 solver.cpp:272]     Train net output #1: det_loss2 = 4.76762 (* 1 = 4.76762 loss)
I1011 15:10:36.123684 38966 sgd_solver.cpp:121] Iteration 380, lr = 0.0005
I1011 15:10:37.710611 38966 yolov3_layer.cpp:532] noobj: 0.00177245 obj: 0.039312 iou: 0.333151 cat: 0.9994 recall: 0.180119 recall75: 0.00719816 count: 27
I1011 15:10:42.824616 38966 solver.cpp:253] Iteration 390 (1.49238 iter/s, 6.70072s/10 iters), loss = 4.56795
I1011 15:10:42.824673 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.46128e-05 (* 1 = 2.46128e-05 loss)
I1011 15:10:42.824682 38966 solver.cpp:272]     Train net output #1: det_loss2 = 5.47371 (* 1 = 5.47371 loss)
I1011 15:10:42.824690 38966 sgd_solver.cpp:121] Iteration 390, lr = 0.0005
I1011 15:10:47.934574 38966 yolov3_layer.cpp:532] noobj: 0.00167409 obj: 0.0393289 iou: 0.335188 cat: 0.999436 recall: 0.201488 recall75: 0.012851 count: 27
I1011 15:10:49.084776 38966 solver.cpp:253] Iteration 400 (1.59747 iter/s, 6.25989s/10 iters), loss = 4.39305
I1011 15:10:49.084836 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.06252e-05 (* 1 = 3.06252e-05 loss)
I1011 15:10:49.084859 38966 solver.cpp:272]     Train net output #1: det_loss2 = 4.12386 (* 1 = 4.12386 loss)
I1011 15:10:49.084870 38966 sgd_solver.cpp:121] Iteration 400, lr = 0.0005
I1011 15:10:55.883821 38966 solver.cpp:253] Iteration 410 (1.47086 iter/s, 6.79876s/10 iters), loss = 4.03604
I1011 15:10:55.883880 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.23847e-05 (* 1 = 2.23847e-05 loss)
I1011 15:10:55.883889 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.88638 (* 1 = 3.88638 loss)
I1011 15:10:55.883898 38966 sgd_solver.cpp:121] Iteration 410, lr = 0.0005
I1011 15:10:58.410739 38966 yolov3_layer.cpp:532] noobj: 0.00146675 obj: 0.0337554 iou: 0.339112 cat: 0.999558 recall: 0.197263 recall75: 0.00729971 count: 26
I1011 15:11:01.528010 38966 solver.cpp:253] Iteration 420 (1.77182 iter/s, 5.64393s/10 iters), loss = 4.45622
I1011 15:11:01.528105 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.52716e-05 (* 1 = 1.52716e-05 loss)
I1011 15:11:01.528121 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.40782 (* 1 = 3.40782 loss)
I1011 15:11:01.528136 38966 sgd_solver.cpp:121] Iteration 420, lr = 0.0005
I1011 15:11:06.942979 38966 solver.cpp:253] Iteration 430 (1.84683 iter/s, 5.41468s/10 iters), loss = 3.99014
I1011 15:11:06.943045 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.48198e-05 (* 1 = 1.48198e-05 loss)
I1011 15:11:06.943056 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.66207 (* 1 = 3.66207 loss)
I1011 15:11:06.943063 38966 sgd_solver.cpp:121] Iteration 430, lr = 0.0005
I1011 15:11:07.142472 38966 yolov3_layer.cpp:532] noobj: 0.00209757 obj: 0.04258 iou: 0.311176 cat: 0.999345 recall: 0.174249 recall75: 0.00979127 count: 26
I1011 15:11:12.284457 38966 solver.cpp:253] Iteration 440 (1.87223 iter/s, 5.34123s/10 iters), loss = 4.35473
I1011 15:11:12.284524 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.74599e-05 (* 1 = 1.74599e-05 loss)
I1011 15:11:12.284535 38966 solver.cpp:272]     Train net output #1: det_loss2 = 4.31171 (* 1 = 4.31171 loss)
I1011 15:11:12.284556 38966 sgd_solver.cpp:121] Iteration 440, lr = 0.0005
I1011 15:11:15.565289 38966 yolov3_layer.cpp:532] noobj: 0.00224738 obj: 0.0504029 iou: 0.310008 cat: 0.999582 recall: 0.145749 recall75: 0.0107226 count: 28
I1011 15:11:17.692476 38966 solver.cpp:253] Iteration 450 (1.84919 iter/s, 5.40778s/10 iters), loss = 3.85814
I1011 15:11:17.692529 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.79301e-05 (* 1 = 1.79301e-05 loss)
I1011 15:11:17.692553 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.47123 (* 1 = 3.47123 loss)
I1011 15:11:17.692564 38966 sgd_solver.cpp:121] Iteration 450, lr = 0.0005
I1011 15:11:23.800663 38966 solver.cpp:253] Iteration 460 (1.63722 iter/s, 6.10793s/10 iters), loss = 4.42261
I1011 15:11:23.800729 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.5655e-05 (* 1 = 1.5655e-05 loss)
I1011 15:11:23.800741 38966 solver.cpp:272]     Train net output #1: det_loss2 = 4.5124 (* 1 = 4.5124 loss)
I1011 15:11:23.800781 38966 sgd_solver.cpp:121] Iteration 460, lr = 0.0005
I1011 15:11:25.180877 38966 yolov3_layer.cpp:532] noobj: 0.00180048 obj: 0.0495082 iou: 0.342884 cat: 0.999639 recall: 0.225933 recall75: 0.0104185 count: 28
I1011 15:11:29.229935 38966 solver.cpp:253] Iteration 470 (1.84195 iter/s, 5.42902s/10 iters), loss = 3.61519
I1011 15:11:29.230581 38966 solver.cpp:272]     Train net output #0: det_loss1 = 8.46977e-06 (* 1 = 8.46977e-06 loss)
I1011 15:11:29.230597 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.00623 (* 1 = 3.00623 loss)
I1011 15:11:29.230608 38966 sgd_solver.cpp:121] Iteration 470, lr = 0.0005
I1011 15:11:34.039633 38966 yolov3_layer.cpp:532] noobj: 0.00199487 obj: 0.0497156 iou: 0.319465 cat: 0.999725 recall: 0.144028 recall75: 0.0167387 count: 26
I1011 15:11:34.843907 38966 solver.cpp:253] Iteration 480 (1.78154 iter/s, 5.61313s/10 iters), loss = 4.20143
I1011 15:11:34.844003 38966 solver.cpp:272]     Train net output #0: det_loss1 = 9.59148e-06 (* 1 = 9.59148e-06 loss)
I1011 15:11:34.844031 38966 solver.cpp:272]     Train net output #1: det_loss2 = 4.88624 (* 1 = 4.88624 loss)
I1011 15:11:34.844045 38966 sgd_solver.cpp:121] Iteration 480, lr = 0.0005
I1011 15:11:40.422365 38966 solver.cpp:253] Iteration 490 (1.7927 iter/s, 5.57819s/10 iters), loss = 4.03346
I1011 15:11:40.422428 38966 solver.cpp:272]     Train net output #0: det_loss1 = 8.12293e-06 (* 1 = 8.12293e-06 loss)
I1011 15:11:40.422436 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.13976 (* 1 = 3.13976 loss)
I1011 15:11:40.422443 38966 sgd_solver.cpp:121] Iteration 490, lr = 0.0005
I1011 15:11:42.664882 38966 yolov3_layer.cpp:532] noobj: 0.00219601 obj: 0.0675128 iou: 0.294609 cat: 0.999715 recall: 0.148022 recall75: 0.01041 count: 26
I1011 15:11:46.090265 38966 solver.cpp:253] Iteration 500 (1.7644 iter/s, 5.66764s/10 iters), loss = 3.55704
I1011 15:11:46.090333 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.89738e-05 (* 1 = 1.89738e-05 loss)
I1011 15:11:46.090343 38966 solver.cpp:272]     Train net output #1: det_loss2 = 4.21759 (* 1 = 4.21759 loss)
I1011 15:11:46.090353 38966 sgd_solver.cpp:121] Iteration 500, lr = 0.0005
I1011 15:11:53.595255 38966 solver.cpp:253] Iteration 510 (1.3325 iter/s, 7.50467s/10 iters), loss = 4.60063
I1011 15:11:53.595324 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.01108e-05 (* 1 = 1.01108e-05 loss)
I1011 15:11:53.595332 38966 solver.cpp:272]     Train net output #1: det_loss2 = 4.543 (* 1 = 4.543 loss)
I1011 15:11:53.595340 38966 sgd_solver.cpp:121] Iteration 510, lr = 0.0005
I1011 15:11:53.811877 38966 yolov3_layer.cpp:532] noobj: 0.00150054 obj: 0.0459284 iou: 0.345244 cat: 0.9997 recall: 0.248156 recall75: 0.0101983 count: 29
I1011 15:12:00.496335 38966 solver.cpp:253] Iteration 520 (1.44911 iter/s, 6.90077s/10 iters), loss = 4.22197
I1011 15:12:00.496533 38966 solver.cpp:272]     Train net output #0: det_loss1 = 6.50799e-06 (* 1 = 6.50799e-06 loss)
I1011 15:12:00.496546 38966 solver.cpp:272]     Train net output #1: det_loss2 = 4.70628 (* 1 = 4.70628 loss)
I1011 15:12:00.496552 38966 sgd_solver.cpp:121] Iteration 520, lr = 0.0005
I1011 15:12:03.973026 38966 yolov3_layer.cpp:532] noobj: 0.00144446 obj: 0.0537531 iou: 0.371187 cat: 0.99971 recall: 0.272387 recall75: 0.0340105 count: 26
I1011 15:12:06.149627 38966 solver.cpp:253] Iteration 530 (1.769 iter/s, 5.6529s/10 iters), loss = 3.51418
I1011 15:12:06.149693 38966 solver.cpp:272]     Train net output #0: det_loss1 = 6.53773e-06 (* 1 = 6.53773e-06 loss)
I1011 15:12:06.149701 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.84347 (* 1 = 3.84347 loss)
I1011 15:12:06.149710 38966 sgd_solver.cpp:121] Iteration 530, lr = 0.0005
I1011 15:12:12.271317 38966 solver.cpp:253] Iteration 540 (1.63361 iter/s, 6.1214s/10 iters), loss = 4.13508
I1011 15:12:12.271381 38966 solver.cpp:272]     Train net output #0: det_loss1 = 6.1443e-06 (* 1 = 6.1443e-06 loss)
I1011 15:12:12.271390 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.78665 (* 1 = 3.78665 loss)
I1011 15:12:12.271399 38966 sgd_solver.cpp:121] Iteration 540, lr = 0.0005
I1011 15:12:13.701752 38966 yolov3_layer.cpp:532] noobj: 0.00154479 obj: 0.0558047 iou: 0.340509 cat: 0.999724 recall: 0.242149 recall75: 0.0117124 count: 27
I1011 15:12:18.133412 38966 solver.cpp:253] Iteration 550 (1.70595 iter/s, 5.86183s/10 iters), loss = 3.85108
I1011 15:12:18.133479 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.76989e-06 (* 1 = 4.76989e-06 loss)
I1011 15:12:18.133489 38966 solver.cpp:272]     Train net output #1: det_loss2 = 5.77903 (* 1 = 5.77903 loss)
I1011 15:12:18.133497 38966 sgd_solver.cpp:121] Iteration 550, lr = 0.0005
I1011 15:12:23.134552 38966 yolov3_layer.cpp:532] noobj: 0.00168957 obj: 0.0574684 iou: 0.351167 cat: 0.999742 recall: 0.241373 recall75: 0.00546265 count: 28
I1011 15:12:24.104578 38966 solver.cpp:253] Iteration 560 (1.67479 iter/s, 5.97089s/10 iters), loss = 4.01148
I1011 15:12:24.104658 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.25768e-06 (* 1 = 4.25768e-06 loss)
I1011 15:12:24.104674 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.33886 (* 1 = 3.33886 loss)
I1011 15:12:24.104686 38966 sgd_solver.cpp:121] Iteration 560, lr = 0.0005
I1011 15:12:29.828410 38966 solver.cpp:253] Iteration 570 (1.74716 iter/s, 5.72356s/10 iters), loss = 3.56571
I1011 15:12:29.828462 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.22381e-06 (* 1 = 4.22381e-06 loss)
I1011 15:12:29.828471 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.1162 (* 1 = 3.1162 loss)
I1011 15:12:29.828480 38966 sgd_solver.cpp:121] Iteration 570, lr = 0.0005
I1011 15:12:32.651932 38966 yolov3_layer.cpp:532] noobj: 0.00171871 obj: 0.0564374 iou: 0.321872 cat: 0.999798 recall: 0.192173 recall75: 0.00461967 count: 27
I1011 15:12:36.210577 38966 solver.cpp:253] Iteration 580 (1.56694 iter/s, 6.38188s/10 iters), loss = 3.86976
I1011 15:12:36.210655 38966 solver.cpp:272]     Train net output #0: det_loss1 = 6.27941e-06 (* 1 = 6.27941e-06 loss)
I1011 15:12:36.210664 38966 solver.cpp:272]     Train net output #1: det_loss2 = 5.277 (* 1 = 5.277 loss)
I1011 15:12:36.210674 38966 sgd_solver.cpp:121] Iteration 580, lr = 0.0005
I1011 15:12:43.714498 38966 solver.cpp:253] Iteration 590 (1.3327 iter/s, 7.50357s/10 iters), loss = 4.06638
I1011 15:12:43.714586 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.29436e-06 (* 1 = 4.29436e-06 loss)
I1011 15:12:43.714601 38966 solver.cpp:272]     Train net output #1: det_loss2 = 4.73827 (* 1 = 4.73827 loss)
I1011 15:12:43.714613 38966 sgd_solver.cpp:121] Iteration 590, lr = 0.0005
I1011 15:12:43.994724 38966 yolov3_layer.cpp:532] noobj: 0.00133961 obj: 0.0457367 iou: 0.352206 cat: 0.999806 recall: 0.285743 recall75: 0.0195801 count: 28
I1011 15:12:50.652245 38966 solver.cpp:253] Iteration 600 (1.44146 iter/s, 6.93743s/10 iters), loss = 3.31538
I1011 15:12:50.652304 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.18949e-06 (* 1 = 5.18949e-06 loss)
I1011 15:12:50.652313 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.58844 (* 1 = 3.58844 loss)
I1011 15:12:50.652321 38966 sgd_solver.cpp:121] Iteration 600, lr = 0.0005
I1011 15:12:55.437372 38966 yolov3_layer.cpp:532] noobj: 0.249628 obj: 3.33735e-05 iou: 0.527081 cat: 0.499975 recall: 1 recall75: 0 count: 1
I1011 15:12:55.489852 38966 yolov3_layer.cpp:532] noobj: 0.00115895 obj: 0.0594152 iou: 0.384381 cat: 0.999806 recall: 0.322859 recall75: 0.0274975 count: 27
I1011 15:12:57.988771 38966 solver.cpp:253] Iteration 610 (1.3631 iter/s, 7.33621s/10 iters), loss = 3.35333
I1011 15:12:57.988839 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.40631e-06 (* 1 = 2.40631e-06 loss)
I1011 15:12:57.988849 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.59952 (* 1 = 3.59952 loss)
I1011 15:12:57.988857 38966 sgd_solver.cpp:121] Iteration 610, lr = 0.0005
I1011 15:13:04.449851 38966 solver.cpp:253] Iteration 620 (1.5478 iter/s, 6.46078s/10 iters), loss = 4.17843
I1011 15:13:04.450119 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.31686e-06 (* 1 = 4.31686e-06 loss)
I1011 15:13:04.450131 38966 solver.cpp:272]     Train net output #1: det_loss2 = 4.4337 (* 1 = 4.4337 loss)
I1011 15:13:04.450139 38966 sgd_solver.cpp:121] Iteration 620, lr = 0.0005
I1011 15:13:06.179497 38966 yolov3_layer.cpp:532] noobj: 0.00157579 obj: 0.0609925 iou: 0.35078 cat: 0.999791 recall: 0.243847 recall75: 0.0045977 count: 29
I1011 15:13:11.781472 38966 solver.cpp:253] Iteration 630 (1.36405 iter/s, 7.3311s/10 iters), loss = 3.11626
I1011 15:13:11.781549 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.15261e-06 (* 1 = 2.15261e-06 loss)
I1011 15:13:11.781563 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.81504 (* 1 = 3.81504 loss)
I1011 15:13:11.781584 38966 sgd_solver.cpp:121] Iteration 630, lr = 0.0005
I1011 15:13:16.777864 38966 yolov3_layer.cpp:532] noobj: 0.00126885 obj: 0.0586853 iou: 0.373252 cat: 0.999856 recall: 0.295193 recall75: 0.0358757 count: 25
I1011 15:13:17.917771 38966 solver.cpp:253] Iteration 640 (1.62972 iter/s, 6.13601s/10 iters), loss = 3.50642
I1011 15:13:17.917836 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.53061e-06 (* 1 = 2.53061e-06 loss)
I1011 15:13:17.917845 38966 solver.cpp:272]     Train net output #1: det_loss2 = 4.09448 (* 1 = 4.09448 loss)
I1011 15:13:17.917855 38966 sgd_solver.cpp:121] Iteration 640, lr = 0.0005
I1011 15:13:24.805828 38966 solver.cpp:253] Iteration 650 (1.45185 iter/s, 6.88775s/10 iters), loss = 3.87851
I1011 15:13:24.805892 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.9589e-06 (* 1 = 1.9589e-06 loss)
I1011 15:13:24.805902 38966 solver.cpp:272]     Train net output #1: det_loss2 = 4.07155 (* 1 = 4.07155 loss)
I1011 15:13:24.805909 38966 sgd_solver.cpp:121] Iteration 650, lr = 0.0005
I1011 15:13:27.092875 38966 yolov3_layer.cpp:532] noobj: 0.00139745 obj: 0.0625471 iou: 0.355395 cat: 0.999757 recall: 0.261673 recall75: 0.00686966 count: 29
I1011 15:13:30.623056 38966 solver.cpp:253] Iteration 660 (1.71911 iter/s, 5.81696s/10 iters), loss = 3.4368
I1011 15:13:30.623113 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.31661e-06 (* 1 = 2.31661e-06 loss)
I1011 15:13:30.623136 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.54651 (* 1 = 2.54651 loss)
I1011 15:13:30.623148 38966 sgd_solver.cpp:121] Iteration 660, lr = 0.0005
I1011 15:13:38.017498 38966 solver.cpp:253] Iteration 670 (1.35242 iter/s, 7.39413s/10 iters), loss = 3.49926
I1011 15:13:38.017694 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.40202e-06 (* 1 = 1.40202e-06 loss)
I1011 15:13:38.017710 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.54088 (* 1 = 2.54088 loss)
I1011 15:13:38.017724 38966 sgd_solver.cpp:121] Iteration 670, lr = 0.0005
I1011 15:13:38.232398 38966 yolov3_layer.cpp:532] noobj: 0.00125022 obj: 0.0653651 iou: 0.401663 cat: 0.999697 recall: 0.320583 recall75: 0.0263864 count: 26
I1011 15:13:44.138077 38966 solver.cpp:253] Iteration 680 (1.63394 iter/s, 6.12017s/10 iters), loss = 3.02215
I1011 15:13:44.138160 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.77923e-06 (* 1 = 1.77923e-06 loss)
I1011 15:13:44.138171 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.05102 (* 1 = 3.05102 loss)
I1011 15:13:44.138183 38966 sgd_solver.cpp:121] Iteration 680, lr = 0.0005
I1011 15:13:47.734551 38966 yolov3_layer.cpp:532] noobj: 0.00162469 obj: 0.0873379 iou: 0.372484 cat: 0.99984 recall: 0.28214 recall75: 0.0235663 count: 26
I1011 15:13:50.175822 38966 solver.cpp:253] Iteration 690 (1.65633 iter/s, 6.03746s/10 iters), loss = 3.51014
I1011 15:13:50.175886 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.92613e-06 (* 1 = 1.92613e-06 loss)
I1011 15:13:50.175896 38966 solver.cpp:272]     Train net output #1: det_loss2 = 4.319 (* 1 = 4.319 loss)
I1011 15:13:50.175905 38966 sgd_solver.cpp:121] Iteration 690, lr = 0.0005
I1011 15:13:57.845355 38966 solver.cpp:253] Iteration 700 (1.30392 iter/s, 7.6692s/10 iters), loss = 3.78127
I1011 15:13:57.845427 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.58404e-06 (* 1 = 1.58404e-06 loss)
I1011 15:13:57.845438 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.26086 (* 1 = 2.26086 loss)
I1011 15:13:57.845445 38966 sgd_solver.cpp:121] Iteration 700, lr = 0.0005
I1011 15:13:59.387365 38966 yolov3_layer.cpp:532] noobj: 0.0012798 obj: 0.0647621 iou: 0.389707 cat: 0.99988 recall: 0.301779 recall75: 0.0210927 count: 29
I1011 15:14:04.239454 38966 solver.cpp:253] Iteration 710 (1.56401 iter/s, 6.3938s/10 iters), loss = 3.51439
I1011 15:14:04.239521 38966 solver.cpp:272]     Train net output #0: det_loss1 = 9.79324e-07 (* 1 = 9.79324e-07 loss)
I1011 15:14:04.239531 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.09531 (* 1 = 3.09531 loss)
I1011 15:14:04.239539 38966 sgd_solver.cpp:121] Iteration 710, lr = 0.0005
I1011 15:14:09.018095 38966 yolov3_layer.cpp:532] noobj: 0.00162003 obj: 0.0855629 iou: 0.360599 cat: 0.99987 recall: 0.290868 recall75: 0.0245288 count: 28
I1011 15:14:09.929993 38966 solver.cpp:253] Iteration 720 (1.75738 iter/s, 5.69027s/10 iters), loss = 3.27398
I1011 15:14:09.930069 38966 solver.cpp:272]     Train net output #0: det_loss1 = 8.7962e-07 (* 1 = 8.7962e-07 loss)
I1011 15:14:09.930078 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.51802 (* 1 = 2.51802 loss)
I1011 15:14:09.930085 38966 sgd_solver.cpp:121] Iteration 720, lr = 0.0005
I1011 15:14:16.412336 38966 solver.cpp:253] Iteration 730 (1.54272 iter/s, 6.48205s/10 iters), loss = 3.32313
I1011 15:14:16.412400 38966 solver.cpp:272]     Train net output #0: det_loss1 = 9.10392e-07 (* 1 = 9.10392e-07 loss)
I1011 15:14:16.412408 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.83522 (* 1 = 3.83522 loss)
I1011 15:14:16.412416 38966 sgd_solver.cpp:121] Iteration 730, lr = 0.0005
I1011 15:14:19.507153 38966 yolov3_layer.cpp:532] noobj: 0.00133643 obj: 0.0848658 iou: 0.374384 cat: 0.999857 recall: 0.286556 recall75: 0.0295186 count: 28
I1011 15:14:23.360604 38966 solver.cpp:253] Iteration 740 (1.43927 iter/s, 6.94796s/10 iters), loss = 3.5175
I1011 15:14:23.360669 38966 solver.cpp:272]     Train net output #0: det_loss1 = 7.82427e-07 (* 1 = 7.82427e-07 loss)
I1011 15:14:23.360678 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.04715 (* 1 = 3.04715 loss)
I1011 15:14:23.360687 38966 sgd_solver.cpp:121] Iteration 740, lr = 0.0005
I1011 15:14:29.477324 38966 solver.cpp:253] Iteration 750 (1.63494 iter/s, 6.11644s/10 iters), loss = 3.27516
I1011 15:14:29.477386 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.66039e-07 (* 1 = 5.66039e-07 loss)
I1011 15:14:29.477394 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.97572 (* 1 = 2.97572 loss)
I1011 15:14:29.477402 38966 sgd_solver.cpp:121] Iteration 750, lr = 0.0005
I1011 15:14:29.675956 38966 yolov3_layer.cpp:532] noobj: 0.00134123 obj: 0.0729817 iou: 0.396264 cat: 0.999886 recall: 0.36467 recall75: 0.0269981 count: 27
I1011 15:14:35.713680 38966 solver.cpp:253] Iteration 760 (1.60358 iter/s, 6.23606s/10 iters), loss = 3.27616
I1011 15:14:35.713758 38966 solver.cpp:272]     Train net output #0: det_loss1 = 8.56035e-07 (* 1 = 8.56035e-07 loss)
I1011 15:14:35.713769 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.01443 (* 1 = 3.01443 loss)
I1011 15:14:35.713788 38966 sgd_solver.cpp:121] Iteration 760, lr = 0.0005
I1011 15:14:40.042513 38966 yolov3_layer.cpp:532] noobj: 0.00140914 obj: 0.0822385 iou: 0.3837 cat: 0.999841 recall: 0.347047 recall75: 0.0218337 count: 28
I1011 15:14:42.355446 38966 solver.cpp:253] Iteration 770 (1.50569 iter/s, 6.64146s/10 iters), loss = 3.3306
I1011 15:14:42.355509 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.16478e-07 (* 1 = 4.16478e-07 loss)
I1011 15:14:42.355518 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.63435 (* 1 = 2.63435 loss)
I1011 15:14:42.355525 38966 sgd_solver.cpp:121] Iteration 770, lr = 0.0005
I1011 15:14:48.076561 38966 solver.cpp:253] Iteration 780 (1.74799 iter/s, 5.72085s/10 iters), loss = 3.49762
I1011 15:14:48.076627 38966 solver.cpp:272]     Train net output #0: det_loss1 = 7.62456e-07 (* 1 = 7.62456e-07 loss)
I1011 15:14:48.076635 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.23328 (* 1 = 3.23328 loss)
I1011 15:14:48.076643 38966 sgd_solver.cpp:121] Iteration 780, lr = 0.0005
I1011 15:14:49.820834 38966 yolov3_layer.cpp:532] noobj: 0.00173044 obj: 0.0957311 iou: 0.376406 cat: 0.999899 recall: 0.297914 recall75: 0.0293545 count: 27
I1011 15:14:55.551887 38966 solver.cpp:253] Iteration 790 (1.33779 iter/s, 7.47499s/10 iters), loss = 3.55036
I1011 15:14:55.551947 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.65925e-07 (* 1 = 4.65925e-07 loss)
I1011 15:14:55.551956 38966 solver.cpp:272]     Train net output #1: det_loss2 = 4.87825 (* 1 = 4.87825 loss)
I1011 15:14:55.551964 38966 sgd_solver.cpp:121] Iteration 790, lr = 0.0005
I1011 15:15:00.168524 38966 yolov3_layer.cpp:532] noobj: 0.00135587 obj: 0.0937213 iou: 0.391465 cat: 0.999921 recall: 0.322866 recall75: 0.0260413 count: 27
I1011 15:15:01.057925 38966 solver.cpp:253] Iteration 800 (1.81627 iter/s, 5.50578s/10 iters), loss = 2.88147
I1011 15:15:01.057991 38966 solver.cpp:272]     Train net output #0: det_loss1 = 6.69396e-07 (* 1 = 6.69396e-07 loss)
I1011 15:15:01.058005 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.58492 (* 1 = 2.58492 loss)
I1011 15:15:01.058017 38966 sgd_solver.cpp:121] Iteration 800, lr = 0.0005
I1011 15:15:07.089035 38966 solver.cpp:253] Iteration 810 (1.65814 iter/s, 6.03084s/10 iters), loss = 2.81456
I1011 15:15:07.089100 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.23856e-07 (* 1 = 5.23856e-07 loss)
I1011 15:15:07.089109 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.16656 (* 1 = 2.16656 loss)
I1011 15:15:07.089118 38966 sgd_solver.cpp:121] Iteration 810, lr = 0.0005
I1011 15:15:10.369227 38966 yolov3_layer.cpp:532] noobj: 0.0014426 obj: 0.0998218 iou: 0.383845 cat: 0.999944 recall: 0.300507 recall75: 0.0353548 count: 26
I1011 15:15:14.576964 38966 solver.cpp:253] Iteration 820 (1.33554 iter/s, 7.4876s/10 iters), loss = 3.48062
I1011 15:15:14.577031 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.18926e-07 (* 1 = 4.18926e-07 loss)
I1011 15:15:14.577040 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.72731 (* 1 = 3.72731 loss)
I1011 15:15:14.577059 38966 sgd_solver.cpp:121] Iteration 820, lr = 0.0005
I1011 15:15:21.280570 38966 solver.cpp:253] Iteration 830 (1.4918 iter/s, 6.7033s/10 iters), loss = 3.24005
I1011 15:15:21.280635 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.54044e-07 (* 1 = 5.54044e-07 loss)
I1011 15:15:21.280645 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.14898 (* 1 = 3.14898 loss)
I1011 15:15:21.280653 38966 sgd_solver.cpp:121] Iteration 830, lr = 0.0005
I1011 15:15:21.491200 38966 yolov3_layer.cpp:532] noobj: 0.00131819 obj: 0.093521 iou: 0.385091 cat: 0.99982 recall: 0.341914 recall75: 0.0334188 count: 28
I1011 15:15:28.102644 38966 solver.cpp:253] Iteration 840 (1.4659 iter/s, 6.82177s/10 iters), loss = 2.9041
I1011 15:15:28.102715 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.40692e-07 (* 1 = 2.40692e-07 loss)
I1011 15:15:28.102726 38966 solver.cpp:272]     Train net output #1: det_loss2 = 4.77978 (* 1 = 4.77978 loss)
I1011 15:15:28.102735 38966 sgd_solver.cpp:121] Iteration 840, lr = 0.0005
I1011 15:15:31.364540 38966 yolov3_layer.cpp:532] noobj: 0.00128145 obj: 0.0926248 iou: 0.425371 cat: 0.999892 recall: 0.37035 recall75: 0.044416 count: 26
I1011 15:15:33.384572 38966 solver.cpp:253] Iteration 850 (1.89334 iter/s, 5.28166s/10 iters), loss = 2.91041
I1011 15:15:33.384635 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.53575e-07 (* 1 = 2.53575e-07 loss)
I1011 15:15:33.384646 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.52811 (* 1 = 2.52811 loss)
I1011 15:15:33.384654 38966 sgd_solver.cpp:121] Iteration 850, lr = 0.0005
I1011 15:15:39.447660 38966 solver.cpp:253] Iteration 860 (1.6494 iter/s, 6.06281s/10 iters), loss = 3.42158
I1011 15:15:39.447731 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.63856e-07 (* 1 = 2.63856e-07 loss)
I1011 15:15:39.447739 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.81924 (* 1 = 3.81924 loss)
I1011 15:15:39.447746 38966 sgd_solver.cpp:121] Iteration 860, lr = 0.0005
I1011 15:15:40.817611 38966 yolov3_layer.cpp:532] noobj: 0.00166424 obj: 0.107831 iou: 0.391427 cat: 0.999912 recall: 0.351572 recall75: 0.0247391 count: 28
I1011 15:15:45.137181 38966 solver.cpp:253] Iteration 870 (1.7577 iter/s, 5.68925s/10 iters), loss = 3.57705
I1011 15:15:45.137243 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.98053e-07 (* 1 = 2.98053e-07 loss)
I1011 15:15:45.137253 38966 solver.cpp:272]     Train net output #1: det_loss2 = 5.07316 (* 1 = 5.07316 loss)
I1011 15:15:45.137260 38966 sgd_solver.cpp:121] Iteration 870, lr = 0.0005
I1011 15:15:50.805373 38966 yolov3_layer.cpp:532] noobj: 0.00135397 obj: 0.11055 iou: 0.40894 cat: 0.99993 recall: 0.364696 recall75: 0.041854 count: 26
I1011 15:15:51.684510 38966 solver.cpp:253] Iteration 880 (1.52741 iter/s, 6.54703s/10 iters), loss = 2.98996
I1011 15:15:51.684583 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.40949e-07 (* 1 = 1.40949e-07 loss)
I1011 15:15:51.684593 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.21771 (* 1 = 3.21771 loss)
I1011 15:15:51.684600 38966 sgd_solver.cpp:121] Iteration 880, lr = 0.0005
I1011 15:15:57.133183 38966 solver.cpp:253] Iteration 890 (1.8354 iter/s, 5.4484s/10 iters), loss = 3.22202
I1011 15:15:57.133250 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.21495e-07 (* 1 = 1.21495e-07 loss)
I1011 15:15:57.133258 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.40084 (* 1 = 3.40084 loss)
I1011 15:15:57.133265 38966 sgd_solver.cpp:121] Iteration 890, lr = 0.0005
I1011 15:15:59.446599 38966 yolov3_layer.cpp:532] noobj: 0.00203195 obj: 0.112633 iou: 0.363636 cat: 0.999943 recall: 0.289659 recall75: 0.0195645 count: 28
I1011 15:16:02.529462 38966 solver.cpp:253] Iteration 900 (1.85322 iter/s, 5.39602s/10 iters), loss = 3.10546
I1011 15:16:02.529527 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.00668e-07 (* 1 = 2.00668e-07 loss)
I1011 15:16:02.529536 38966 solver.cpp:272]     Train net output #1: det_loss2 = 4.16501 (* 1 = 4.16501 loss)
I1011 15:16:02.529544 38966 sgd_solver.cpp:121] Iteration 900, lr = 0.0005
I1011 15:16:08.814829 38966 solver.cpp:253] Iteration 910 (1.59107 iter/s, 6.28508s/10 iters), loss = 3.14863
I1011 15:16:08.814926 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.34282e-07 (* 1 = 1.34282e-07 loss)
I1011 15:16:08.814936 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.68701 (* 1 = 3.68701 loss)
I1011 15:16:08.814944 38966 sgd_solver.cpp:121] Iteration 910, lr = 0.0005
I1011 15:16:09.058732 38966 yolov3_layer.cpp:532] noobj: 0.00159202 obj: 0.103232 iou: 0.365278 cat: 0.999957 recall: 0.31611 recall75: 0.0160189 count: 26
I1011 15:16:15.260246 38966 solver.cpp:253] Iteration 920 (1.55157 iter/s, 6.44509s/10 iters), loss = 3.22702
I1011 15:16:15.260509 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.34147e-07 (* 1 = 2.34147e-07 loss)
I1011 15:16:15.260522 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.94251 (* 1 = 2.94251 loss)
I1011 15:16:15.260532 38966 sgd_solver.cpp:121] Iteration 920, lr = 0.0005
I1011 15:16:20.149096 38966 yolov3_layer.cpp:532] noobj: 0.0013611 obj: 0.10233 iou: 0.383715 cat: 0.999962 recall: 0.310643 recall75: 0.0143999 count: 28
I1011 15:16:22.842134 38966 solver.cpp:253] Iteration 930 (1.31903 iter/s, 7.58136s/10 iters), loss = 2.89111
I1011 15:16:22.842205 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.46366e-07 (* 1 = 1.46366e-07 loss)
I1011 15:16:22.842222 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.47818 (* 1 = 2.47818 loss)
I1011 15:16:22.842238 38966 sgd_solver.cpp:121] Iteration 930, lr = 0.0005
I1011 15:16:29.983608 38966 solver.cpp:253] Iteration 940 (1.40034 iter/s, 7.14114s/10 iters), loss = 2.86124
I1011 15:16:29.983705 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.31835e-07 (* 1 = 1.31835e-07 loss)
I1011 15:16:29.983738 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.93281 (* 1 = 2.93281 loss)
I1011 15:16:29.983755 38966 sgd_solver.cpp:121] Iteration 940, lr = 0.0005
I1011 15:16:31.726562 38966 yolov3_layer.cpp:532] noobj: 0.0011011 obj: 0.109464 iou: 0.409323 cat: 0.999952 recall: 0.329364 recall75: 0.0337207 count: 27
I1011 15:16:37.008071 38966 solver.cpp:253] Iteration 950 (1.42367 iter/s, 7.02412s/10 iters), loss = 3.62045
I1011 15:16:37.008133 38966 solver.cpp:272]     Train net output #0: det_loss1 = 7.10806e-08 (* 1 = 7.10806e-08 loss)
I1011 15:16:37.008142 38966 solver.cpp:272]     Train net output #1: det_loss2 = 4.43266 (* 1 = 4.43266 loss)
I1011 15:16:37.008149 38966 sgd_solver.cpp:121] Iteration 950, lr = 0.0005
I1011 15:16:41.665079 38966 yolov3_layer.cpp:532] noobj: 0.00169056 obj: 0.124153 iou: 0.375153 cat: 0.999924 recall: 0.330938 recall75: 0.0219918 count: 28
I1011 15:16:42.662354 38966 solver.cpp:253] Iteration 960 (1.76865 iter/s, 5.65402s/10 iters), loss = 3.30992
I1011 15:16:42.662425 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.12044e-07 (* 1 = 1.12044e-07 loss)
I1011 15:16:42.662434 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.00777 (* 1 = 2.00777 loss)
I1011 15:16:42.662444 38966 sgd_solver.cpp:121] Iteration 960, lr = 0.0005
I1011 15:16:48.954885 38966 solver.cpp:253] Iteration 970 (1.58926 iter/s, 6.29224s/10 iters), loss = 2.85347
I1011 15:16:48.955054 38966 solver.cpp:272]     Train net output #0: det_loss1 = 7.72893e-08 (* 1 = 7.72893e-08 loss)
I1011 15:16:48.955065 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.48428 (* 1 = 2.48428 loss)
I1011 15:16:48.955072 38966 sgd_solver.cpp:121] Iteration 970, lr = 0.0005
I1011 15:16:51.690219 38966 yolov3_layer.cpp:532] noobj: 0.00139071 obj: 0.124812 iou: 0.381162 cat: 0.999973 recall: 0.318026 recall75: 0.0219463 count: 26
I1011 15:16:54.602998 38966 solver.cpp:253] Iteration 980 (1.77062 iter/s, 5.64773s/10 iters), loss = 2.83891
I1011 15:16:54.603194 38966 solver.cpp:272]     Train net output #0: det_loss1 = 7.16681e-08 (* 1 = 7.16681e-08 loss)
I1011 15:16:54.603240 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.24754 (* 1 = 2.24754 loss)
I1011 15:16:54.603258 38966 sgd_solver.cpp:121] Iteration 980, lr = 0.0005
I1011 15:17:00.220350 38966 solver.cpp:253] Iteration 990 (1.78032 iter/s, 5.61696s/10 iters), loss = 3.11159
I1011 15:17:00.220417 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.42714e-07 (* 1 = 1.42714e-07 loss)
I1011 15:17:00.220427 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.98902 (* 1 = 2.98902 loss)
I1011 15:17:00.220436 38966 sgd_solver.cpp:121] Iteration 990, lr = 0.0005
I1011 15:17:00.444682 38966 yolov3_layer.cpp:532] noobj: 0.00186263 obj: 0.137928 iou: 0.381136 cat: 0.99995 recall: 0.298695 recall75: 0.0196243 count: 27
I1011 15:17:05.691288 38966 solver.cpp:764] Snapshotting to binary proto file snapshot/yolov3_lite_deploy_iter_1000.caffemodel
I1011 15:17:05.746490 38966 sgd_solver.cpp:293] Snapshotting solver state to binary proto file snapshot/yolov3_lite_deploy_iter_1000.solverstate
I1011 15:17:05.764197 38966 solver.cpp:443] Iteration 1000, Testing net (#0)
I1011 15:17:05.764245 38966 net.cpp:679] Ignoring source layer label_data_1_split
I1011 15:17:05.769574 38966 net.cpp:679] Ignoring source layer Yolov3Loss1
I1011 15:17:05.769637 38966 net.cpp:679] Ignoring source layer Yolov3Loss2
I1011 15:17:11.790752 38966 blocking_queue.cpp:50] Waiting for data
I1011 15:17:24.612468 38966 blocking_queue.cpp:50] Waiting for data
I1011 15:17:37.518190 38966 blocking_queue.cpp:50] Waiting for data
I1011 15:17:50.434162 38966 blocking_queue.cpp:50] Waiting for data
I1011 15:18:02.982587 38966 blocking_queue.cpp:50] Waiting for data
I1011 15:18:06.600631 38966 solver.cpp:550] class1: 0.113918
I1011 15:18:06.600666 38966 solver.cpp:556]     Test net output #0: detection_eval = 0.113918
I1011 15:18:07.285694 38966 solver.cpp:253] Iteration 1000 (0.149114 iter/s, 67.063s/10 iters), loss = 2.62194
I1011 15:18:07.285769 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.25434e-07 (* 1 = 1.25434e-07 loss)
I1011 15:18:07.285784 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.17461 (* 1 = 2.17461 loss)
I1011 15:18:07.285806 38966 sgd_solver.cpp:121] Iteration 1000, lr = 0.0005
I1011 15:18:11.472193 38966 yolov3_layer.cpp:532] noobj: 0.00121521 obj: 0.132396 iou: 0.43224 cat: 0.999946 recall: 0.407602 recall75: 0.0373908 count: 25
I1011 15:18:13.909257 38966 solver.cpp:253] Iteration 1010 (1.50983 iter/s, 6.62326s/10 iters), loss = 2.77995
I1011 15:18:13.909324 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.40131e-08 (* 1 = 5.40131e-08 loss)
I1011 15:18:13.909337 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.17777 (* 1 = 3.17777 loss)
I1011 15:18:13.909348 38966 sgd_solver.cpp:121] Iteration 1010, lr = 0.0005
I1011 15:18:19.275944 38966 solver.cpp:253] Iteration 1020 (1.86344 iter/s, 5.36642s/10 iters), loss = 2.71571
I1011 15:18:19.276018 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.39541e-07 (* 1 = 1.39541e-07 loss)
I1011 15:18:19.276027 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.21047 (* 1 = 2.21047 loss)
I1011 15:18:19.276047 38966 sgd_solver.cpp:121] Iteration 1020, lr = 0.0005
I1011 15:18:21.078124 38966 yolov3_layer.cpp:532] noobj: 0.0013668 obj: 0.123667 iou: 0.432624 cat: 0.99995 recall: 0.430054 recall75: 0.0341637 count: 26
I1011 15:18:26.681967 38966 solver.cpp:253] Iteration 1030 (1.35032 iter/s, 7.40566s/10 iters), loss = 2.81177
I1011 15:18:26.682039 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.26555e-08 (* 1 = 5.26555e-08 loss)
I1011 15:18:26.682049 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.69622 (* 1 = 2.69622 loss)
I1011 15:18:26.682057 38966 sgd_solver.cpp:121] Iteration 1030, lr = 0.0005
I1011 15:18:31.330293 38966 yolov3_layer.cpp:532] noobj: 0.00135482 obj: 0.141055 iou: 0.422194 cat: 0.99996 recall: 0.438625 recall75: 0.0270486 count: 27
I1011 15:18:32.237812 38966 solver.cpp:253] Iteration 1040 (1.8 iter/s, 5.55556s/10 iters), loss = 2.75916
I1011 15:18:32.237890 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.78409e-08 (* 1 = 3.78409e-08 loss)
I1011 15:18:32.237907 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.61923 (* 1 = 3.61923 loss)
I1011 15:18:32.237920 38966 sgd_solver.cpp:121] Iteration 1040, lr = 0.0005
I1011 15:18:37.888365 38966 solver.cpp:253] Iteration 1050 (1.76983 iter/s, 5.65027s/10 iters), loss = 3.11869
I1011 15:18:37.888551 38966 solver.cpp:272]     Train net output #0: det_loss1 = 6.44626e-08 (* 1 = 6.44626e-08 loss)
I1011 15:18:37.888562 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.00892 (* 1 = 3.00892 loss)
I1011 15:18:37.888571 38966 sgd_solver.cpp:121] Iteration 1050, lr = 0.0005
I1011 15:18:41.145205 38966 yolov3_layer.cpp:532] noobj: 0.00178359 obj: 0.158834 iou: 0.403504 cat: 0.999973 recall: 0.369398 recall75: 0.0197537 count: 29
I1011 15:18:45.393513 38966 solver.cpp:253] Iteration 1060 (1.3325 iter/s, 7.50468s/10 iters), loss = 2.99527
I1011 15:18:45.393585 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.41701e-08 (* 1 = 4.41701e-08 loss)
I1011 15:18:45.393594 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.97757 (* 1 = 1.97757 loss)
I1011 15:18:45.393602 38966 sgd_solver.cpp:121] Iteration 1060, lr = 0.0005
I1011 15:18:52.975791 38966 solver.cpp:253] Iteration 1070 (1.31892 iter/s, 7.58194s/10 iters), loss = 2.56833
I1011 15:18:52.975854 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.08513e-08 (* 1 = 2.08513e-08 loss)
I1011 15:18:52.975862 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.56234 (* 1 = 3.56234 loss)
I1011 15:18:52.975869 38966 sgd_solver.cpp:121] Iteration 1070, lr = 0.0005
I1011 15:18:53.289700 38966 yolov3_layer.cpp:532] noobj: 0.00100567 obj: 0.159813 iou: 0.448732 cat: 0.999973 recall: 0.434178 recall75: 0.0575589 count: 27
I1011 15:18:58.692051 38966 solver.cpp:253] Iteration 1080 (1.74948 iter/s, 5.71599s/10 iters), loss = 2.65129
I1011 15:18:58.692113 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.0778e-08 (* 1 = 2.0778e-08 loss)
I1011 15:18:58.692123 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.80611 (* 1 = 2.80611 loss)
I1011 15:18:58.692131 38966 sgd_solver.cpp:121] Iteration 1080, lr = 0.0005
I1011 15:19:02.269145 38966 yolov3_layer.cpp:532] noobj: 0.0019672 obj: 0.13419 iou: 0.368236 cat: 0.999964 recall: 0.301717 recall75: 0.0429327 count: 27
I1011 15:19:04.374341 38966 solver.cpp:253] Iteration 1090 (1.75994 iter/s, 5.682s/10 iters), loss = 2.97792
I1011 15:19:04.374433 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.85711e-08 (* 1 = 3.85711e-08 loss)
I1011 15:19:04.374449 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.15912 (* 1 = 2.15912 loss)
I1011 15:19:04.374471 38966 sgd_solver.cpp:121] Iteration 1090, lr = 0.0005
I1011 15:19:10.763795 38966 solver.cpp:253] Iteration 1100 (1.56516 iter/s, 6.38914s/10 iters), loss = 2.56959
I1011 15:19:10.764037 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.96872e-08 (* 1 = 3.96872e-08 loss)
I1011 15:19:10.764056 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.8237 (* 1 = 1.8237 loss)
I1011 15:19:10.764070 38966 sgd_solver.cpp:121] Iteration 1100, lr = 0.0005
I1011 15:19:12.394850 38966 yolov3_layer.cpp:532] noobj: 0.00131923 obj: 0.154433 iou: 0.411532 cat: 0.999973 recall: 0.387474 recall75: 0.0395398 count: 25
I1011 15:19:17.741425 38966 solver.cpp:253] Iteration 1110 (1.43325 iter/s, 6.97714s/10 iters), loss = 2.81812
I1011 15:19:17.741488 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.6793e-08 (* 1 = 2.6793e-08 loss)
I1011 15:19:17.741497 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.19402 (* 1 = 3.19402 loss)
I1011 15:19:17.741506 38966 sgd_solver.cpp:121] Iteration 1110, lr = 0.0005
I1011 15:19:22.869652 38966 yolov3_layer.cpp:532] noobj: 0.00125466 obj: 0.158299 iou: 0.417413 cat: 0.999925 recall: 0.389933 recall75: 0.0220256 count: 27
I1011 15:19:23.838171 38966 solver.cpp:253] Iteration 1120 (1.6403 iter/s, 6.09646s/10 iters), loss = 2.89167
I1011 15:19:23.838227 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.81998e-08 (* 1 = 1.81998e-08 loss)
I1011 15:19:23.838235 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.44865 (* 1 = 3.44865 loss)
I1011 15:19:23.838243 38966 sgd_solver.cpp:121] Iteration 1120, lr = 0.0005
I1011 15:19:30.003723 38966 solver.cpp:253] Iteration 1130 (1.62199 iter/s, 6.16527s/10 iters), loss = 2.84966
I1011 15:19:30.003789 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.42056e-08 (* 1 = 4.42056e-08 loss)
I1011 15:19:30.003798 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.06233 (* 1 = 3.06233 loss)
I1011 15:19:30.003806 38966 sgd_solver.cpp:121] Iteration 1130, lr = 0.0005
I1011 15:19:33.272343 38966 yolov3_layer.cpp:532] noobj: 0.00144398 obj: 0.180246 iou: 0.394698 cat: 0.999966 recall: 0.322152 recall75: 0.0374908 count: 27
I1011 15:19:37.299327 38966 solver.cpp:253] Iteration 1140 (1.37075 iter/s, 7.29528s/10 iters), loss = 2.71888
I1011 15:19:37.299391 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.33605e-08 (* 1 = 2.33605e-08 loss)
I1011 15:19:37.299399 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.7711 (* 1 = 2.7711 loss)
I1011 15:19:37.299407 38966 sgd_solver.cpp:121] Iteration 1140, lr = 0.0005
I1011 15:19:43.740154 38966 solver.cpp:253] Iteration 1150 (1.55275 iter/s, 6.4402s/10 iters), loss = 2.71013
I1011 15:19:43.740381 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.54017e-08 (* 1 = 1.54017e-08 loss)
I1011 15:19:43.740393 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.90628 (* 1 = 2.90628 loss)
I1011 15:19:43.740401 38966 sgd_solver.cpp:121] Iteration 1150, lr = 0.0005
I1011 15:19:44.162245 38966 yolov3_layer.cpp:532] noobj: 0.00140858 obj: 0.172276 iou: 0.427861 cat: 0.999974 recall: 0.429333 recall75: 0.037335 count: 27
I1011 15:19:50.580828 38966 solver.cpp:253] Iteration 1160 (1.46211 iter/s, 6.83941s/10 iters), loss = 2.61197
I1011 15:19:50.580901 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.4535e-08 (* 1 = 2.4535e-08 loss)
I1011 15:19:50.580910 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.96424 (* 1 = 2.96424 loss)
I1011 15:19:50.580917 38966 sgd_solver.cpp:121] Iteration 1160, lr = 0.0005
I1011 15:19:55.441558 38966 yolov3_layer.cpp:532] noobj: 0.0011582 obj: 0.174958 iou: 0.447896 cat: 0.999984 recall: 0.459572 recall75: 0.044915 count: 26
I1011 15:19:57.984869 38966 solver.cpp:253] Iteration 1170 (1.35083 iter/s, 7.40285s/10 iters), loss = 2.43788
I1011 15:19:57.984959 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.33209e-08 (* 1 = 1.33209e-08 loss)
I1011 15:19:57.984978 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.37451 (* 1 = 2.37451 loss)
I1011 15:19:57.984992 38966 sgd_solver.cpp:121] Iteration 1170, lr = 0.0005
I1011 15:20:03.630105 38966 solver.cpp:253] Iteration 1180 (1.7717 iter/s, 5.64431s/10 iters), loss = 2.54341
I1011 15:20:03.630172 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.16562e-08 (* 1 = 1.16562e-08 loss)
I1011 15:20:03.630182 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.57602 (* 1 = 2.57602 loss)
I1011 15:20:03.630188 38966 sgd_solver.cpp:121] Iteration 1180, lr = 0.0005
I1011 15:20:05.264936 38966 yolov3_layer.cpp:532] noobj: 0.00147242 obj: 0.214636 iou: 0.45095 cat: 0.99998 recall: 0.456784 recall75: 0.0684382 count: 27
I1011 15:20:09.964635 38966 solver.cpp:253] Iteration 1190 (1.5789 iter/s, 6.33352s/10 iters), loss = 2.62537
I1011 15:20:09.964702 38966 solver.cpp:272]     Train net output #0: det_loss1 = 8.01977e-09 (* 1 = 8.01977e-09 loss)
I1011 15:20:09.964710 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.02294 (* 1 = 3.02294 loss)
I1011 15:20:09.964717 38966 sgd_solver.cpp:121] Iteration 1190, lr = 0.0005
I1011 15:20:14.513093 38966 yolov3_layer.cpp:532] noobj: 0.00173813 obj: 0.19428 iou: 0.394486 cat: 0.999987 recall: 0.371133 recall75: 0.0580694 count: 27
I1011 15:20:15.237421 38966 solver.cpp:253] Iteration 1200 (1.89683 iter/s, 5.27194s/10 iters), loss = 2.81627
I1011 15:20:15.237483 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.69291e-08 (* 1 = 1.69291e-08 loss)
I1011 15:20:15.237491 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.24484 (* 1 = 3.24484 loss)
I1011 15:20:15.237498 38966 sgd_solver.cpp:121] Iteration 1200, lr = 0.0005
I1011 15:20:20.510607 38966 solver.cpp:253] Iteration 1210 (1.89669 iter/s, 5.27235s/10 iters), loss = 2.49254
I1011 15:20:20.510670 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.22561e-08 (* 1 = 1.22561e-08 loss)
I1011 15:20:20.510680 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.68805 (* 1 = 2.68805 loss)
I1011 15:20:20.510687 38966 sgd_solver.cpp:121] Iteration 1210, lr = 0.0005
I1011 15:20:22.985700 38966 yolov3_layer.cpp:532] noobj: 0.00204739 obj: 0.212851 iou: 0.401139 cat: 0.999988 recall: 0.376874 recall75: 0.0557155 count: 27
I1011 15:20:26.108669 38966 solver.cpp:253] Iteration 1220 (1.78661 iter/s, 5.59718s/10 iters), loss = 2.3836
I1011 15:20:26.108732 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.17826e-08 (* 1 = 1.17826e-08 loss)
I1011 15:20:26.108742 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.25543 (* 1 = 2.25543 loss)
I1011 15:20:26.108762 38966 sgd_solver.cpp:121] Iteration 1220, lr = 0.0005
I1011 15:20:32.211160 38966 solver.cpp:253] Iteration 1230 (1.63893 iter/s, 6.10154s/10 iters), loss = 2.63633
I1011 15:20:32.211257 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.34973e-08 (* 1 = 1.34973e-08 loss)
I1011 15:20:32.211274 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.21594 (* 1 = 2.21594 loss)
I1011 15:20:32.211288 38966 sgd_solver.cpp:121] Iteration 1230, lr = 0.0005
I1011 15:20:32.406349 38966 yolov3_layer.cpp:532] noobj: 0.00175076 obj: 0.210151 iou: 0.409069 cat: 0.999988 recall: 0.419002 recall75: 0.0504249 count: 27
I1011 15:20:38.549860 38966 solver.cpp:253] Iteration 1240 (1.57786 iter/s, 6.33771s/10 iters), loss = 2.31334
I1011 15:20:38.549927 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.04157e-08 (* 1 = 1.04157e-08 loss)
I1011 15:20:38.549935 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.25801 (* 1 = 2.25801 loss)
I1011 15:20:38.549942 38966 sgd_solver.cpp:121] Iteration 1240, lr = 0.0005
I1011 15:20:42.645767 38966 yolov3_layer.cpp:532] noobj: 0.00138114 obj: 0.239293 iou: 0.462949 cat: 0.999985 recall: 0.52104 recall75: 0.0693534 count: 26
I1011 15:20:44.828979 38966 solver.cpp:253] Iteration 1250 (1.59282 iter/s, 6.27816s/10 iters), loss = 2.35016
I1011 15:20:44.829289 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.07792e-08 (* 1 = 1.07792e-08 loss)
I1011 15:20:44.829308 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.30463 (* 1 = 3.30463 loss)
I1011 15:20:44.829321 38966 sgd_solver.cpp:121] Iteration 1250, lr = 0.0005
I1011 15:20:50.904009 38966 solver.cpp:253] Iteration 1260 (1.6464 iter/s, 6.07387s/10 iters), loss = 2.81041
I1011 15:20:50.904074 38966 solver.cpp:272]     Train net output #0: det_loss1 = 6.33319e-09 (* 1 = 6.33319e-09 loss)
I1011 15:20:50.904083 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.82808 (* 1 = 2.82808 loss)
I1011 15:20:50.904089 38966 sgd_solver.cpp:121] Iteration 1260, lr = 0.0005
I1011 15:20:52.306313 38966 yolov3_layer.cpp:532] noobj: 0.00190467 obj: 0.207703 iou: 0.370343 cat: 0.999989 recall: 0.319083 recall75: 0.0389619 count: 27
I1011 15:20:56.260886 38966 solver.cpp:253] Iteration 1270 (1.86704 iter/s, 5.35606s/10 iters), loss = 2.76283
I1011 15:20:56.260953 38966 solver.cpp:272]     Train net output #0: det_loss1 = 9.01949e-09 (* 1 = 9.01949e-09 loss)
I1011 15:20:56.260965 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.78101 (* 1 = 2.78101 loss)
I1011 15:20:56.260977 38966 sgd_solver.cpp:121] Iteration 1270, lr = 0.0005
I1011 15:21:01.289628 38966 yolov3_layer.cpp:532] noobj: 0.00197884 obj: 0.223169 iou: 0.39402 cat: 0.999991 recall: 0.349415 recall75: 0.0365775 count: 27
I1011 15:21:02.268575 38966 solver.cpp:253] Iteration 1280 (1.66478 iter/s, 6.0068s/10 iters), loss = 2.75154
I1011 15:21:02.268651 38966 solver.cpp:272]     Train net output #0: det_loss1 = 8.90993e-09 (* 1 = 8.90993e-09 loss)
I1011 15:21:02.268663 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.67894 (* 1 = 3.67894 loss)
I1011 15:21:02.268676 38966 sgd_solver.cpp:121] Iteration 1280, lr = 0.0005
I1011 15:21:08.139418 38966 solver.cpp:253] Iteration 1290 (1.70359 iter/s, 5.86997s/10 iters), loss = 2.37612
I1011 15:21:08.139489 38966 solver.cpp:272]     Train net output #0: det_loss1 = 9.71129e-09 (* 1 = 9.71129e-09 loss)
I1011 15:21:08.139503 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.61809 (* 1 = 2.61809 loss)
I1011 15:21:08.139514 38966 sgd_solver.cpp:121] Iteration 1290, lr = 0.0005
I1011 15:21:11.098498 38966 yolov3_layer.cpp:532] noobj: 0.00153302 obj: 0.235851 iou: 0.437082 cat: 0.999989 recall: 0.461871 recall75: 0.0592222 count: 27
I1011 15:21:14.898182 38966 solver.cpp:253] Iteration 1300 (1.47977 iter/s, 6.75779s/10 iters), loss = 2.41567
I1011 15:21:14.898396 38966 solver.cpp:272]     Train net output #0: det_loss1 = 8.53839e-09 (* 1 = 8.53839e-09 loss)
I1011 15:21:14.898418 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.51421 (* 1 = 2.51421 loss)
I1011 15:21:14.898442 38966 sgd_solver.cpp:121] Iteration 1300, lr = 0.0005
I1011 15:21:21.062340 38966 solver.cpp:253] Iteration 1310 (1.62256 iter/s, 6.16311s/10 iters), loss = 2.59991
I1011 15:21:21.062407 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.70031e-09 (* 1 = 5.70031e-09 loss)
I1011 15:21:21.062417 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.22516 (* 1 = 3.22516 loss)
I1011 15:21:21.062424 38966 sgd_solver.cpp:121] Iteration 1310, lr = 0.0005
I1011 15:21:21.372251 38966 yolov3_layer.cpp:532] noobj: 0.00128437 obj: 0.210914 iou: 0.419927 cat: 0.999991 recall: 0.404324 recall75: 0.0572263 count: 26
I1011 15:21:26.711148 38966 solver.cpp:253] Iteration 1320 (1.77054 iter/s, 5.64798s/10 iters), loss = 2.70365
I1011 15:21:26.711211 38966 solver.cpp:272]     Train net output #0: det_loss1 = 6.08027e-09 (* 1 = 6.08027e-09 loss)
I1011 15:21:26.711220 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.8915 (* 1 = 2.8915 loss)
I1011 15:21:26.711226 38966 sgd_solver.cpp:121] Iteration 1320, lr = 0.0005
I1011 15:21:30.432896 38966 yolov3_layer.cpp:532] noobj: 0.0017686 obj: 0.201014 iou: 0.401592 cat: 0.999992 recall: 0.367202 recall75: 0.0380041 count: 27
I1011 15:21:32.797835 38966 solver.cpp:253] Iteration 1330 (1.64317 iter/s, 6.08581s/10 iters), loss = 2.44425
I1011 15:21:32.797896 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.60958e-09 (* 1 = 5.60958e-09 loss)
I1011 15:21:32.797904 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.79067 (* 1 = 2.79067 loss)
I1011 15:21:32.797911 38966 sgd_solver.cpp:121] Iteration 1330, lr = 0.0005
I1011 15:21:39.332320 38966 solver.cpp:253] Iteration 1340 (1.53056 iter/s, 6.53355s/10 iters), loss = 2.51491
I1011 15:21:39.332412 38966 solver.cpp:272]     Train net output #0: det_loss1 = 8.69741e-09 (* 1 = 8.69741e-09 loss)
I1011 15:21:39.332422 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.1089 (* 1 = 3.1089 loss)
I1011 15:21:39.332442 38966 sgd_solver.cpp:121] Iteration 1340, lr = 0.0005
I1011 15:21:40.719597 38966 yolov3_layer.cpp:532] noobj: 0.00145349 obj: 0.268738 iou: 0.441312 cat: 0.999986 recall: 0.441495 recall75: 0.0608437 count: 28
I1011 15:21:45.605943 38966 solver.cpp:253] Iteration 1350 (1.59421 iter/s, 6.2727s/10 iters), loss = 2.41707
I1011 15:21:45.606134 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.69919e-09 (* 1 = 2.69919e-09 loss)
I1011 15:21:45.606146 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.2658 (* 1 = 2.2658 loss)
I1011 15:21:45.606155 38966 sgd_solver.cpp:121] Iteration 1350, lr = 0.0005
I1011 15:21:50.605737 38966 yolov3_layer.cpp:532] noobj: 0.00160784 obj: 0.283036 iou: 0.466972 cat: 0.99999 recall: 0.533468 recall75: 0.0667521 count: 28
I1011 15:21:51.758998 38966 solver.cpp:253] Iteration 1360 (1.62547 iter/s, 6.15206s/10 iters), loss = 2.50615
I1011 15:21:51.759063 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.22597e-08 (* 1 = 1.22597e-08 loss)
I1011 15:21:51.759070 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.08792 (* 1 = 3.08792 loss)
I1011 15:21:51.759078 38966 sgd_solver.cpp:121] Iteration 1360, lr = 0.0005
I1011 15:21:58.201539 38966 solver.cpp:253] Iteration 1370 (1.5524 iter/s, 6.44164s/10 iters), loss = 2.28458
I1011 15:21:58.201607 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.78923e-09 (* 1 = 5.78923e-09 loss)
I1011 15:21:58.201617 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.51165 (* 1 = 1.51165 loss)
I1011 15:21:58.201624 38966 sgd_solver.cpp:121] Iteration 1370, lr = 0.0005
I1011 15:22:01.473361 38966 yolov3_layer.cpp:532] noobj: 0.00131677 obj: 0.272591 iou: 0.468399 cat: 0.99999 recall: 0.500888 recall75: 0.0785248 count: 28
I1011 15:22:05.880010 38966 solver.cpp:253] Iteration 1380 (1.30252 iter/s, 7.67742s/10 iters), loss = 2.27621
I1011 15:22:05.880075 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.41142e-09 (* 1 = 4.41142e-09 loss)
I1011 15:22:05.880084 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.58594 (* 1 = 2.58594 loss)
I1011 15:22:05.880092 38966 sgd_solver.cpp:121] Iteration 1380, lr = 0.0005
I1011 15:22:12.673341 38966 solver.cpp:253] Iteration 1390 (1.47223 iter/s, 6.7924s/10 iters), loss = 2.3784
I1011 15:22:12.673403 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.44989e-09 (* 1 = 4.44989e-09 loss)
I1011 15:22:12.673413 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.87802 (* 1 = 2.87802 loss)
I1011 15:22:12.673419 38966 sgd_solver.cpp:121] Iteration 1390, lr = 0.0005
I1011 15:22:12.923683 38966 yolov3_layer.cpp:532] noobj: 0.00119051 obj: 0.264894 iou: 0.484622 cat: 0.999989 recall: 0.55885 recall75: 0.0820033 count: 29
I1011 15:22:18.642756 38966 solver.cpp:253] Iteration 1400 (1.67544 iter/s, 5.96859s/10 iters), loss = 2.47692
I1011 15:22:18.642990 38966 solver.cpp:272]     Train net output #0: det_loss1 = 8.56347e-09 (* 1 = 8.56347e-09 loss)
I1011 15:22:18.643005 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.08571 (* 1 = 2.08571 loss)
I1011 15:22:18.643014 38966 sgd_solver.cpp:121] Iteration 1400, lr = 0.0005
I1011 15:22:23.441953 38966 yolov3_layer.cpp:532] noobj: 0.00164259 obj: 0.27031 iou: 0.448085 cat: 0.99999 recall: 0.479562 recall75: 0.0624832 count: 28
I1011 15:22:26.186273 38966 solver.cpp:253] Iteration 1410 (1.32585 iter/s, 7.54234s/10 iters), loss = 2.23564
I1011 15:22:26.186336 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.90784e-09 (* 1 = 4.90784e-09 loss)
I1011 15:22:26.186344 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.80962 (* 1 = 1.80962 loss)
I1011 15:22:26.186352 38966 sgd_solver.cpp:121] Iteration 1410, lr = 0.0005
I1011 15:22:33.797346 38966 solver.cpp:253] Iteration 1420 (1.31405 iter/s, 7.61007s/10 iters), loss = 1.98329
I1011 15:22:33.797410 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.59856e-09 (* 1 = 3.59856e-09 loss)
I1011 15:22:33.797417 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.31952 (* 1 = 2.31952 loss)
I1011 15:22:33.797425 38966 sgd_solver.cpp:121] Iteration 1420, lr = 0.0005
I1011 15:22:35.410773 38966 yolov3_layer.cpp:532] noobj: 0.000920473 obj: 0.266519 iou: 0.501171 cat: 0.999968 recall: 0.569871 recall75: 0.0985137 count: 25
I1011 15:22:40.423517 38966 solver.cpp:253] Iteration 1430 (1.50937 iter/s, 6.62529s/10 iters), loss = 2.50291
I1011 15:22:40.423573 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.52473e-09 (* 1 = 1.52473e-09 loss)
I1011 15:22:40.423583 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.38925 (* 1 = 3.38925 loss)
I1011 15:22:40.423593 38966 sgd_solver.cpp:121] Iteration 1430, lr = 0.0005
I1011 15:22:45.375377 38966 yolov3_layer.cpp:532] noobj: 0.00140121 obj: 0.262898 iou: 0.4651 cat: 0.999988 recall: 0.496246 recall75: 0.0648605 count: 27
I1011 15:22:46.173236 38966 solver.cpp:253] Iteration 1440 (1.73945 iter/s, 5.74896s/10 iters), loss = 2.40917
I1011 15:22:46.173300 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.94076e-09 (* 1 = 1.94076e-09 loss)
I1011 15:22:46.173307 38966 solver.cpp:272]     Train net output #1: det_loss2 = 3.42261 (* 1 = 3.42261 loss)
I1011 15:22:46.173316 38966 sgd_solver.cpp:121] Iteration 1440, lr = 0.0005
I1011 15:22:52.026361 38966 solver.cpp:253] Iteration 1450 (1.70872 iter/s, 5.85234s/10 iters), loss = 2.39464
I1011 15:22:52.026585 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.16129e-09 (* 1 = 3.16129e-09 loss)
I1011 15:22:52.026598 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.94964 (* 1 = 2.94964 loss)
I1011 15:22:52.026608 38966 sgd_solver.cpp:121] Iteration 1450, lr = 0.0005
I1011 15:22:54.983475 38966 yolov3_layer.cpp:532] noobj: 0.00137158 obj: 4.96073e-07 iou: 0.264078 cat: 0.713329 recall: 0 recall75: 0 count: 1
I1011 15:22:55.031675 38966 yolov3_layer.cpp:532] noobj: 0.00184324 obj: 0.310752 iou: 0.439248 cat: 0.999991 recall: 0.46106 recall75: 0.0551107 count: 29
I1011 15:22:58.944864 38966 solver.cpp:253] Iteration 1460 (1.44562 iter/s, 6.91742s/10 iters), loss = 2.36054
I1011 15:22:58.945010 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.34829e-09 (* 1 = 2.34829e-09 loss)
I1011 15:22:58.945027 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.74762 (* 1 = 1.74762 loss)
I1011 15:22:58.945039 38966 sgd_solver.cpp:121] Iteration 1460, lr = 0.0005
I1011 15:23:04.421970 38966 solver.cpp:253] Iteration 1470 (1.82605 iter/s, 5.4763s/10 iters), loss = 2.13539
I1011 15:23:04.422042 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.01528e-09 (* 1 = 4.01528e-09 loss)
I1011 15:23:04.422053 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.28502 (* 1 = 2.28502 loss)
I1011 15:23:04.422072 38966 sgd_solver.cpp:121] Iteration 1470, lr = 0.0005
I1011 15:23:04.613986 38966 yolov3_layer.cpp:532] noobj: 0.00180778 obj: 0.299578 iou: 0.450495 cat: 0.999996 recall: 0.495446 recall75: 0.070476 count: 27
I1011 15:23:10.769096 38966 solver.cpp:253] Iteration 1480 (1.57572 iter/s, 6.3463s/10 iters), loss = 2.17178
I1011 15:23:10.769162 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.05e-09 (* 1 = 3.05e-09 loss)
I1011 15:23:10.769170 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.47228 (* 1 = 2.47228 loss)
I1011 15:23:10.769178 38966 sgd_solver.cpp:121] Iteration 1480, lr = 0.0005
I1011 15:23:15.685405 38966 yolov3_layer.cpp:532] noobj: 0.00125488 obj: 0.328025 iou: 0.499012 cat: 0.999994 recall: 0.581487 recall75: 0.0866632 count: 28
I1011 15:23:18.358364 38966 solver.cpp:253] Iteration 1490 (1.31782 iter/s, 7.58831s/10 iters), loss = 2.08841
I1011 15:23:18.358430 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.96081e-09 (* 1 = 2.96081e-09 loss)
I1011 15:23:18.358439 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.10205 (* 1 = 2.10205 loss)
I1011 15:23:18.358446 38966 sgd_solver.cpp:121] Iteration 1490, lr = 0.0005
I1011 15:23:24.741044 38966 solver.cpp:253] Iteration 1500 (1.56694 iter/s, 6.38186s/10 iters), loss = 2.3381
I1011 15:23:24.741277 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.19424e-09 (* 1 = 1.19424e-09 loss)
I1011 15:23:24.741291 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.4478 (* 1 = 2.4478 loss)
I1011 15:23:24.741297 38966 sgd_solver.cpp:121] Iteration 1500, lr = 0.0005
I1011 15:23:26.108289 38966 yolov3_layer.cpp:532] noobj: 0.00150901 obj: 0.315464 iou: 0.451401 cat: 0.999986 recall: 0.476633 recall75: 0.0739242 count: 28
I1011 15:23:30.441648 38966 solver.cpp:253] Iteration 1510 (1.75448 iter/s, 5.6997s/10 iters), loss = 2.06132
I1011 15:23:30.441717 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.19959e-09 (* 1 = 3.19959e-09 loss)
I1011 15:23:30.441727 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.17931 (* 1 = 2.17931 loss)
I1011 15:23:30.441746 38966 sgd_solver.cpp:121] Iteration 1510, lr = 0.0005
I1011 15:23:36.127547 38966 yolov3_layer.cpp:532] noobj: 0.00157305 obj: 0.337571 iou: 0.495132 cat: 0.999995 recall: 0.568784 recall75: 0.102621 count: 27
I1011 15:23:37.443311 38966 solver.cpp:253] Iteration 1520 (1.42841 iter/s, 7.00078s/10 iters), loss = 1.85314
I1011 15:23:37.443372 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.02197e-09 (* 1 = 4.02197e-09 loss)
I1011 15:23:37.443382 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.18392 (* 1 = 2.18392 loss)
I1011 15:23:37.443389 38966 sgd_solver.cpp:121] Iteration 1520, lr = 0.0005
I1011 15:23:45.000676 38966 solver.cpp:253] Iteration 1530 (1.32338 iter/s, 7.55643s/10 iters), loss = 2.05367
I1011 15:23:45.000743 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.56407e-09 (* 1 = 1.56407e-09 loss)
I1011 15:23:45.000752 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.47974 (* 1 = 2.47974 loss)
I1011 15:23:45.000759 38966 sgd_solver.cpp:121] Iteration 1530, lr = 0.0005
I1011 15:23:47.604081 38966 yolov3_layer.cpp:532] noobj: 0.00117839 obj: 0.314488 iou: 0.499787 cat: 0.99997 recall: 0.580238 recall75: 0.0903936 count: 27
I1011 15:23:50.925339 38966 solver.cpp:253] Iteration 1540 (1.68807 iter/s, 5.92392s/10 iters), loss = 2.26491
I1011 15:23:50.925407 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.38307e-09 (* 1 = 1.38307e-09 loss)
I1011 15:23:50.925416 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.93259 (* 1 = 1.93259 loss)
I1011 15:23:50.925424 38966 sgd_solver.cpp:121] Iteration 1540, lr = 0.0005
I1011 15:23:56.994109 38966 solver.cpp:253] Iteration 1550 (1.64799 iter/s, 6.06801s/10 iters), loss = 1.81653
I1011 15:23:56.994472 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.15098e-09 (* 1 = 2.15098e-09 loss)
I1011 15:23:56.994510 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.63223 (* 1 = 1.63223 loss)
I1011 15:23:56.994539 38966 sgd_solver.cpp:121] Iteration 1550, lr = 0.0005
I1011 15:23:57.391109 38966 yolov3_layer.cpp:532] noobj: 0.00138064 obj: 0.314053 iou: 0.474268 cat: 0.999996 recall: 0.525504 recall75: 0.0738488 count: 25
I1011 15:24:02.766425 38966 solver.cpp:253] Iteration 1560 (1.73271 iter/s, 5.7713s/10 iters), loss = 2.2446
I1011 15:24:02.766495 38966 solver.cpp:272]     Train net output #0: det_loss1 = 7.60095e-10 (* 1 = 7.60095e-10 loss)
I1011 15:24:02.766505 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.54783 (* 1 = 2.54783 loss)
I1011 15:24:02.766513 38966 sgd_solver.cpp:121] Iteration 1560, lr = 0.0005
I1011 15:24:06.553553 38966 yolov3_layer.cpp:532] noobj: 0.002157 obj: 0.338139 iou: 0.421007 cat: 0.999997 recall: 0.424994 recall75: 0.0696545 count: 29
I1011 15:24:08.434160 38966 solver.cpp:253] Iteration 1570 (1.7646 iter/s, 5.66702s/10 iters), loss = 2.15959
I1011 15:24:08.434255 38966 solver.cpp:272]     Train net output #0: det_loss1 = 9.56097e-10 (* 1 = 9.56097e-10 loss)
I1011 15:24:08.434273 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.64625 (* 1 = 1.64625 loss)
I1011 15:24:08.434288 38966 sgd_solver.cpp:121] Iteration 1570, lr = 0.0005
I1011 15:24:14.631577 38966 solver.cpp:253] Iteration 1580 (1.61378 iter/s, 6.19663s/10 iters), loss = 2.17812
I1011 15:24:14.631659 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.13548e-09 (* 1 = 1.13548e-09 loss)
I1011 15:24:14.631669 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.0565 (* 1 = 2.0565 loss)
I1011 15:24:14.631690 38966 sgd_solver.cpp:121] Iteration 1580, lr = 0.0005
I1011 15:24:16.497143 38966 yolov3_layer.cpp:532] noobj: 0.0015365 obj: 0.358404 iou: 0.468934 cat: 0.999998 recall: 0.544294 recall75: 0.0603784 count: 26
I1011 15:24:21.966949 38966 solver.cpp:253] Iteration 1590 (1.36342 iter/s, 7.3345s/10 iters), loss = 2.02888
I1011 15:24:21.967005 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.76218e-10 (* 1 = 5.76218e-10 loss)
I1011 15:24:21.967015 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.70685 (* 1 = 2.70685 loss)
I1011 15:24:21.967021 38966 sgd_solver.cpp:121] Iteration 1590, lr = 0.0005
I1011 15:24:26.597519 38966 yolov3_layer.cpp:532] noobj: 0.00154471 obj: 0.357827 iou: 0.467262 cat: 0.999997 recall: 0.537445 recall75: 0.0948747 count: 26
I1011 15:24:27.690115 38966 solver.cpp:253] Iteration 1600 (1.7475 iter/s, 5.72248s/10 iters), loss = 2.16495
I1011 15:24:27.690335 38966 solver.cpp:272]     Train net output #0: det_loss1 = 6.61886e-10 (* 1 = 6.61886e-10 loss)
I1011 15:24:27.690346 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.60825 (* 1 = 1.60825 loss)
I1011 15:24:27.690356 38966 sgd_solver.cpp:121] Iteration 1600, lr = 0.0005
I1011 15:24:33.695834 38966 solver.cpp:253] Iteration 1610 (1.66532 iter/s, 6.00483s/10 iters), loss = 1.96312
I1011 15:24:33.695897 38966 solver.cpp:272]     Train net output #0: det_loss1 = 6.42498e-10 (* 1 = 6.42498e-10 loss)
I1011 15:24:33.695906 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.33265 (* 1 = 2.33265 loss)
I1011 15:24:33.695914 38966 sgd_solver.cpp:121] Iteration 1610, lr = 0.0005
I1011 15:24:36.498510 38966 yolov3_layer.cpp:532] noobj: 0.00154548 obj: 0.349578 iou: 0.485285 cat: 0.999997 recall: 0.527654 recall75: 0.111957 count: 26
I1011 15:24:40.139585 38966 solver.cpp:253] Iteration 1620 (1.55208 iter/s, 6.44299s/10 iters), loss = 2.19424
I1011 15:24:40.146078 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.66084e-09 (* 1 = 1.66084e-09 loss)
I1011 15:24:40.146107 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.14347 (* 1 = 2.14347 loss)
I1011 15:24:40.146116 38966 sgd_solver.cpp:121] Iteration 1620, lr = 0.0005
I1011 15:24:47.458374 38966 solver.cpp:253] Iteration 1630 (1.36771 iter/s, 7.31149s/10 iters), loss = 1.97917
I1011 15:24:47.458482 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.0628e-10 (* 1 = 4.0628e-10 loss)
I1011 15:24:47.458500 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.46683 (* 1 = 2.46683 loss)
I1011 15:24:47.458516 38966 sgd_solver.cpp:121] Iteration 1630, lr = 0.0005
I1011 15:24:47.742952 38966 yolov3_layer.cpp:532] noobj: 0.00138081 obj: 0.352482 iou: 0.493156 cat: 0.999954 recall: 0.566194 recall75: 0.100591 count: 27
I1011 15:24:53.814002 38966 solver.cpp:253] Iteration 1640 (1.5736 iter/s, 6.35485s/10 iters), loss = 1.89694
I1011 15:24:53.814051 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.78757e-09 (* 1 = 1.78757e-09 loss)
I1011 15:24:53.814060 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.72105 (* 1 = 1.72105 loss)
I1011 15:24:53.814067 38966 sgd_solver.cpp:121] Iteration 1640, lr = 0.0005
I1011 15:24:57.267459 38966 yolov3_layer.cpp:532] noobj: 0.00151976 obj: 0.33344 iou: 0.465906 cat: 0.999996 recall: 0.513408 recall75: 0.0885834 count: 25
I1011 15:24:59.003144 38966 solver.cpp:253] Iteration 1650 (1.92733 iter/s, 5.18853s/10 iters), loss = 1.91972
I1011 15:24:59.003476 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.32755e-09 (* 1 = 1.32755e-09 loss)
I1011 15:24:59.003496 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.07743 (* 1 = 1.07743 loss)
I1011 15:24:59.003509 38966 sgd_solver.cpp:121] Iteration 1650, lr = 0.0005
I1011 15:25:04.940162 38966 solver.cpp:253] Iteration 1660 (1.68462 iter/s, 5.93606s/10 iters), loss = 1.96473
I1011 15:25:04.940248 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.35018e-10 (* 1 = 4.35018e-10 loss)
I1011 15:25:04.940259 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.31455 (* 1 = 1.31455 loss)
I1011 15:25:04.940279 38966 sgd_solver.cpp:121] Iteration 1660, lr = 0.0005
I1011 15:25:06.268309 38966 yolov3_layer.cpp:532] noobj: 0.00157033 obj: 0.413813 iou: 0.516634 cat: 0.999984 recall: 0.622931 recall75: 0.138833 count: 28
I1011 15:25:11.377252 38966 solver.cpp:253] Iteration 1670 (1.55368 iter/s, 6.43633s/10 iters), loss = 1.97291
I1011 15:25:11.377326 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.47944e-09 (* 1 = 1.47944e-09 loss)
I1011 15:25:11.377338 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.76051 (* 1 = 1.76051 loss)
I1011 15:25:11.377349 38966 sgd_solver.cpp:121] Iteration 1670, lr = 0.0005
I1011 15:25:17.748494 38966 yolov3_layer.cpp:532] noobj: 0.00118851 obj: 0.390185 iou: 0.512141 cat: 0.999996 recall: 0.611579 recall75: 0.122041 count: 27
I1011 15:25:19.080324 38966 solver.cpp:253] Iteration 1680 (1.29833 iter/s, 7.70221s/10 iters), loss = 1.61962
I1011 15:25:19.080392 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.39007e-10 (* 1 = 3.39007e-10 loss)
I1011 15:25:19.080413 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.88983 (* 1 = 1.88983 loss)
I1011 15:25:19.080423 38966 sgd_solver.cpp:121] Iteration 1680, lr = 0.0005
I1011 15:25:26.000236 38966 solver.cpp:253] Iteration 1690 (1.44527 iter/s, 6.91913s/10 iters), loss = 1.86062
I1011 15:25:26.000305 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.48036e-10 (* 1 = 1.48036e-10 loss)
I1011 15:25:26.000315 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.33533 (* 1 = 2.33533 loss)
I1011 15:25:26.000334 38966 sgd_solver.cpp:121] Iteration 1690, lr = 0.0005
I1011 15:25:28.568902 38966 yolov3_layer.cpp:532] noobj: 0.00129228 obj: 0.361563 iou: 0.489515 cat: 0.999998 recall: 0.555691 recall75: 0.126756 count: 26
I1011 15:25:31.673568 38966 solver.cpp:253] Iteration 1700 (1.76284 iter/s, 5.67268s/10 iters), loss = 1.99326
I1011 15:25:31.673805 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.04418e-10 (* 1 = 3.04418e-10 loss)
I1011 15:25:31.673818 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.67586 (* 1 = 1.67586 loss)
I1011 15:25:31.673826 38966 sgd_solver.cpp:121] Iteration 1700, lr = 0.0005
I1011 15:25:37.024082 38966 solver.cpp:253] Iteration 1710 (1.86926 iter/s, 5.34971s/10 iters), loss = 1.98921
I1011 15:25:37.024183 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.68966e-10 (* 1 = 4.68966e-10 loss)
I1011 15:25:37.024204 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.29317 (* 1 = 1.29317 loss)
I1011 15:25:37.024219 38966 sgd_solver.cpp:121] Iteration 1710, lr = 0.0005
I1011 15:25:37.435775 38966 yolov3_layer.cpp:532] noobj: 0.00204874 obj: 0.404787 iou: 0.474566 cat: 0.999996 recall: 0.531173 recall75: 0.0976461 count: 28
I1011 15:25:43.377463 38966 solver.cpp:253] Iteration 1720 (1.57415 iter/s, 6.35265s/10 iters), loss = 1.98346
I1011 15:25:43.377506 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.41201e-10 (* 1 = 2.41201e-10 loss)
I1011 15:25:43.377514 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.40196 (* 1 = 2.40196 loss)
I1011 15:25:43.377521 38966 sgd_solver.cpp:121] Iteration 1720, lr = 0.0005
I1011 15:25:47.124920 38966 yolov3_layer.cpp:532] noobj: 0.00200798 obj: 0.418458 iou: 0.467333 cat: 0.999998 recall: 0.531679 recall75: 0.0910194 count: 29
I1011 15:25:48.917006 38966 solver.cpp:253] Iteration 1730 (1.8054 iter/s, 5.53893s/10 iters), loss = 2.03126
I1011 15:25:48.917168 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.36273e-10 (* 1 = 3.36273e-10 loss)
I1011 15:25:48.917214 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.87987 (* 1 = 1.87987 loss)
I1011 15:25:48.917249 38966 sgd_solver.cpp:121] Iteration 1730, lr = 0.0005
I1011 15:25:54.625010 38966 solver.cpp:253] Iteration 1740 (1.75215 iter/s, 5.70727s/10 iters), loss = 2.00253
I1011 15:25:54.625082 38966 solver.cpp:272]     Train net output #0: det_loss1 = 6.48336e-10 (* 1 = 6.48336e-10 loss)
I1011 15:25:54.625092 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.6843 (* 1 = 1.6843 loss)
I1011 15:25:54.625099 38966 sgd_solver.cpp:121] Iteration 1740, lr = 0.0005
I1011 15:25:56.046813 38966 yolov3_layer.cpp:532] noobj: 0.00202712 obj: 0.374679 iou: 0.458223 cat: 0.999997 recall: 0.497105 recall75: 0.0787067 count: 27
I1011 15:26:00.546772 38966 solver.cpp:253] Iteration 1750 (1.68888 iter/s, 5.9211s/10 iters), loss = 1.70668
I1011 15:26:00.546845 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.05015e-10 (* 1 = 5.05015e-10 loss)
I1011 15:26:00.546857 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.913558 (* 1 = 0.913558 loss)
I1011 15:26:00.546869 38966 sgd_solver.cpp:121] Iteration 1750, lr = 0.0005
I1011 15:26:05.615487 38966 yolov3_layer.cpp:532] noobj: 0.00151327 obj: 0.414709 iou: 0.51609 cat: 0.999996 recall: 0.613289 recall75: 0.128023 count: 26
I1011 15:26:06.699923 38966 solver.cpp:253] Iteration 1760 (1.62536 iter/s, 6.15247s/10 iters), loss = 1.7993
I1011 15:26:06.700006 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.56503e-10 (* 1 = 3.56503e-10 loss)
I1011 15:26:06.700018 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.10371 (* 1 = 2.10371 loss)
I1011 15:26:06.700037 38966 sgd_solver.cpp:121] Iteration 1760, lr = 0.0005
I1011 15:26:13.633193 38966 solver.cpp:253] Iteration 1770 (1.44248 iter/s, 6.93249s/10 iters), loss = 1.77746
I1011 15:26:13.633359 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.77626e-10 (* 1 = 3.77626e-10 loss)
I1011 15:26:13.633424 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.53495 (* 1 = 1.53495 loss)
I1011 15:26:13.633460 38966 sgd_solver.cpp:121] Iteration 1770, lr = 0.0005
I1011 15:26:16.921911 38966 yolov3_layer.cpp:532] noobj: 0.00121592 obj: 0.431896 iou: 0.511159 cat: 0.999998 recall: 0.596101 recall75: 0.12735 count: 28
I1011 15:26:20.720019 38966 solver.cpp:253] Iteration 1780 (1.41124 iter/s, 7.08597s/10 iters), loss = 1.79243
I1011 15:26:20.720085 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.49491e-10 (* 1 = 5.49491e-10 loss)
I1011 15:26:20.720096 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.33092 (* 1 = 1.33092 loss)
I1011 15:26:20.720108 38966 sgd_solver.cpp:121] Iteration 1780, lr = 0.0005
I1011 15:26:26.581022 38966 solver.cpp:253] Iteration 1790 (1.70638 iter/s, 5.86037s/10 iters), loss = 1.54606
I1011 15:26:26.581087 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.33169e-10 (* 1 = 2.33169e-10 loss)
I1011 15:26:26.581101 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.66322 (* 1 = 1.66322 loss)
I1011 15:26:26.581112 38966 sgd_solver.cpp:121] Iteration 1790, lr = 0.0005
I1011 15:26:26.832578 38966 yolov3_layer.cpp:532] noobj: 0.001359 obj: 0.45017 iou: 0.534638 cat: 0.999997 recall: 0.61362 recall75: 0.170859 count: 27
I1011 15:26:32.384299 38966 solver.cpp:253] Iteration 1800 (1.72335 iter/s, 5.80264s/10 iters), loss = 1.91588
I1011 15:26:32.384389 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.11774e-10 (* 1 = 2.11774e-10 loss)
I1011 15:26:32.384419 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.57511 (* 1 = 2.57511 loss)
I1011 15:26:32.384431 38966 sgd_solver.cpp:121] Iteration 1800, lr = 0.0005
I1011 15:26:36.766481 38966 yolov3_layer.cpp:532] noobj: 0.0016385 obj: 0.404444 iou: 0.480432 cat: 0.999998 recall: 0.546206 recall75: 0.114113 count: 26
I1011 15:26:39.117661 38966 solver.cpp:253] Iteration 1810 (1.4853 iter/s, 6.73264s/10 iters), loss = 1.68241
I1011 15:26:39.117724 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.09376e-10 (* 1 = 1.09376e-10 loss)
I1011 15:26:39.117733 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.00838 (* 1 = 2.00838 loss)
I1011 15:26:39.117739 38966 sgd_solver.cpp:121] Iteration 1810, lr = 0.0005
I1011 15:26:45.376155 38966 solver.cpp:253] Iteration 1820 (1.598 iter/s, 6.25783s/10 iters), loss = 1.80556
I1011 15:26:45.376217 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.66179e-10 (* 1 = 1.66179e-10 loss)
I1011 15:26:45.376225 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.53873 (* 1 = 1.53873 loss)
I1011 15:26:45.376233 38966 sgd_solver.cpp:121] Iteration 1820, lr = 0.0005
I1011 15:26:46.882817 38966 yolov3_layer.cpp:532] noobj: 0.0017165 obj: 0.411599 iou: 0.476227 cat: 0.999998 recall: 0.538379 recall75: 0.100053 count: 27
I1011 15:26:51.231103 38966 solver.cpp:253] Iteration 1830 (1.70814 iter/s, 5.85432s/10 iters), loss = 1.73064
I1011 15:26:51.231168 38966 solver.cpp:272]     Train net output #0: det_loss1 = 7.74163e-11 (* 1 = 7.74163e-11 loss)
I1011 15:26:51.231178 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.82694 (* 1 = 1.82694 loss)
I1011 15:26:51.231187 38966 sgd_solver.cpp:121] Iteration 1830, lr = 0.0005
I1011 15:26:56.176004 38966 yolov3_layer.cpp:532] noobj: 0.0017753 obj: 0.473079 iou: 0.512325 cat: 0.999997 recall: 0.594282 recall75: 0.131336 count: 28
I1011 15:26:57.058022 38966 solver.cpp:253] Iteration 1840 (1.71636 iter/s, 5.82629s/10 iters), loss = 1.7666
I1011 15:26:57.058192 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.77596e-10 (* 1 = 1.77596e-10 loss)
I1011 15:26:57.058240 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.42498 (* 1 = 1.42498 loss)
I1011 15:26:57.058279 38966 sgd_solver.cpp:121] Iteration 1840, lr = 0.0005
I1011 15:27:03.260279 38966 solver.cpp:253] Iteration 1850 (1.61251 iter/s, 6.20151s/10 iters), loss = 1.88009
I1011 15:27:03.260345 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.13947e-10 (* 1 = 2.13947e-10 loss)
I1011 15:27:03.260354 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.80848 (* 1 = 1.80848 loss)
I1011 15:27:03.260363 38966 sgd_solver.cpp:121] Iteration 1850, lr = 0.0005
I1011 15:27:06.561658 38966 yolov3_layer.cpp:532] noobj: 0.00152299 obj: 0.444215 iou: 0.510822 cat: 0.999998 recall: 0.62782 recall75: 0.120541 count: 28
I1011 15:27:10.798710 38966 solver.cpp:253] Iteration 1860 (1.32667 iter/s, 7.53766s/10 iters), loss = 1.78516
I1011 15:27:10.798950 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.07928e-10 (* 1 = 1.07928e-10 loss)
I1011 15:27:10.798967 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.11392 (* 1 = 1.11392 loss)
I1011 15:27:10.798979 38966 sgd_solver.cpp:121] Iteration 1860, lr = 0.0005
I1011 15:27:16.598096 38966 solver.cpp:253] Iteration 1870 (1.72455 iter/s, 5.79861s/10 iters), loss = 1.79756
I1011 15:27:16.598167 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.23492e-10 (* 1 = 1.23492e-10 loss)
I1011 15:27:16.598177 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.62913 (* 1 = 1.62913 loss)
I1011 15:27:16.598186 38966 sgd_solver.cpp:121] Iteration 1870, lr = 0.0005
I1011 15:27:16.817600 38966 yolov3_layer.cpp:532] noobj: 0.00150255 obj: 0.439371 iou: 0.51626 cat: 0.999998 recall: 0.592974 recall75: 0.118389 count: 27
I1011 15:27:23.655386 38966 solver.cpp:253] Iteration 1880 (1.41712 iter/s, 7.05657s/10 iters), loss = 1.91583
I1011 15:27:23.655468 38966 solver.cpp:272]     Train net output #0: det_loss1 = 8.35585e-11 (* 1 = 8.35585e-11 loss)
I1011 15:27:23.655480 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.65861 (* 1 = 1.65861 loss)
I1011 15:27:23.655489 38966 sgd_solver.cpp:121] Iteration 1880, lr = 0.0005
I1011 15:27:28.150645 38966 yolov3_layer.cpp:532] noobj: 0.00128326 obj: 0.458999 iou: 0.519475 cat: 0.999981 recall: 0.638703 recall75: 0.147769 count: 28
I1011 15:27:30.796603 38966 solver.cpp:253] Iteration 1890 (1.40046 iter/s, 7.14049s/10 iters), loss = 1.69736
I1011 15:27:30.796681 38966 solver.cpp:272]     Train net output #0: det_loss1 = 8.13808e-11 (* 1 = 8.13808e-11 loss)
I1011 15:27:30.796691 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.51086 (* 1 = 1.51086 loss)
I1011 15:27:30.796700 38966 sgd_solver.cpp:121] Iteration 1890, lr = 0.0005
I1011 15:27:37.780993 38966 solver.cpp:253] Iteration 1900 (1.43191 iter/s, 6.98368s/10 iters), loss = 1.85085
I1011 15:27:37.781044 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.99203e-11 (* 1 = 3.99203e-11 loss)
I1011 15:27:37.781054 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.98215 (* 1 = 2.98215 loss)
I1011 15:27:37.781075 38966 sgd_solver.cpp:121] Iteration 1900, lr = 0.0005
I1011 15:27:39.508949 38966 yolov3_layer.cpp:532] noobj: 0.00137868 obj: 0.470306 iou: 0.495441 cat: 0.999998 recall: 0.570661 recall75: 0.136583 count: 29
I1011 15:27:43.662989 38966 solver.cpp:253] Iteration 1910 (1.70028 iter/s, 5.88139s/10 iters), loss = 1.63779
I1011 15:27:43.663158 38966 solver.cpp:272]     Train net output #0: det_loss1 = 8.66991e-11 (* 1 = 8.66991e-11 loss)
I1011 15:27:43.663172 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.54587 (* 1 = 1.54587 loss)
I1011 15:27:43.663192 38966 sgd_solver.cpp:121] Iteration 1910, lr = 0.0005
I1011 15:27:48.596937 38966 yolov3_layer.cpp:532] noobj: 0.00189384 obj: 0.443792 iou: 0.487607 cat: 0.999999 recall: 0.575582 recall75: 0.109431 count: 26
I1011 15:27:49.800613 38966 solver.cpp:253] Iteration 1920 (1.62949 iter/s, 6.1369s/10 iters), loss = 1.78629
I1011 15:27:49.800688 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.22172e-10 (* 1 = 1.22172e-10 loss)
I1011 15:27:49.800699 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.30121 (* 1 = 2.30121 loss)
I1011 15:27:49.800709 38966 sgd_solver.cpp:121] Iteration 1920, lr = 0.0005
I1011 15:27:57.242580 38966 solver.cpp:253] Iteration 1930 (1.34387 iter/s, 7.44121s/10 iters), loss = 1.6401
I1011 15:27:57.242662 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.9332e-11 (* 1 = 2.9332e-11 loss)
I1011 15:27:57.242674 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.34643 (* 1 = 2.34643 loss)
I1011 15:27:57.242696 38966 sgd_solver.cpp:121] Iteration 1930, lr = 0.0005
I1011 15:27:59.805472 38966 yolov3_layer.cpp:532] noobj: 0.00117174 obj: 0.455886 iou: 0.537195 cat: 0.999998 recall: 0.662099 recall75: 0.150423 count: 26
I1011 15:28:03.248659 38966 solver.cpp:253] Iteration 1940 (1.66515 iter/s, 6.00548s/10 iters), loss = 1.69614
I1011 15:28:03.254256 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.03464e-10 (* 1 = 2.03464e-10 loss)
I1011 15:28:03.254272 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.74547 (* 1 = 1.74547 loss)
I1011 15:28:03.254292 38966 sgd_solver.cpp:121] Iteration 1940, lr = 0.0005
I1011 15:28:10.991633 38966 solver.cpp:253] Iteration 1950 (1.29254 iter/s, 7.73669s/10 iters), loss = 1.55894
I1011 15:28:10.991703 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.59331e-11 (* 1 = 5.59331e-11 loss)
I1011 15:28:10.991711 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.38203 (* 1 = 1.38203 loss)
I1011 15:28:10.991730 38966 sgd_solver.cpp:121] Iteration 1950, lr = 0.0005
I1011 15:28:11.231922 38966 yolov3_layer.cpp:532] noobj: 0.00124634 obj: 0.460909 iou: 0.527867 cat: 0.999995 recall: 0.623053 recall75: 0.134101 count: 27
I1011 15:28:18.555265 38966 solver.cpp:253] Iteration 1960 (1.32225 iter/s, 7.56288s/10 iters), loss = 1.65912
I1011 15:28:18.555534 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.25835e-11 (* 1 = 4.25835e-11 loss)
I1011 15:28:18.555547 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.56521 (* 1 = 1.56521 loss)
I1011 15:28:18.555557 38966 sgd_solver.cpp:121] Iteration 1960, lr = 0.0005
I1011 15:28:23.004379 38966 yolov3_layer.cpp:532] noobj: 0.00111509 obj: 0.476935 iou: 0.557659 cat: 0.999998 recall: 0.659259 recall75: 0.164166 count: 27
I1011 15:28:25.582600 38966 solver.cpp:253] Iteration 1970 (1.42319 iter/s, 7.02645s/10 iters), loss = 1.54415
I1011 15:28:25.588148 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.16152e-11 (* 1 = 4.16152e-11 loss)
I1011 15:28:25.588165 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.76614 (* 1 = 1.76614 loss)
I1011 15:28:25.588184 38966 sgd_solver.cpp:121] Iteration 1970, lr = 0.0005
I1011 15:28:33.204406 38966 solver.cpp:253] Iteration 1980 (1.3131 iter/s, 7.61558s/10 iters), loss = 1.50972
I1011 15:28:33.204495 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.06849e-11 (* 1 = 3.06849e-11 loss)
I1011 15:28:33.204507 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.4491 (* 1 = 1.4491 loss)
I1011 15:28:33.204526 38966 sgd_solver.cpp:121] Iteration 1980, lr = 0.0005
I1011 15:28:34.531831 38966 yolov3_layer.cpp:532] noobj: 0.00118742 obj: 0.468049 iou: 0.568528 cat: 0.999996 recall: 0.701008 recall75: 0.183752 count: 27
I1011 15:28:39.246316 38966 solver.cpp:253] Iteration 1990 (1.65527 iter/s, 6.04131s/10 iters), loss = 1.60905
I1011 15:28:39.246377 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.92041e-11 (* 1 = 1.92041e-11 loss)
I1011 15:28:39.246385 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.57811 (* 1 = 1.57811 loss)
I1011 15:28:39.246393 38966 sgd_solver.cpp:121] Iteration 1990, lr = 0.0005
I1011 15:28:44.363404 38966 yolov3_layer.cpp:532] noobj: 0.00133749 obj: 0.476338 iou: 0.507813 cat: 0.999999 recall: 0.603702 recall75: 0.123637 count: 25
I1011 15:28:44.764885 38966 solver.cpp:764] Snapshotting to binary proto file snapshot/yolov3_lite_deploy_iter_2000.caffemodel
I1011 15:28:44.807792 38966 sgd_solver.cpp:293] Snapshotting solver state to binary proto file snapshot/yolov3_lite_deploy_iter_2000.solverstate
I1011 15:28:44.829800 38966 solver.cpp:443] Iteration 2000, Testing net (#0)
I1011 15:28:44.829833 38966 net.cpp:679] Ignoring source layer label_data_1_split
I1011 15:28:44.830487 38966 net.cpp:679] Ignoring source layer Yolov3Loss1
I1011 15:28:44.830503 38966 net.cpp:679] Ignoring source layer Yolov3Loss2
I1011 15:28:47.349135 38966 blocking_queue.cpp:50] Waiting for data
I1011 15:29:00.454499 38966 blocking_queue.cpp:50] Waiting for data
I1011 15:29:12.840826 38966 blocking_queue.cpp:50] Waiting for data
I1011 15:29:25.642369 38966 blocking_queue.cpp:50] Waiting for data
I1011 15:29:38.265972 38966 blocking_queue.cpp:50] Waiting for data
I1011 15:29:45.269829 38966 solver.cpp:550] class1: 0.441617
I1011 15:29:45.269863 38966 solver.cpp:556]     Test net output #0: detection_eval = 0.441617
I1011 15:29:45.811851 38966 solver.cpp:253] Iteration 2000 (0.150241 iter/s, 66.5599s/10 iters), loss = 1.45617
I1011 15:29:45.811914 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.18034e-11 (* 1 = 2.18034e-11 loss)
I1011 15:29:45.811926 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.39697 (* 1 = 1.39697 loss)
I1011 15:29:45.811935 38966 sgd_solver.cpp:121] Iteration 2000, lr = 0.0005
I1011 15:29:51.114500 38966 solver.cpp:253] Iteration 2010 (1.88603 iter/s, 5.30215s/10 iters), loss = 1.65823
I1011 15:29:51.114560 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.95624e-11 (* 1 = 2.95624e-11 loss)
I1011 15:29:51.114569 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.50366 (* 1 = 1.50366 loss)
I1011 15:29:51.114578 38966 sgd_solver.cpp:121] Iteration 2010, lr = 0.0005
I1011 15:29:54.116430 38966 yolov3_layer.cpp:532] noobj: 0.0015167 obj: 0.488591 iou: 0.536398 cat: 0.999998 recall: 0.631414 recall75: 0.150159 count: 26
I1011 15:29:57.910782 38966 solver.cpp:253] Iteration 2020 (1.47153 iter/s, 6.79566s/10 iters), loss = 1.39793
I1011 15:29:57.910845 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.73955e-11 (* 1 = 1.73955e-11 loss)
I1011 15:29:57.910852 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.55116 (* 1 = 1.55116 loss)
I1011 15:29:57.910861 38966 sgd_solver.cpp:121] Iteration 2020, lr = 0.0005
I1011 15:30:04.474092 38966 solver.cpp:253] Iteration 2030 (1.52376 iter/s, 6.5627s/10 iters), loss = 1.46521
I1011 15:30:04.474181 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.30677e-11 (* 1 = 2.30677e-11 loss)
I1011 15:30:04.474205 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.40958 (* 1 = 1.40958 loss)
I1011 15:30:04.474213 38966 sgd_solver.cpp:121] Iteration 2030, lr = 0.0005
I1011 15:30:04.719640 38966 yolov3_layer.cpp:532] noobj: 0.00137594 obj: 0.522752 iou: 0.552386 cat: 0.999999 recall: 0.647105 recall75: 0.192049 count: 27
I1011 15:30:11.819568 38966 solver.cpp:253] Iteration 2040 (1.36151 iter/s, 7.34479s/10 iters), loss = 1.54514
I1011 15:30:11.819775 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.10693e-11 (* 1 = 2.10693e-11 loss)
I1011 15:30:11.819787 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.18715 (* 1 = 1.18715 loss)
I1011 15:30:11.819793 38966 sgd_solver.cpp:121] Iteration 2040, lr = 0.0005
I1011 15:30:15.702350 38966 yolov3_layer.cpp:532] noobj: 0.00157799 obj: 0.476536 iou: 0.507488 cat: 0.999999 recall: 0.614322 recall75: 0.127715 count: 27
I1011 15:30:18.022344 38966 solver.cpp:253] Iteration 2050 (1.61237 iter/s, 6.20205s/10 iters), loss = 1.75356
I1011 15:30:18.022454 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.28258e-11 (* 1 = 5.28258e-11 loss)
I1011 15:30:18.022475 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.61832 (* 1 = 1.61832 loss)
I1011 15:30:18.022485 38966 sgd_solver.cpp:121] Iteration 2050, lr = 0.0005
I1011 15:30:25.387359 38966 solver.cpp:253] Iteration 2060 (1.3579 iter/s, 7.3643s/10 iters), loss = 1.59676
I1011 15:30:25.387442 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.27107e-11 (* 1 = 1.27107e-11 loss)
I1011 15:30:25.387459 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.75837 (* 1 = 1.75837 loss)
I1011 15:30:25.387470 38966 sgd_solver.cpp:121] Iteration 2060, lr = 0.0005
I1011 15:30:26.991626 38966 yolov3_layer.cpp:532] noobj: 0.00132044 obj: 0.487269 iou: 0.562493 cat: 0.999997 recall: 0.680516 recall75: 0.199337 count: 26
I1011 15:30:31.822742 38966 solver.cpp:253] Iteration 2070 (1.55405 iter/s, 6.43478s/10 iters), loss = 1.50037
I1011 15:30:31.822861 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.76765e-11 (* 1 = 1.76765e-11 loss)
I1011 15:30:31.822875 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.48545 (* 1 = 1.48545 loss)
I1011 15:30:31.822896 38966 sgd_solver.cpp:121] Iteration 2070, lr = 0.0005
I1011 15:30:36.632390 38966 yolov3_layer.cpp:532] noobj: 0.00168681 obj: 0.511328 iou: 0.525129 cat: 0.999998 recall: 0.646007 recall75: 0.148223 count: 27
I1011 15:30:37.851521 38966 solver.cpp:253] Iteration 2080 (1.65888 iter/s, 6.02818s/10 iters), loss = 1.39368
I1011 15:30:37.851594 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.58212e-11 (* 1 = 2.58212e-11 loss)
I1011 15:30:37.851604 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.13939 (* 1 = 1.13939 loss)
I1011 15:30:37.851615 38966 sgd_solver.cpp:121] Iteration 2080, lr = 0.0005
I1011 15:30:45.539453 38966 solver.cpp:253] Iteration 2090 (1.30086 iter/s, 7.68725s/10 iters), loss = 1.33634
I1011 15:30:45.539700 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.5283e-11 (* 1 = 1.5283e-11 loss)
I1011 15:30:45.539710 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.73213 (* 1 = 1.73213 loss)
I1011 15:30:45.539718 38966 sgd_solver.cpp:121] Iteration 2090, lr = 0.0005
I1011 15:30:48.448760 38966 yolov3_layer.cpp:532] noobj: 0.00106545 obj: 0.5434 iou: 0.577011 cat: 0.999991 recall: 0.702755 recall75: 0.21878 count: 25
I1011 15:30:52.370679 38966 solver.cpp:253] Iteration 2100 (1.46404 iter/s, 6.83043s/10 iters), loss = 1.49534
I1011 15:30:52.370853 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.04908e-11 (* 1 = 1.04908e-11 loss)
I1011 15:30:52.370899 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.54422 (* 1 = 1.54422 loss)
I1011 15:30:52.370935 38966 sgd_solver.cpp:121] Iteration 2100, lr = 0.0005
I1011 15:30:58.596792 38966 solver.cpp:253] Iteration 2110 (1.60631 iter/s, 6.22545s/10 iters), loss = 1.58591
I1011 15:30:58.596859 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.21744e-11 (* 1 = 1.21744e-11 loss)
I1011 15:30:58.596869 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.29696 (* 1 = 1.29696 loss)
I1011 15:30:58.596876 38966 sgd_solver.cpp:121] Iteration 2110, lr = 0.0005
I1011 15:30:58.806972 38966 yolov3_layer.cpp:532] noobj: 0.00144423 obj: 0.505963 iou: 0.536792 cat: 0.999997 recall: 0.663094 recall75: 0.146489 count: 27
I1011 15:31:04.315052 38966 solver.cpp:253] Iteration 2120 (1.74894 iter/s, 5.71774s/10 iters), loss = 1.68495
I1011 15:31:04.315122 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.10321e-11 (* 1 = 3.10321e-11 loss)
I1011 15:31:04.315131 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.15103 (* 1 = 1.15103 loss)
I1011 15:31:04.315140 38966 sgd_solver.cpp:121] Iteration 2120, lr = 0.0005
I1011 15:31:09.069378 38966 yolov3_layer.cpp:532] noobj: 0.0017298 obj: 0.525366 iou: 0.534868 cat: 0.999998 recall: 0.631013 recall75: 0.156764 count: 28
I1011 15:31:11.623522 38966 solver.cpp:253] Iteration 2130 (1.36839 iter/s, 7.30784s/10 iters), loss = 1.44652
I1011 15:31:11.623581 38966 solver.cpp:272]     Train net output #0: det_loss1 = 7.86791e-12 (* 1 = 7.86791e-12 loss)
I1011 15:31:11.623590 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.71523 (* 1 = 1.71523 loss)
I1011 15:31:11.623597 38966 sgd_solver.cpp:121] Iteration 2130, lr = 0.0005
I1011 15:31:17.863270 38966 solver.cpp:253] Iteration 2140 (1.60277 iter/s, 6.2392s/10 iters), loss = 1.54284
I1011 15:31:17.863442 38966 solver.cpp:272]     Train net output #0: det_loss1 = 7.30284e-12 (* 1 = 7.30284e-12 loss)
I1011 15:31:17.863453 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.17997 (* 1 = 1.17997 loss)
I1011 15:31:17.863461 38966 sgd_solver.cpp:121] Iteration 2140, lr = 0.0005
I1011 15:31:19.227849 38966 yolov3_layer.cpp:532] noobj: 0.00163095 obj: 0.524112 iou: 0.527618 cat: 0.999999 recall: 0.64758 recall75: 0.177312 count: 27
I1011 15:31:24.161165 38966 solver.cpp:253] Iteration 2150 (1.588 iter/s, 6.29724s/10 iters), loss = 1.3013
I1011 15:31:24.161213 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.88243e-12 (* 1 = 4.88243e-12 loss)
I1011 15:31:24.161221 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.85112 (* 1 = 1.85112 loss)
I1011 15:31:24.161227 38966 sgd_solver.cpp:121] Iteration 2150, lr = 0.0005
I1011 15:31:29.349494 38966 yolov3_layer.cpp:532] noobj: 0.00156725 obj: 0.510753 iou: 0.536825 cat: 0.999998 recall: 0.640146 recall75: 0.192101 count: 26
I1011 15:31:30.135308 38966 solver.cpp:253] Iteration 2160 (1.67402 iter/s, 5.97363s/10 iters), loss = 1.34389
I1011 15:31:30.135373 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.00413e-12 (* 1 = 3.00413e-12 loss)
I1011 15:31:30.135390 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.14656 (* 1 = 1.14656 loss)
I1011 15:31:30.135401 38966 sgd_solver.cpp:121] Iteration 2160, lr = 0.0005
I1011 15:31:35.847136 38966 solver.cpp:253] Iteration 2170 (1.75091 iter/s, 5.71133s/10 iters), loss = 1.64007
I1011 15:31:35.847189 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.91549e-12 (* 1 = 2.91549e-12 loss)
I1011 15:31:35.847201 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.81271 (* 1 = 1.81271 loss)
I1011 15:31:35.847221 38966 sgd_solver.cpp:121] Iteration 2170, lr = 0.0005
I1011 15:31:38.343756 38966 yolov3_layer.cpp:532] noobj: 0.00202839 obj: 0.503246 iou: 0.470945 cat: 0.999999 recall: 0.525186 recall75: 0.127472 count: 27
I1011 15:31:41.355878 38966 solver.cpp:253] Iteration 2180 (1.81545 iter/s, 5.50827s/10 iters), loss = 1.50078
I1011 15:31:41.355933 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.55296e-12 (* 1 = 4.55296e-12 loss)
I1011 15:31:41.355957 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.56901 (* 1 = 1.56901 loss)
I1011 15:31:41.355968 38966 sgd_solver.cpp:121] Iteration 2180, lr = 0.0005
I1011 15:31:47.187737 38966 solver.cpp:253] Iteration 2190 (1.71487 iter/s, 5.83135s/10 iters), loss = 1.54876
I1011 15:31:47.187805 38966 solver.cpp:272]     Train net output #0: det_loss1 = 6.12446e-12 (* 1 = 6.12446e-12 loss)
I1011 15:31:47.187813 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.32749 (* 1 = 1.32749 loss)
I1011 15:31:47.187821 38966 sgd_solver.cpp:121] Iteration 2190, lr = 0.0005
I1011 15:31:47.388577 38966 yolov3_layer.cpp:532] noobj: 0.00199389 obj: 0.538477 iou: 0.507853 cat: 0.999999 recall: 0.590234 recall75: 0.139665 count: 26
I1011 15:31:53.006000 38966 solver.cpp:253] Iteration 2200 (1.71888 iter/s, 5.81776s/10 iters), loss = 1.4135
I1011 15:31:53.006196 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.20098e-12 (* 1 = 4.20098e-12 loss)
I1011 15:31:53.006207 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.32965 (* 1 = 1.32965 loss)
I1011 15:31:53.006215 38966 sgd_solver.cpp:121] Iteration 2200, lr = 0.0005
I1011 15:31:56.666487 38966 yolov3_layer.cpp:532] noobj: 0.00182746 obj: 0.53383 iou: 0.546099 cat: 0.999996 recall: 0.675849 recall75: 0.157133 count: 27
I1011 15:31:59.196692 38966 solver.cpp:253] Iteration 2210 (1.6155 iter/s, 6.19003s/10 iters), loss = 1.69495
I1011 15:31:59.196753 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.17556e-12 (* 1 = 4.17556e-12 loss)
I1011 15:31:59.196763 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.93199 (* 1 = 1.93199 loss)
I1011 15:31:59.196771 38966 sgd_solver.cpp:121] Iteration 2210, lr = 0.0005
I1011 15:32:05.326261 38966 solver.cpp:253] Iteration 2220 (1.63158 iter/s, 6.12905s/10 iters), loss = 1.52708
I1011 15:32:05.326321 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.25463e-12 (* 1 = 3.25463e-12 loss)
I1011 15:32:05.326329 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.95562 (* 1 = 1.95562 loss)
I1011 15:32:05.326337 38966 sgd_solver.cpp:121] Iteration 2220, lr = 0.0005
I1011 15:32:07.198997 38966 yolov3_layer.cpp:532] noobj: 0.0017228 obj: 0.497803 iou: 0.520438 cat: 0.999999 recall: 0.626556 recall75: 0.153385 count: 29
I1011 15:32:11.771796 38966 solver.cpp:253] Iteration 2230 (1.55159 iter/s, 6.44499s/10 iters), loss = 1.63785
I1011 15:32:11.771864 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.48798e-12 (* 1 = 3.48798e-12 loss)
I1011 15:32:11.771873 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.61014 (* 1 = 1.61014 loss)
I1011 15:32:11.771893 38966 sgd_solver.cpp:121] Iteration 2230, lr = 0.0005
I1011 15:32:16.581164 38966 yolov3_layer.cpp:532] noobj: 0.0017902 obj: 0.489623 iou: 0.509375 cat: 0.999999 recall: 0.627537 recall75: 0.17564 count: 28
I1011 15:32:17.492528 38966 solver.cpp:253] Iteration 2240 (1.74818 iter/s, 5.72023s/10 iters), loss = 1.59357
I1011 15:32:17.492589 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.55992e-12 (* 1 = 4.55992e-12 loss)
I1011 15:32:17.492599 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.44688 (* 1 = 1.44688 loss)
I1011 15:32:17.492604 38966 sgd_solver.cpp:121] Iteration 2240, lr = 0.0005
I1011 15:32:23.773768 38966 solver.cpp:253] Iteration 2250 (1.59218 iter/s, 6.2807s/10 iters), loss = 1.42154
I1011 15:32:23.773955 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.10214e-12 (* 1 = 4.10214e-12 loss)
I1011 15:32:23.773967 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.05362 (* 1 = 2.05362 loss)
I1011 15:32:23.773975 38966 sgd_solver.cpp:121] Iteration 2250, lr = 0.0005
I1011 15:32:27.177469 38966 yolov3_layer.cpp:532] noobj: 0.00152538 obj: 0.521254 iou: 0.547423 cat: 0.999999 recall: 0.670698 recall75: 0.185155 count: 27
I1011 15:32:31.504065 38966 solver.cpp:253] Iteration 2260 (1.29374 iter/s, 7.72954s/10 iters), loss = 1.43345
I1011 15:32:31.504118 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.2342e-12 (* 1 = 5.2342e-12 loss)
I1011 15:32:31.504127 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.38316 (* 1 = 1.38316 loss)
I1011 15:32:31.504145 38966 sgd_solver.cpp:121] Iteration 2260, lr = 0.0005
I1011 15:32:39.028426 38966 solver.cpp:253] Iteration 2270 (1.32913 iter/s, 7.52374s/10 iters), loss = 1.36975
I1011 15:32:39.028501 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.29403e-12 (* 1 = 3.29403e-12 loss)
I1011 15:32:39.028512 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.60765 (* 1 = 1.60765 loss)
I1011 15:32:39.028519 38966 sgd_solver.cpp:121] Iteration 2270, lr = 0.0005
I1011 15:32:39.238247 38966 yolov3_layer.cpp:532] noobj: 0.00104745 obj: 0.536611 iou: 0.582352 cat: 0.999975 recall: 0.719369 recall75: 0.215598 count: 26
I1011 15:32:45.280809 38966 solver.cpp:253] Iteration 2280 (1.59953 iter/s, 6.25184s/10 iters), loss = 1.49215
I1011 15:32:45.280870 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.71754e-12 (* 1 = 1.71754e-12 loss)
I1011 15:32:45.280879 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.21429 (* 1 = 1.21429 loss)
I1011 15:32:45.280885 38966 sgd_solver.cpp:121] Iteration 2280, lr = 0.0005
I1011 15:32:49.152343 38966 yolov3_layer.cpp:532] noobj: 0.00136691 obj: 0.501108 iou: 0.521343 cat: 0.999998 recall: 0.644284 recall75: 0.149993 count: 26
I1011 15:32:51.506240 38966 solver.cpp:253] Iteration 2290 (1.60645 iter/s, 6.22491s/10 iters), loss = 1.6053
I1011 15:32:51.506309 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.65354e-12 (* 1 = 1.65354e-12 loss)
I1011 15:32:51.506317 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.36663 (* 1 = 1.36663 loss)
I1011 15:32:51.506325 38966 sgd_solver.cpp:121] Iteration 2290, lr = 0.0005
I1011 15:32:58.279121 38966 solver.cpp:253] Iteration 2300 (1.4766 iter/s, 6.77232s/10 iters), loss = 1.3146
I1011 15:32:58.279372 38966 solver.cpp:272]     Train net output #0: det_loss1 = 7.67135e-13 (* 1 = 7.67135e-13 loss)
I1011 15:32:58.279386 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.77634 (* 1 = 1.77634 loss)
I1011 15:32:58.279393 38966 sgd_solver.cpp:121] Iteration 2300, lr = 0.0005
I1011 15:32:59.430569 38966 yolov3_layer.cpp:532] noobj: 0.00145524 obj: 0.552942 iou: 0.55535 cat: 0.999991 recall: 0.690639 recall75: 0.181349 count: 27
I1011 15:33:03.965495 38966 solver.cpp:253] Iteration 2310 (1.7588 iter/s, 5.68569s/10 iters), loss = 1.75819
I1011 15:33:03.965570 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.55952e-12 (* 1 = 4.55952e-12 loss)
I1011 15:33:03.965581 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.22217 (* 1 = 1.22217 loss)
I1011 15:33:03.965602 38966 sgd_solver.cpp:121] Iteration 2310, lr = 0.0005
I1011 15:33:10.448427 38966 yolov3_layer.cpp:532] noobj: 0.0016252 obj: 0.538782 iou: 0.541298 cat: 0.999996 recall: 0.634842 recall75: 0.172527 count: 28
I1011 15:33:11.380861 38966 solver.cpp:253] Iteration 2320 (1.34866 iter/s, 7.41475s/10 iters), loss = 1.54499
I1011 15:33:11.380946 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.42841e-12 (* 1 = 1.42841e-12 loss)
I1011 15:33:11.380962 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.79028 (* 1 = 1.79028 loss)
I1011 15:33:11.380975 38966 sgd_solver.cpp:121] Iteration 2320, lr = 0.0005
I1011 15:33:17.491819 38966 solver.cpp:253] Iteration 2330 (1.63655 iter/s, 6.11043s/10 iters), loss = 1.53187
I1011 15:33:17.491884 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.78045e-12 (* 1 = 2.78045e-12 loss)
I1011 15:33:17.491892 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.92077 (* 1 = 1.92077 loss)
I1011 15:33:17.491901 38966 sgd_solver.cpp:121] Iteration 2330, lr = 0.0005
I1011 15:33:20.750625 38966 yolov3_layer.cpp:532] noobj: 0.00181643 obj: 0.554926 iou: 0.53894 cat: 0.999995 recall: 0.672673 recall75: 0.205841 count: 27
I1011 15:33:24.692625 38966 solver.cpp:253] Iteration 2340 (1.38884 iter/s, 7.20023s/10 iters), loss = 1.35207
I1011 15:33:24.692688 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.06195e-12 (* 1 = 1.06195e-12 loss)
I1011 15:33:24.692696 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.41788 (* 1 = 1.41788 loss)
I1011 15:33:24.692703 38966 sgd_solver.cpp:121] Iteration 2340, lr = 0.0005
I1011 15:33:30.566959 38966 solver.cpp:253] Iteration 2350 (1.70246 iter/s, 5.87385s/10 iters), loss = 1.50168
I1011 15:33:30.567279 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.58423e-12 (* 1 = 2.58423e-12 loss)
I1011 15:33:30.567291 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.37998 (* 1 = 1.37998 loss)
I1011 15:33:30.567299 38966 sgd_solver.cpp:121] Iteration 2350, lr = 0.0005
I1011 15:33:30.888119 38966 yolov3_layer.cpp:532] noobj: 0.00195142 obj: 0.550096 iou: 0.537573 cat: 0.999999 recall: 0.664469 recall75: 0.179685 count: 28
I1011 15:33:36.756251 38966 solver.cpp:253] Iteration 2360 (1.6159 iter/s, 6.18852s/10 iters), loss = 1.2321
I1011 15:33:36.756399 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.28667e-12 (* 1 = 1.28667e-12 loss)
I1011 15:33:36.756438 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.2898 (* 1 = 1.2898 loss)
I1011 15:33:36.756466 38966 sgd_solver.cpp:121] Iteration 2360, lr = 0.0005
I1011 15:33:41.234933 38966 yolov3_layer.cpp:532] noobj: 0.00133792 obj: 0.558584 iou: 0.599059 cat: 0.999996 recall: 0.767573 recall75: 0.238715 count: 26
I1011 15:33:43.527456 38966 solver.cpp:253] Iteration 2370 (1.47698 iter/s, 6.77058s/10 iters), loss = 1.23293
I1011 15:33:43.527534 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.28862e-12 (* 1 = 3.28862e-12 loss)
I1011 15:33:43.527549 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.01665 (* 1 = 1.01665 loss)
I1011 15:33:43.527570 38966 sgd_solver.cpp:121] Iteration 2370, lr = 0.0005
I1011 15:33:49.793555 38966 solver.cpp:253] Iteration 2380 (1.59602 iter/s, 6.26558s/10 iters), loss = 1.57581
I1011 15:33:49.793604 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.01214e-12 (* 1 = 2.01214e-12 loss)
I1011 15:33:49.793614 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.90488 (* 1 = 1.90488 loss)
I1011 15:33:49.793619 38966 sgd_solver.cpp:121] Iteration 2380, lr = 0.0005
I1011 15:33:51.579632 38966 yolov3_layer.cpp:532] noobj: 0.00163629 obj: 0.576785 iou: 0.56373 cat: 0.999999 recall: 0.725551 recall75: 0.175716 count: 28
I1011 15:33:57.677142 38966 solver.cpp:253] Iteration 2390 (1.26856 iter/s, 7.88297s/10 iters), loss = 1.36122
I1011 15:33:57.677233 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.96922e-12 (* 1 = 1.96922e-12 loss)
I1011 15:33:57.677242 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.40121 (* 1 = 1.40121 loss)
I1011 15:33:57.677253 38966 sgd_solver.cpp:121] Iteration 2390, lr = 0.0005
I1011 15:34:04.183735 38966 yolov3_layer.cpp:532] noobj: 0.00112446 obj: 0.57743 iou: 0.617035 cat: 0.999997 recall: 0.7763 recall75: 0.282757 count: 27
I1011 15:34:05.245235 38966 solver.cpp:253] Iteration 2400 (1.32145 iter/s, 7.56746s/10 iters), loss = 1.30418
I1011 15:34:05.245388 38966 solver.cpp:272]     Train net output #0: det_loss1 = 7.1495e-13 (* 1 = 7.1495e-13 loss)
I1011 15:34:05.245434 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.39342 (* 1 = 1.39342 loss)
I1011 15:34:05.245471 38966 sgd_solver.cpp:121] Iteration 2400, lr = 0.0005
I1011 15:34:11.530512 38966 solver.cpp:253] Iteration 2410 (1.59117 iter/s, 6.2847s/10 iters), loss = 1.32465
I1011 15:34:11.530556 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.87934e-12 (* 1 = 1.87934e-12 loss)
I1011 15:34:11.530565 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.21328 (* 1 = 1.21328 loss)
I1011 15:34:11.530570 38966 sgd_solver.cpp:121] Iteration 2410, lr = 0.0005
I1011 15:34:14.155406 38966 yolov3_layer.cpp:532] noobj: 0.00174354 obj: 0.532282 iou: 0.554613 cat: 0.999998 recall: 0.694314 recall75: 0.236268 count: 27
I1011 15:34:17.368103 38966 solver.cpp:253] Iteration 2420 (1.71317 iter/s, 5.83714s/10 iters), loss = 1.53318
I1011 15:34:17.368163 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.91091e-13 (* 1 = 4.91091e-13 loss)
I1011 15:34:17.368171 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.60989 (* 1 = 1.60989 loss)
I1011 15:34:17.368178 38966 sgd_solver.cpp:121] Iteration 2420, lr = 0.0005
I1011 15:34:23.670341 38966 solver.cpp:253] Iteration 2430 (1.58687 iter/s, 6.30172s/10 iters), loss = 1.36614
I1011 15:34:23.670505 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.16992e-12 (* 1 = 1.16992e-12 loss)
I1011 15:34:23.670547 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.2239 (* 1 = 1.2239 loss)
I1011 15:34:23.670583 38966 sgd_solver.cpp:121] Iteration 2430, lr = 0.0005
I1011 15:34:23.942878 38966 yolov3_layer.cpp:532] noobj: 0.00181267 obj: 0.567055 iou: 0.556361 cat: 0.999994 recall: 0.687795 recall75: 0.214628 count: 27
I1011 15:34:30.304739 38966 solver.cpp:253] Iteration 2440 (1.50744 iter/s, 6.63378s/10 iters), loss = 1.37979
I1011 15:34:30.304810 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.01414e-12 (* 1 = 1.01414e-12 loss)
I1011 15:34:30.304821 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.00366 (* 1 = 2.00366 loss)
I1011 15:34:30.304829 38966 sgd_solver.cpp:121] Iteration 2440, lr = 0.0005
I1011 15:34:35.105701 38966 yolov3_layer.cpp:532] noobj: 0.00126285 obj: 0.541922 iou: 0.568625 cat: 0.999998 recall: 0.711682 recall75: 0.215913 count: 26
I1011 15:34:37.979178 38966 solver.cpp:253] Iteration 2450 (1.30313 iter/s, 7.67385s/10 iters), loss = 1.26389
I1011 15:34:37.979228 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.92207e-13 (* 1 = 5.92207e-13 loss)
I1011 15:34:37.979254 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.47746 (* 1 = 1.47746 loss)
I1011 15:34:37.979264 38966 sgd_solver.cpp:121] Iteration 2450, lr = 0.0005
I1011 15:34:44.926091 38966 solver.cpp:253] Iteration 2460 (1.4396 iter/s, 6.94639s/10 iters), loss = 1.25694
I1011 15:34:44.926163 38966 solver.cpp:272]     Train net output #0: det_loss1 = 6.89205e-13 (* 1 = 6.89205e-13 loss)
I1011 15:34:44.926177 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.23511 (* 1 = 1.23511 loss)
I1011 15:34:44.926199 38966 sgd_solver.cpp:121] Iteration 2460, lr = 0.0005
I1011 15:34:46.629981 38966 yolov3_layer.cpp:532] noobj: 0.00127292 obj: 0.594084 iou: 0.623094 cat: 0.999998 recall: 0.79853 recall75: 0.251741 count: 27
I1011 15:34:51.881191 38966 solver.cpp:253] Iteration 2470 (1.43791 iter/s, 6.95456s/10 iters), loss = 1.13632
I1011 15:34:51.881253 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.80208e-13 (* 1 = 5.80208e-13 loss)
I1011 15:34:51.881263 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.00234 (* 1 = 1.00234 loss)
I1011 15:34:51.881269 38966 sgd_solver.cpp:121] Iteration 2470, lr = 0.0005
I1011 15:34:57.344177 38966 yolov3_layer.cpp:532] noobj: 0.00153375 obj: 0.58845 iou: 0.571549 cat: 0.999999 recall: 0.72072 recall75: 0.269408 count: 26
I1011 15:34:58.378363 38966 solver.cpp:253] Iteration 2480 (1.53925 iter/s, 6.49667s/10 iters), loss = 1.19017
I1011 15:34:58.378429 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.05578e-13 (* 1 = 5.05578e-13 loss)
I1011 15:34:58.378437 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.971311 (* 1 = 0.971311 loss)
I1011 15:34:58.378445 38966 sgd_solver.cpp:121] Iteration 2480, lr = 0.0005
I1011 15:35:04.330967 38966 solver.cpp:253] Iteration 2490 (1.68007 iter/s, 5.95212s/10 iters), loss = 1.08976
I1011 15:35:04.331040 38966 solver.cpp:272]     Train net output #0: det_loss1 = 7.43328e-13 (* 1 = 7.43328e-13 loss)
I1011 15:35:04.331050 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.747727 (* 1 = 0.747727 loss)
I1011 15:35:04.331058 38966 sgd_solver.cpp:121] Iteration 2490, lr = 0.0005
I1011 15:35:06.838923 38966 yolov3_layer.cpp:532] noobj: 0.00162665 obj: 0.590129 iou: 0.594091 cat: 0.999999 recall: 0.722532 recall75: 0.262327 count: 26
I1011 15:35:10.101917 38966 solver.cpp:253] Iteration 2500 (1.73296 iter/s, 5.77049s/10 iters), loss = 1.36401
I1011 15:35:10.101979 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.99431e-13 (* 1 = 4.99431e-13 loss)
I1011 15:35:10.101989 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.49089 (* 1 = 1.49089 loss)
I1011 15:35:10.101996 38966 sgd_solver.cpp:121] Iteration 2500, lr = 0.0005
I1011 15:35:16.220357 38966 solver.cpp:253] Iteration 2510 (1.63453 iter/s, 6.11796s/10 iters), loss = 1.58341
I1011 15:35:16.220420 38966 solver.cpp:272]     Train net output #0: det_loss1 = 6.25065e-13 (* 1 = 6.25065e-13 loss)
I1011 15:35:16.220429 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.94643 (* 1 = 1.94643 loss)
I1011 15:35:16.220438 38966 sgd_solver.cpp:121] Iteration 2510, lr = 0.0005
I1011 15:35:16.464905 38966 yolov3_layer.cpp:532] noobj: 0.0021918 obj: 0.537776 iou: 0.510068 cat: 0.999998 recall: 0.602107 recall75: 0.163571 count: 28
I1011 15:35:23.468281 38966 solver.cpp:253] Iteration 2520 (1.37981 iter/s, 7.24737s/10 iters), loss = 1.26864
I1011 15:35:23.468348 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.56932e-13 (* 1 = 1.56932e-13 loss)
I1011 15:35:23.468358 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.37795 (* 1 = 2.37795 loss)
I1011 15:35:23.468366 38966 sgd_solver.cpp:121] Iteration 2520, lr = 0.0005
I1011 15:35:26.979697 38966 yolov3_layer.cpp:532] noobj: 0.00159348 obj: 0.558324 iou: 0.565988 cat: 0.999998 recall: 0.700106 recall75: 0.243091 count: 27
I1011 15:35:29.016999 38966 solver.cpp:253] Iteration 2530 (1.80236 iter/s, 5.54828s/10 iters), loss = 1.29717
I1011 15:35:29.017084 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.74574e-13 (* 1 = 3.74574e-13 loss)
I1011 15:35:29.017102 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.903366 (* 1 = 0.903366 loss)
I1011 15:35:29.017112 38966 sgd_solver.cpp:121] Iteration 2530, lr = 0.0005
I1011 15:35:36.121971 38966 solver.cpp:253] Iteration 2540 (1.40758 iter/s, 7.10441s/10 iters), loss = 1.21025
I1011 15:35:36.122043 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.04094e-13 (* 1 = 3.04094e-13 loss)
I1011 15:35:36.122052 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.00965 (* 1 = 1.00965 loss)
I1011 15:35:36.122061 38966 sgd_solver.cpp:121] Iteration 2540, lr = 0.0005
I1011 15:35:37.687666 38966 yolov3_layer.cpp:532] noobj: 0.00143374 obj: 0.592481 iou: 0.583699 cat: 0.999997 recall: 0.751538 recall75: 0.233312 count: 27
I1011 15:35:43.233639 38966 solver.cpp:253] Iteration 2550 (1.40625 iter/s, 7.11112s/10 iters), loss = 1.40932
I1011 15:35:43.233707 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.08147e-13 (* 1 = 4.08147e-13 loss)
I1011 15:35:43.233716 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.14412 (* 1 = 1.14412 loss)
I1011 15:35:43.233723 38966 sgd_solver.cpp:121] Iteration 2550, lr = 0.0005
I1011 15:35:49.646831 38966 yolov3_layer.cpp:532] noobj: 0.00125693 obj: 0.585817 iou: 0.603478 cat: 0.999999 recall: 0.767569 recall75: 0.239085 count: 28
I1011 15:35:50.674314 38966 solver.cpp:253] Iteration 2560 (1.34407 iter/s, 7.44011s/10 iters), loss = 1.3017
I1011 15:35:50.674383 38966 solver.cpp:272]     Train net output #0: det_loss1 = 8.16011e-13 (* 1 = 8.16011e-13 loss)
I1011 15:35:50.674394 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.5141 (* 1 = 1.5141 loss)
I1011 15:35:50.674403 38966 sgd_solver.cpp:121] Iteration 2560, lr = 0.0005
I1011 15:35:56.580337 38966 solver.cpp:253] Iteration 2570 (1.69332 iter/s, 5.90556s/10 iters), loss = 1.23942
I1011 15:35:56.580401 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.6011e-13 (* 1 = 5.6011e-13 loss)
I1011 15:35:56.580411 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.12141 (* 1 = 1.12141 loss)
I1011 15:35:56.580418 38966 sgd_solver.cpp:121] Iteration 2570, lr = 0.0005
I1011 15:35:59.468935 38966 yolov3_layer.cpp:532] noobj: 0.00173726 obj: 0.604108 iou: 0.571292 cat: 0.999998 recall: 0.694544 recall75: 0.249802 count: 27
I1011 15:36:02.871801 38966 solver.cpp:253] Iteration 2580 (1.58958 iter/s, 6.29098s/10 iters), loss = 1.09709
I1011 15:36:02.871870 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.05661e-13 (* 1 = 3.05661e-13 loss)
I1011 15:36:02.871879 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.968992 (* 1 = 0.968992 loss)
I1011 15:36:02.871887 38966 sgd_solver.cpp:121] Iteration 2580, lr = 0.0005
I1011 15:36:09.488198 38966 solver.cpp:253] Iteration 2590 (1.51151 iter/s, 6.61589s/10 iters), loss = 1.1362
I1011 15:36:09.488428 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.09953e-12 (* 1 = 1.09953e-12 loss)
I1011 15:36:09.488440 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.991679 (* 1 = 0.991679 loss)
I1011 15:36:09.488449 38966 sgd_solver.cpp:121] Iteration 2590, lr = 0.0005
I1011 15:36:09.740527 38966 yolov3_layer.cpp:532] noobj: 0.00163543 obj: 0.621328 iou: 0.578842 cat: 0.999999 recall: 0.72741 recall75: 0.237908 count: 25
I1011 15:36:17.080132 38966 solver.cpp:253] Iteration 2600 (1.31731 iter/s, 7.59121s/10 iters), loss = 1.11285
I1011 15:36:17.080221 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.32518e-13 (* 1 = 2.32518e-13 loss)
I1011 15:36:17.080231 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.878775 (* 1 = 0.878775 loss)
I1011 15:36:17.080251 38966 sgd_solver.cpp:121] Iteration 2600, lr = 0.0005
I1011 15:36:21.646067 38966 yolov3_layer.cpp:532] noobj: 0.00130429 obj: 0.624905 iou: 0.612864 cat: 0.999998 recall: 0.754971 recall75: 0.318798 count: 29
I1011 15:36:24.249200 38966 solver.cpp:253] Iteration 2610 (1.39499 iter/s, 7.16851s/10 iters), loss = 1.30769
I1011 15:36:24.249282 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.8633e-13 (* 1 = 2.8633e-13 loss)
I1011 15:36:24.249292 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.859123 (* 1 = 0.859123 loss)
I1011 15:36:24.249311 38966 sgd_solver.cpp:121] Iteration 2610, lr = 0.0005
I1011 15:36:31.601486 38966 solver.cpp:253] Iteration 2620 (1.36023 iter/s, 7.3517s/10 iters), loss = 1.22877
I1011 15:36:31.601586 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.06776e-13 (* 1 = 1.06776e-13 loss)
I1011 15:36:31.601595 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.62855 (* 1 = 1.62855 loss)
I1011 15:36:31.601605 38966 sgd_solver.cpp:121] Iteration 2620, lr = 0.0005
I1011 15:36:32.986873 38966 yolov3_layer.cpp:532] noobj: 0.00136222 obj: 0.577999 iou: 0.602068 cat: 0.999997 recall: 0.764633 recall75: 0.239708 count: 27
I1011 15:36:37.609297 38966 solver.cpp:253] Iteration 2630 (1.66464 iter/s, 6.00732s/10 iters), loss = 1.45222
I1011 15:36:37.609361 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.01223e-13 (* 1 = 3.01223e-13 loss)
I1011 15:36:37.609370 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.22145 (* 1 = 1.22145 loss)
I1011 15:36:37.609377 38966 sgd_solver.cpp:121] Iteration 2630, lr = 0.0005
I1011 15:36:42.998703 38966 yolov3_layer.cpp:532] noobj: 0.00190023 obj: 0.593311 iou: 0.568543 cat: 0.999999 recall: 0.698943 recall75: 0.222247 count: 28
I1011 15:36:44.100657 38966 solver.cpp:253] Iteration 2640 (1.54063 iter/s, 6.49087s/10 iters), loss = 1.08826
I1011 15:36:44.100723 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.00928e-13 (* 1 = 3.00928e-13 loss)
I1011 15:36:44.100733 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.807774 (* 1 = 0.807774 loss)
I1011 15:36:44.100740 38966 sgd_solver.cpp:121] Iteration 2640, lr = 0.0005
I1011 15:36:51.033763 38966 solver.cpp:253] Iteration 2650 (1.44246 iter/s, 6.93259s/10 iters), loss = 1.04668
I1011 15:36:51.033831 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.07685e-13 (* 1 = 2.07685e-13 loss)
I1011 15:36:51.033841 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.70039 (* 1 = 1.70039 loss)
I1011 15:36:51.033849 38966 sgd_solver.cpp:121] Iteration 2650, lr = 0.0005
I1011 15:36:53.700749 38966 yolov3_layer.cpp:532] noobj: 0.00145215 obj: 0.636155 iou: 0.620978 cat: 0.999999 recall: 0.78865 recall75: 0.305148 count: 27
I1011 15:36:57.296521 38966 solver.cpp:253] Iteration 2660 (1.59686 iter/s, 6.26229s/10 iters), loss = 1.21883
I1011 15:36:57.296572 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.11106e-13 (* 1 = 2.11106e-13 loss)
I1011 15:36:57.296581 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.44606 (* 1 = 1.44606 loss)
I1011 15:36:57.296591 38966 sgd_solver.cpp:121] Iteration 2660, lr = 0.0005
I1011 15:37:03.942759 38966 solver.cpp:253] Iteration 2670 (1.50472 iter/s, 6.64576s/10 iters), loss = 1.28373
I1011 15:37:03.942823 38966 solver.cpp:272]     Train net output #0: det_loss1 = 6.97839e-13 (* 1 = 6.97839e-13 loss)
I1011 15:37:03.942832 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.34238 (* 1 = 1.34238 loss)
I1011 15:37:03.942840 38966 sgd_solver.cpp:121] Iteration 2670, lr = 0.0005
I1011 15:37:04.183493 38966 yolov3_layer.cpp:532] noobj: 0.00180348 obj: 0.6224 iou: 0.553763 cat: 0.999999 recall: 0.67537 recall75: 0.234541 count: 27
I1011 15:37:11.563081 38966 solver.cpp:253] Iteration 2680 (1.31238 iter/s, 7.61976s/10 iters), loss = 1.09533
I1011 15:37:11.563153 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.11427e-13 (* 1 = 1.11427e-13 loss)
I1011 15:37:11.563163 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.09327 (* 1 = 1.09327 loss)
I1011 15:37:11.563170 38966 sgd_solver.cpp:121] Iteration 2680, lr = 0.0005
I1011 15:37:15.475862 38966 yolov3_layer.cpp:532] noobj: 0.00130797 obj: 0.634479 iou: 0.621601 cat: 0.999998 recall: 0.792986 recall75: 0.291338 count: 28
I1011 15:37:17.583927 38966 solver.cpp:253] Iteration 2690 (1.66103 iter/s, 6.02038s/10 iters), loss = 1.01985
I1011 15:37:17.583993 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.62507e-13 (* 1 = 4.62507e-13 loss)
I1011 15:37:17.584002 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.988447 (* 1 = 0.988447 loss)
I1011 15:37:17.584009 38966 sgd_solver.cpp:121] Iteration 2690, lr = 0.0005
I1011 15:37:23.635807 38966 solver.cpp:253] Iteration 2700 (1.65251 iter/s, 6.05141s/10 iters), loss = 1.28071
I1011 15:37:23.635967 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.55515e-13 (* 1 = 1.55515e-13 loss)
I1011 15:37:23.636013 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.60786 (* 1 = 1.60786 loss)
I1011 15:37:23.636045 38966 sgd_solver.cpp:121] Iteration 2700, lr = 0.0005
I1011 15:37:24.854823 38966 yolov3_layer.cpp:532] noobj: 0.00189531 obj: 0.613144 iou: 0.574776 cat: 0.999998 recall: 0.731337 recall75: 0.201791 count: 27
I1011 15:37:29.613867 38966 solver.cpp:253] Iteration 2710 (1.67293 iter/s, 5.97753s/10 iters), loss = 1.27138
I1011 15:37:29.613929 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.09905e-13 (* 1 = 2.09905e-13 loss)
I1011 15:37:29.613940 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.32577 (* 1 = 1.32577 loss)
I1011 15:37:29.613948 38966 sgd_solver.cpp:121] Iteration 2710, lr = 0.0005
I1011 15:37:35.915676 38966 yolov3_layer.cpp:532] noobj: 0.00154026 obj: 0.617875 iou: 0.599482 cat: 0.999998 recall: 0.759124 recall75: 0.241093 count: 27
I1011 15:37:36.832685 38966 solver.cpp:253] Iteration 2720 (1.38537 iter/s, 7.21827s/10 iters), loss = 1.25092
I1011 15:37:36.832792 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.65121e-12 (* 1 = 1.65121e-12 loss)
I1011 15:37:36.832809 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.57218 (* 1 = 1.57218 loss)
I1011 15:37:36.832826 38966 sgd_solver.cpp:121] Iteration 2720, lr = 0.0005
I1011 15:37:42.864286 38966 solver.cpp:253] Iteration 2730 (1.65807 iter/s, 6.03112s/10 iters), loss = 1.2101
I1011 15:37:42.864352 38966 solver.cpp:272]     Train net output #0: det_loss1 = 7.42508e-13 (* 1 = 7.42508e-13 loss)
I1011 15:37:42.864362 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.03934 (* 1 = 1.03934 loss)
I1011 15:37:42.864369 38966 sgd_solver.cpp:121] Iteration 2730, lr = 0.0005
I1011 15:37:46.136374 38966 yolov3_layer.cpp:532] noobj: 0.00178109 obj: 0.616742 iou: 0.569557 cat: 0.999998 recall: 0.695644 recall75: 0.280703 count: 26
I1011 15:37:50.437722 38966 solver.cpp:253] Iteration 2740 (1.3205 iter/s, 7.5729s/10 iters), loss = 1.0866
I1011 15:37:50.437784 38966 solver.cpp:272]     Train net output #0: det_loss1 = 6.85843e-13 (* 1 = 6.85843e-13 loss)
I1011 15:37:50.437793 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.26713 (* 1 = 1.26713 loss)
I1011 15:37:50.437801 38966 sgd_solver.cpp:121] Iteration 2740, lr = 0.0005
I1011 15:37:57.276180 38966 solver.cpp:253] Iteration 2750 (1.46242 iter/s, 6.83797s/10 iters), loss = 1.06973
I1011 15:37:57.276242 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.98983e-13 (* 1 = 1.98983e-13 loss)
I1011 15:37:57.276249 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.694034 (* 1 = 0.694034 loss)
I1011 15:37:57.276257 38966 sgd_solver.cpp:121] Iteration 2750, lr = 0.0005
I1011 15:37:57.744424 38966 yolov3_layer.cpp:532] noobj: 0.00123657 obj: 0.615462 iou: 0.602627 cat: 0.999997 recall: 0.76097 recall75: 0.269186 count: 26
I1011 15:38:02.962219 38966 solver.cpp:253] Iteration 2760 (1.75882 iter/s, 5.68562s/10 iters), loss = 1.38747
I1011 15:38:02.962267 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.6613e-13 (* 1 = 3.6613e-13 loss)
I1011 15:38:02.962277 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.86377 (* 1 = 1.86377 loss)
I1011 15:38:02.962285 38966 sgd_solver.cpp:121] Iteration 2760, lr = 0.0005
I1011 15:38:07.416817 38966 yolov3_layer.cpp:532] noobj: 0.00182964 obj: 0.58538 iou: 0.559613 cat: 0.999999 recall: 0.696563 recall75: 0.186382 count: 26
I1011 15:38:09.791503 38966 solver.cpp:253] Iteration 2770 (1.46439 iter/s, 6.8288s/10 iters), loss = 1.16324
I1011 15:38:09.791576 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.67141e-13 (* 1 = 3.67141e-13 loss)
I1011 15:38:09.791586 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.838116 (* 1 = 0.838116 loss)
I1011 15:38:09.791594 38966 sgd_solver.cpp:121] Iteration 2770, lr = 0.0005
I1011 15:38:17.423787 38966 solver.cpp:253] Iteration 2780 (1.31032 iter/s, 7.63174s/10 iters), loss = 1.21294
I1011 15:38:17.424003 38966 solver.cpp:272]     Train net output #0: det_loss1 = 7.62419e-13 (* 1 = 7.62419e-13 loss)
I1011 15:38:17.424015 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.01452 (* 1 = 1.01452 loss)
I1011 15:38:17.424022 38966 sgd_solver.cpp:121] Iteration 2780, lr = 0.0005
I1011 15:38:18.978466 38966 yolov3_layer.cpp:532] noobj: 3.42915e-05 obj: 5.02218e-09 iou: 0.302782 cat: 0.83301 recall: 0 recall75: 0 count: 1
I1011 15:38:19.020840 38966 yolov3_layer.cpp:532] noobj: 0.00123618 obj: 0.633809 iou: 0.627561 cat: 0.999998 recall: 0.79543 recall75: 0.291394 count: 27
I1011 15:38:24.182930 38966 solver.cpp:253] Iteration 2790 (1.47962 iter/s, 6.7585s/10 iters), loss = 1.05123
I1011 15:38:24.183002 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.21835e-13 (* 1 = 4.21835e-13 loss)
I1011 15:38:24.183012 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.982202 (* 1 = 0.982202 loss)
I1011 15:38:24.183020 38966 sgd_solver.cpp:121] Iteration 2790, lr = 0.0005
I1011 15:38:29.625192 38966 yolov3_layer.cpp:532] noobj: 0.0015747 obj: 0.628392 iou: 0.589591 cat: 0.999999 recall: 0.722368 recall75: 0.310752 count: 27
I1011 15:38:30.976219 38966 solver.cpp:253] Iteration 2800 (1.47215 iter/s, 6.7928s/10 iters), loss = 1.1884
I1011 15:38:30.976281 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.97456e-13 (* 1 = 4.97456e-13 loss)
I1011 15:38:30.976289 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.14584 (* 1 = 1.14584 loss)
I1011 15:38:30.976297 38966 sgd_solver.cpp:121] Iteration 2800, lr = 0.0005
I1011 15:38:38.488760 38966 solver.cpp:253] Iteration 2810 (1.3312 iter/s, 7.51202s/10 iters), loss = 1.07458
I1011 15:38:38.488819 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.56372e-13 (* 1 = 5.56372e-13 loss)
I1011 15:38:38.488842 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.33469 (* 1 = 1.33469 loss)
I1011 15:38:38.488852 38966 sgd_solver.cpp:121] Iteration 2810, lr = 0.0005
I1011 15:38:40.862342 38966 yolov3_layer.cpp:532] noobj: 0.00137984 obj: 0.646989 iou: 0.639872 cat: 0.999997 recall: 0.817079 recall75: 0.320437 count: 28
I1011 15:38:44.292160 38966 solver.cpp:253] Iteration 2820 (1.72325 iter/s, 5.80298s/10 iters), loss = 1.14326
I1011 15:38:44.292251 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.08659e-12 (* 1 = 1.08659e-12 loss)
I1011 15:38:44.292263 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.23411 (* 1 = 1.23411 loss)
I1011 15:38:44.292284 38966 sgd_solver.cpp:121] Iteration 2820, lr = 0.0005
I1011 15:38:50.900143 38966 solver.cpp:253] Iteration 2830 (1.51344 iter/s, 6.60748s/10 iters), loss = 1.19189
I1011 15:38:50.900413 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.10614e-13 (* 1 = 2.10614e-13 loss)
I1011 15:38:50.900425 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.0795 (* 1 = 1.0795 loss)
I1011 15:38:50.900434 38966 sgd_solver.cpp:121] Iteration 2830, lr = 0.0005
I1011 15:38:51.157637 38966 yolov3_layer.cpp:532] noobj: 0.00158767 obj: 0.644562 iou: 0.586661 cat: 0.999999 recall: 0.73029 recall75: 0.247987 count: 27
I1011 15:38:58.661384 38966 solver.cpp:253] Iteration 2840 (1.28858 iter/s, 7.76049s/10 iters), loss = 1.01384
I1011 15:38:58.661448 38966 solver.cpp:272]     Train net output #0: det_loss1 = 7.28799e-13 (* 1 = 7.28799e-13 loss)
I1011 15:38:58.661458 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.956509 (* 1 = 0.956509 loss)
I1011 15:38:58.661465 38966 sgd_solver.cpp:121] Iteration 2840, lr = 0.0005
I1011 15:39:03.404731 38966 yolov3_layer.cpp:532] noobj: 0.00111754 obj: 0.687117 iou: 0.658564 cat: 0.999998 recall: 0.827297 recall75: 0.351751 count: 27
I1011 15:39:06.180564 38966 solver.cpp:253] Iteration 2850 (1.33003 iter/s, 7.51865s/10 iters), loss = 0.914946
I1011 15:39:06.180645 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.41867e-13 (* 1 = 3.41867e-13 loss)
I1011 15:39:06.180655 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.03553 (* 1 = 1.03553 loss)
I1011 15:39:06.180663 38966 sgd_solver.cpp:121] Iteration 2850, lr = 0.0005
I1011 15:39:13.767716 38966 solver.cpp:253] Iteration 2860 (1.31811 iter/s, 7.58662s/10 iters), loss = 0.951252
I1011 15:39:13.767781 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.94599e-13 (* 1 = 1.94599e-13 loss)
I1011 15:39:13.767789 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.04602 (* 1 = 1.04602 loss)
I1011 15:39:13.767799 38966 sgd_solver.cpp:121] Iteration 2860, lr = 0.0005
I1011 15:39:15.412098 38966 yolov3_layer.cpp:532] noobj: 0.00119583 obj: 0.68058 iou: 0.644118 cat: 0.999998 recall: 0.801323 recall75: 0.344261 count: 27
I1011 15:39:20.835268 38966 solver.cpp:253] Iteration 2870 (1.41502 iter/s, 7.06704s/10 iters), loss = 1.04052
I1011 15:39:20.835350 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.2709e-13 (* 1 = 1.2709e-13 loss)
I1011 15:39:20.835359 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.829666 (* 1 = 0.829666 loss)
I1011 15:39:20.835381 38966 sgd_solver.cpp:121] Iteration 2870, lr = 0.0005
I1011 15:39:26.819051 38966 yolov3_layer.cpp:532] noobj: 0.0013924 obj: 0.652866 iou: 0.610468 cat: 0.999998 recall: 0.772229 recall75: 0.277718 count: 28
I1011 15:39:28.004621 38966 solver.cpp:253] Iteration 2880 (1.39493 iter/s, 7.16884s/10 iters), loss = 1.19464
I1011 15:39:28.004685 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.20323e-13 (* 1 = 2.20323e-13 loss)
I1011 15:39:28.004696 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.25941 (* 1 = 1.25941 loss)
I1011 15:39:28.004704 38966 sgd_solver.cpp:121] Iteration 2880, lr = 0.0005
I1011 15:39:35.089222 38966 solver.cpp:253] Iteration 2890 (1.41161 iter/s, 7.0841s/10 iters), loss = 1.1238
I1011 15:39:35.089308 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.11081e-13 (* 1 = 2.11081e-13 loss)
I1011 15:39:35.089326 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.34551 (* 1 = 1.34551 loss)
I1011 15:39:35.089340 38966 sgd_solver.cpp:121] Iteration 2890, lr = 0.0005
I1011 15:39:37.814397 38966 yolov3_layer.cpp:532] noobj: 0.00157468 obj: 0.644205 iou: 0.607254 cat: 0.999995 recall: 0.732307 recall75: 0.31631 count: 29
I1011 15:39:41.426018 38966 solver.cpp:253] Iteration 2900 (1.5782 iter/s, 6.33634s/10 iters), loss = 1.15947
I1011 15:39:41.426084 38966 solver.cpp:272]     Train net output #0: det_loss1 = 8.61387e-13 (* 1 = 8.61387e-13 loss)
I1011 15:39:41.426092 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.27131 (* 1 = 1.27131 loss)
I1011 15:39:41.426100 38966 sgd_solver.cpp:121] Iteration 2900, lr = 0.0005
I1011 15:39:48.508347 38966 solver.cpp:253] Iteration 2910 (1.41206 iter/s, 7.08184s/10 iters), loss = 1.12593
I1011 15:39:48.508414 38966 solver.cpp:272]     Train net output #0: det_loss1 = 0.135982 (* 1 = 0.135982 loss)
I1011 15:39:48.508424 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.26781 (* 1 = 1.26781 loss)
I1011 15:39:48.508431 38966 sgd_solver.cpp:121] Iteration 2910, lr = 0.0005
I1011 15:39:48.792845 38966 yolov3_layer.cpp:532] noobj: 1.15066e-07 obj: 6.55614e-07 iou: 0.430241 cat: 0.891734 recall: 0 recall75: 0 count: 1
I1011 15:39:48.834501 38966 yolov3_layer.cpp:532] noobj: 0.00152865 obj: 0.625874 iou: 0.594754 cat: 0.999998 recall: 0.727897 recall75: 0.268589 count: 28
I1011 15:39:55.492976 38966 solver.cpp:253] Iteration 2920 (1.43182 iter/s, 6.98414s/10 iters), loss = 0.989263
I1011 15:39:55.493059 38966 solver.cpp:272]     Train net output #0: det_loss1 = 9.11191e-13 (* 1 = 9.11191e-13 loss)
I1011 15:39:55.493069 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.00413 (* 1 = 1.00413 loss)
I1011 15:39:55.493078 38966 sgd_solver.cpp:121] Iteration 2920, lr = 0.0005
I1011 15:39:59.843654 38966 yolov3_layer.cpp:532] noobj: 0.00129759 obj: 0.659845 iou: 0.620627 cat: 0.999994 recall: 0.777649 recall75: 0.299696 count: 26
I1011 15:40:02.362541 38966 solver.cpp:253] Iteration 2930 (1.4558 iter/s, 6.86907s/10 iters), loss = 1.05099
I1011 15:40:02.362599 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.9596e-12 (* 1 = 1.9596e-12 loss)
I1011 15:40:02.362609 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.55768 (* 1 = 0.55768 loss)
I1011 15:40:02.362617 38966 sgd_solver.cpp:121] Iteration 2930, lr = 0.0005
I1011 15:40:08.753509 38966 solver.cpp:253] Iteration 2940 (1.56482 iter/s, 6.39052s/10 iters), loss = 1.02985
I1011 15:40:08.753568 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.4997e-12 (* 1 = 1.4997e-12 loss)
I1011 15:40:08.753578 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.926248 (* 1 = 0.926248 loss)
I1011 15:40:08.753587 38966 sgd_solver.cpp:121] Iteration 2940, lr = 0.0005
I1011 15:40:10.394996 38966 yolov3_layer.cpp:532] noobj: 0.00150307 obj: 0.64907 iou: 0.631626 cat: 0.999999 recall: 0.790688 recall75: 0.329109 count: 27
I1011 15:40:15.605113 38966 solver.cpp:253] Iteration 2950 (1.45961 iter/s, 6.85113s/10 iters), loss = 1.10356
I1011 15:40:15.605180 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.8853e-13 (* 1 = 3.8853e-13 loss)
I1011 15:40:15.605190 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.05416 (* 1 = 1.05416 loss)
I1011 15:40:15.605196 38966 sgd_solver.cpp:121] Iteration 2950, lr = 0.0005
I1011 15:40:20.665082 38966 yolov3_layer.cpp:532] noobj: 0.00142183 obj: 0.650361 iou: 0.634243 cat: 0.999998 recall: 0.804364 recall75: 0.329096 count: 28
I1011 15:40:21.859926 38966 solver.cpp:253] Iteration 2960 (1.59888 iter/s, 6.25437s/10 iters), loss = 0.998326
I1011 15:40:21.860007 38966 solver.cpp:272]     Train net output #0: det_loss1 = 9.41119e-13 (* 1 = 9.41119e-13 loss)
I1011 15:40:21.860015 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.26986 (* 1 = 1.26986 loss)
I1011 15:40:21.860035 38966 sgd_solver.cpp:121] Iteration 2960, lr = 0.0005
I1011 15:40:28.925160 38966 solver.cpp:253] Iteration 2970 (1.41549 iter/s, 7.06471s/10 iters), loss = 1.0473
I1011 15:40:28.925221 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.17255e-13 (* 1 = 4.17255e-13 loss)
I1011 15:40:28.925232 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.946272 (* 1 = 0.946272 loss)
I1011 15:40:28.925240 38966 sgd_solver.cpp:121] Iteration 2970, lr = 0.0005
I1011 15:40:31.495112 38966 yolov3_layer.cpp:532] noobj: 0.0015049 obj: 0.657041 iou: 0.603248 cat: 0.999998 recall: 0.757125 recall75: 0.268017 count: 28
I1011 15:40:34.544884 38966 solver.cpp:253] Iteration 2980 (1.77957 iter/s, 5.61933s/10 iters), loss = 1.06618
I1011 15:40:34.544950 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.67799e-13 (* 1 = 1.67799e-13 loss)
I1011 15:40:34.544958 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.06691 (* 1 = 1.06691 loss)
I1011 15:40:34.544965 38966 sgd_solver.cpp:121] Iteration 2980, lr = 0.0005
I1011 15:40:40.578316 38966 solver.cpp:253] Iteration 2990 (1.65755 iter/s, 6.03301s/10 iters), loss = 1.19801
I1011 15:40:40.578380 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.01171e-13 (* 1 = 2.01171e-13 loss)
I1011 15:40:40.578388 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.05811 (* 1 = 1.05811 loss)
I1011 15:40:40.578397 38966 sgd_solver.cpp:121] Iteration 2990, lr = 0.0005
I1011 15:40:40.727648 38966 yolov3_layer.cpp:532] noobj: 0.00183994 obj: 0.641799 iou: 0.596948 cat: 0.999992 recall: 0.76177 recall75: 0.26061 count: 27
I1011 15:40:41.646992 38966 blocking_queue.cpp:50] Waiting for data
I1011 15:40:45.595541 38966 solver.cpp:764] Snapshotting to binary proto file snapshot/yolov3_lite_deploy_iter_3000.caffemodel
I1011 15:40:45.641253 38966 sgd_solver.cpp:293] Snapshotting solver state to binary proto file snapshot/yolov3_lite_deploy_iter_3000.solverstate
I1011 15:40:45.659782 38966 solver.cpp:443] Iteration 3000, Testing net (#0)
I1011 15:40:45.659824 38966 net.cpp:679] Ignoring source layer label_data_1_split
I1011 15:40:45.660315 38966 net.cpp:679] Ignoring source layer Yolov3Loss1
I1011 15:40:45.660321 38966 net.cpp:679] Ignoring source layer Yolov3Loss2
I1011 15:40:58.668709 38966 blocking_queue.cpp:50] Waiting for data
I1011 15:41:11.774221 38966 blocking_queue.cpp:50] Waiting for data
I1011 15:41:25.095934 38966 blocking_queue.cpp:50] Waiting for data
I1011 15:41:38.218473 38966 blocking_queue.cpp:50] Waiting for data
I1011 15:41:47.546732 38966 solver.cpp:550] class1: 0.834477
I1011 15:41:47.546902 38966 solver.cpp:556]     Test net output #0: detection_eval = 0.834477
I1011 15:41:48.148319 38966 solver.cpp:253] Iteration 3000 (0.148003 iter/s, 67.5661s/10 iters), loss = 1.10488
I1011 15:41:48.148380 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.16043e-13 (* 1 = 5.16043e-13 loss)
I1011 15:41:48.148394 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.856509 (* 1 = 0.856509 loss)
I1011 15:41:48.148403 38966 sgd_solver.cpp:121] Iteration 3000, lr = 0.0005
I1011 15:41:51.865481 38966 yolov3_layer.cpp:532] noobj: 0.00194639 obj: 0.643608 iou: 0.566631 cat: 0.999999 recall: 0.699751 recall75: 0.259615 count: 27
I1011 15:41:54.024739 38966 solver.cpp:253] Iteration 3010 (1.70183 iter/s, 5.87601s/10 iters), loss = 1.0816
I1011 15:41:54.024811 38966 solver.cpp:272]     Train net output #0: det_loss1 = 7.62663e-13 (* 1 = 7.62663e-13 loss)
I1011 15:41:54.024821 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.08752 (* 1 = 1.08752 loss)
I1011 15:41:54.024829 38966 sgd_solver.cpp:121] Iteration 3010, lr = 0.0005
I1011 15:42:00.684736 38966 solver.cpp:253] Iteration 3020 (1.50161 iter/s, 6.65954s/10 iters), loss = 1.14384
I1011 15:42:00.684803 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.47808e-12 (* 1 = 1.47808e-12 loss)
I1011 15:42:00.684813 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.60391 (* 1 = 0.60391 loss)
I1011 15:42:00.684820 38966 sgd_solver.cpp:121] Iteration 3020, lr = 0.0005
I1011 15:42:02.259213 38966 yolov3_layer.cpp:532] noobj: 0.00154908 obj: 0.649296 iou: 0.610146 cat: 0.999999 recall: 0.751135 recall75: 0.288345 count: 26
I1011 15:42:07.396200 38966 solver.cpp:253] Iteration 3030 (1.49009 iter/s, 6.711s/10 iters), loss = 0.951797
I1011 15:42:07.396277 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.95488e-12 (* 1 = 1.95488e-12 loss)
I1011 15:42:07.396286 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.0776 (* 1 = 1.0776 loss)
I1011 15:42:07.396306 38966 sgd_solver.cpp:121] Iteration 3030, lr = 0.0005
I1011 15:42:12.554073 38966 yolov3_layer.cpp:532] noobj: 0.00138261 obj: 0.661919 iou: 0.617951 cat: 0.999991 recall: 0.808099 recall75: 0.270788 count: 26
I1011 15:42:13.786336 38966 solver.cpp:253] Iteration 3040 (1.56502 iter/s, 6.38969s/10 iters), loss = 1.08595
I1011 15:42:13.786402 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.22427e-12 (* 1 = 2.22427e-12 loss)
I1011 15:42:13.786412 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.2172 (* 1 = 1.2172 loss)
I1011 15:42:13.786419 38966 sgd_solver.cpp:121] Iteration 3040, lr = 0.0005
I1011 15:42:21.652930 38966 solver.cpp:253] Iteration 3050 (1.27128 iter/s, 7.86608s/10 iters), loss = 0.997217
I1011 15:42:21.653146 38966 solver.cpp:272]     Train net output #0: det_loss1 = 8.33829e-13 (* 1 = 8.33829e-13 loss)
I1011 15:42:21.653158 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.945611 (* 1 = 0.945611 loss)
I1011 15:42:21.653168 38966 sgd_solver.cpp:121] Iteration 3050, lr = 0.0005
I1011 15:42:24.611117 38966 yolov3_layer.cpp:532] noobj: 0.00125331 obj: 0.689367 iou: 0.648855 cat: 0.999996 recall: 0.813641 recall75: 0.325788 count: 27
I1011 15:42:28.272318 38966 solver.cpp:253] Iteration 3060 (1.51085 iter/s, 6.61879s/10 iters), loss = 1.0559
I1011 15:42:28.272393 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.46427e-13 (* 1 = 2.46427e-13 loss)
I1011 15:42:28.272404 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.19186 (* 1 = 1.19186 loss)
I1011 15:42:28.272413 38966 sgd_solver.cpp:121] Iteration 3060, lr = 0.0005
I1011 15:42:34.096619 38966 solver.cpp:253] Iteration 3070 (1.71706 iter/s, 5.82389s/10 iters), loss = 1.30111
I1011 15:42:34.096684 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.95968e-13 (* 1 = 3.95968e-13 loss)
I1011 15:42:34.096693 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.862635 (* 1 = 0.862635 loss)
I1011 15:42:34.096700 38966 sgd_solver.cpp:121] Iteration 3070, lr = 0.0005
I1011 15:42:34.302081 38966 yolov3_layer.cpp:532] noobj: 0.00196095 obj: 0.636741 iou: 0.589502 cat: 0.999998 recall: 0.735934 recall75: 0.239646 count: 27
I1011 15:42:40.561867 38966 solver.cpp:253] Iteration 3080 (1.54684 iter/s, 6.46481s/10 iters), loss = 1.0513
I1011 15:42:40.561926 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.46338e-13 (* 1 = 3.46338e-13 loss)
I1011 15:42:40.561936 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.815385 (* 1 = 0.815385 loss)
I1011 15:42:40.561947 38966 sgd_solver.cpp:121] Iteration 3080, lr = 0.0005
I1011 15:42:44.825899 38966 yolov3_layer.cpp:532] noobj: 0.00169612 obj: 0.65393 iou: 0.575623 cat: 0.999999 recall: 0.704545 recall75: 0.260874 count: 27
I1011 15:42:46.869449 38966 solver.cpp:253] Iteration 3090 (1.5855 iter/s, 6.30717s/10 iters), loss = 1.04274
I1011 15:42:46.869514 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.87622e-13 (* 1 = 2.87622e-13 loss)
I1011 15:42:46.869524 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.982162 (* 1 = 0.982162 loss)
I1011 15:42:46.869534 38966 sgd_solver.cpp:121] Iteration 3090, lr = 0.0005
I1011 15:42:52.114516 38966 solver.cpp:253] Iteration 3100 (1.90669 iter/s, 5.2447s/10 iters), loss = 1.03154
I1011 15:42:52.114821 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.92459e-12 (* 1 = 2.92459e-12 loss)
I1011 15:42:52.114832 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.0706 (* 1 = 1.0706 loss)
I1011 15:42:52.114841 38966 sgd_solver.cpp:121] Iteration 3100, lr = 0.0005
I1011 15:42:53.675601 38966 yolov3_layer.cpp:532] noobj: 0.00197461 obj: 0.677347 iou: 0.596739 cat: 0.999999 recall: 0.748018 recall75: 0.275256 count: 26
I1011 15:42:58.938045 38966 solver.cpp:253] Iteration 3110 (1.46567 iter/s, 6.82283s/10 iters), loss = 0.838497
I1011 15:42:58.938104 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.35918e-12 (* 1 = 1.35918e-12 loss)
I1011 15:42:58.938112 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.970144 (* 1 = 0.970144 loss)
I1011 15:42:58.938120 38966 sgd_solver.cpp:121] Iteration 3110, lr = 0.0005
I1011 15:43:04.435778 38966 yolov3_layer.cpp:532] noobj: 0.0014406 obj: 0.699394 iou: 0.645227 cat: 0.999999 recall: 0.816731 recall75: 0.349691 count: 27
I1011 15:43:05.391749 38966 solver.cpp:253] Iteration 3120 (1.5496 iter/s, 6.45328s/10 iters), loss = 0.968922
I1011 15:43:05.391824 38966 solver.cpp:272]     Train net output #0: det_loss1 = 6.54152e-13 (* 1 = 6.54152e-13 loss)
I1011 15:43:05.391832 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.01283 (* 1 = 1.01283 loss)
I1011 15:43:05.391851 38966 sgd_solver.cpp:121] Iteration 3120, lr = 0.0005
I1011 15:43:11.662139 38966 solver.cpp:253] Iteration 3130 (1.59491 iter/s, 6.26996s/10 iters), loss = 0.944549
I1011 15:43:11.662212 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.3179e-12 (* 1 = 1.3179e-12 loss)
I1011 15:43:11.662222 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.00086 (* 1 = 1.00086 loss)
I1011 15:43:11.662230 38966 sgd_solver.cpp:121] Iteration 3130, lr = 0.0005
I1011 15:43:14.521353 38966 yolov3_layer.cpp:532] noobj: 0.00155796 obj: 0.652462 iou: 0.61355 cat: 0.999993 recall: 0.761128 recall75: 0.330278 count: 24
I1011 15:43:18.259629 38966 solver.cpp:253] Iteration 3140 (1.51583 iter/s, 6.59704s/10 iters), loss = 0.935749
I1011 15:43:18.259693 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.1249e-13 (* 1 = 1.1249e-13 loss)
I1011 15:43:18.259702 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.12883 (* 1 = 1.12883 loss)
I1011 15:43:18.259709 38966 sgd_solver.cpp:121] Iteration 3140, lr = 0.0005
I1011 15:43:24.131585 38966 solver.cpp:253] Iteration 3150 (1.70313 iter/s, 5.87156s/10 iters), loss = 1.27303
I1011 15:43:24.131798 38966 solver.cpp:272]     Train net output #0: det_loss1 = 6.97441e-13 (* 1 = 6.97441e-13 loss)
I1011 15:43:24.131809 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.20186 (* 1 = 1.20186 loss)
I1011 15:43:24.131821 38966 sgd_solver.cpp:121] Iteration 3150, lr = 0.0005
I1011 15:43:24.366222 38966 yolov3_layer.cpp:532] noobj: 0.00187335 obj: 0.640684 iou: 0.565752 cat: 0.999998 recall: 0.696902 recall75: 0.230576 count: 27
I1011 15:43:31.455121 38966 solver.cpp:253] Iteration 3160 (1.36558 iter/s, 7.32291s/10 iters), loss = 0.913589
I1011 15:43:31.455191 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.60891e-12 (* 1 = 1.60891e-12 loss)
I1011 15:43:31.455200 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.974728 (* 1 = 0.974728 loss)
I1011 15:43:31.455209 38966 sgd_solver.cpp:121] Iteration 3160, lr = 0.0005
I1011 15:43:36.397111 38966 yolov3_layer.cpp:532] noobj: 0.00126115 obj: 0.678885 iou: 0.645141 cat: 0.999985 recall: 0.807768 recall75: 0.335125 count: 26
I1011 15:43:39.002185 38966 solver.cpp:253] Iteration 3170 (1.32511 iter/s, 7.54657s/10 iters), loss = 1.03292
I1011 15:43:39.002260 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.48132e-13 (* 1 = 3.48132e-13 loss)
I1011 15:43:39.002271 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.54163 (* 1 = 1.54163 loss)
I1011 15:43:39.002280 38966 sgd_solver.cpp:121] Iteration 3170, lr = 0.0005
I1011 15:43:44.961088 38966 solver.cpp:253] Iteration 3180 (1.67828 iter/s, 5.95849s/10 iters), loss = 1.11184
I1011 15:43:44.961165 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.77925e-12 (* 1 = 1.77925e-12 loss)
I1011 15:43:44.961175 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.10829 (* 1 = 1.10829 loss)
I1011 15:43:44.961185 38966 sgd_solver.cpp:121] Iteration 3180, lr = 0.0005
I1011 15:43:46.869187 38966 yolov3_layer.cpp:532] noobj: 0.00192548 obj: 0.646206 iou: 0.585793 cat: 0.999999 recall: 0.749036 recall75: 0.287662 count: 28
I1011 15:43:52.712479 38966 solver.cpp:253] Iteration 3190 (1.29018 iter/s, 7.75089s/10 iters), loss = 1.10073
I1011 15:43:52.712553 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.46557e-13 (* 1 = 2.46557e-13 loss)
I1011 15:43:52.712563 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.801164 (* 1 = 0.801164 loss)
I1011 15:43:52.712571 38966 sgd_solver.cpp:121] Iteration 3190, lr = 0.0005
I1011 15:43:58.049983 38966 yolov3_layer.cpp:532] noobj: 0.00143894 obj: 0.684314 iou: 0.624937 cat: 0.999999 recall: 0.784119 recall75: 0.305988 count: 28
I1011 15:43:58.954313 38966 solver.cpp:253] Iteration 3200 (1.6022 iter/s, 6.24141s/10 iters), loss = 0.952063
I1011 15:43:58.954381 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.59929e-13 (* 1 = 2.59929e-13 loss)
I1011 15:43:58.954391 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.21841 (* 1 = 1.21841 loss)
I1011 15:43:58.954401 38966 sgd_solver.cpp:121] Iteration 3200, lr = 0.0005
I1011 15:44:04.397832 38966 solver.cpp:253] Iteration 3210 (1.83718 iter/s, 5.44313s/10 iters), loss = 1.20669
I1011 15:44:04.397917 38966 solver.cpp:272]     Train net output #0: det_loss1 = 9.2748e-13 (* 1 = 9.2748e-13 loss)
I1011 15:44:04.397948 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.777316 (* 1 = 0.777316 loss)
I1011 15:44:04.397960 38966 sgd_solver.cpp:121] Iteration 3210, lr = 0.0005
I1011 15:44:07.663735 38966 yolov3_layer.cpp:532] noobj: 0.0019451 obj: 0.634606 iou: 0.577357 cat: 0.999998 recall: 0.699097 recall75: 0.259789 count: 27
I1011 15:44:11.691112 38966 solver.cpp:253] Iteration 3220 (1.37122 iter/s, 7.29279s/10 iters), loss = 0.994754
I1011 15:44:11.691179 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.79869e-13 (* 1 = 1.79869e-13 loss)
I1011 15:44:11.691190 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.21637 (* 1 = 1.21637 loss)
I1011 15:44:11.691197 38966 sgd_solver.cpp:121] Iteration 3220, lr = 0.0005
I1011 15:44:17.566336 38966 solver.cpp:253] Iteration 3230 (1.70218 iter/s, 5.87482s/10 iters), loss = 1.22326
I1011 15:44:17.566431 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.38142e-13 (* 1 = 5.38142e-13 loss)
I1011 15:44:17.566447 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.806528 (* 1 = 0.806528 loss)
I1011 15:44:17.566469 38966 sgd_solver.cpp:121] Iteration 3230, lr = 0.0005
I1011 15:44:17.876070 38966 yolov3_layer.cpp:532] noobj: 0.0019598 obj: 0.653454 iou: 0.576927 cat: 0.999999 recall: 0.719338 recall75: 0.249933 count: 27
I1011 15:44:23.684294 38966 solver.cpp:253] Iteration 3240 (1.63465 iter/s, 6.11753s/10 iters), loss = 0.842296
I1011 15:44:23.684355 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.22479e-12 (* 1 = 2.22479e-12 loss)
I1011 15:44:23.684365 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.760222 (* 1 = 0.760222 loss)
I1011 15:44:23.684371 38966 sgd_solver.cpp:121] Iteration 3240, lr = 0.0005
I1011 15:44:27.652444 38966 yolov3_layer.cpp:532] noobj: 0.0018804 obj: 0.678642 iou: 0.602768 cat: 0.999998 recall: 0.719279 recall75: 0.285971 count: 27
I1011 15:44:29.628001 38966 solver.cpp:253] Iteration 3250 (1.68256 iter/s, 5.94331s/10 iters), loss = 1.15592
I1011 15:44:29.628237 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.67972e-12 (* 1 = 1.67972e-12 loss)
I1011 15:44:29.628247 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.920135 (* 1 = 0.920135 loss)
I1011 15:44:29.628257 38966 sgd_solver.cpp:121] Iteration 3250, lr = 0.0005
I1011 15:44:36.074216 38966 solver.cpp:253] Iteration 3260 (1.55144 iter/s, 6.44561s/10 iters), loss = 0.952147
I1011 15:44:36.074291 38966 solver.cpp:272]     Train net output #0: det_loss1 = 8.90949e-13 (* 1 = 8.90949e-13 loss)
I1011 15:44:36.074301 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.02527 (* 1 = 1.02527 loss)
I1011 15:44:36.074309 38966 sgd_solver.cpp:121] Iteration 3260, lr = 0.0005
I1011 15:44:37.770370 38966 yolov3_layer.cpp:532] noobj: 0.00171733 obj: 0.680803 iou: 0.593756 cat: 0.999999 recall: 0.734739 recall75: 0.272297 count: 26
I1011 15:44:43.108296 38966 solver.cpp:253] Iteration 3270 (1.42174 iter/s, 7.03361s/10 iters), loss = 0.93721
I1011 15:44:43.108366 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.3241e-12 (* 1 = 1.3241e-12 loss)
I1011 15:44:43.108376 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.827336 (* 1 = 0.827336 loss)
I1011 15:44:43.108384 38966 sgd_solver.cpp:121] Iteration 3270, lr = 0.0005
I1011 15:44:48.966583 38966 yolov3_layer.cpp:532] noobj: 0.00134495 obj: 0.673031 iou: 0.65383 cat: 0.999998 recall: 0.822863 recall75: 0.358194 count: 26
I1011 15:44:50.043933 38966 solver.cpp:253] Iteration 3280 (1.44192 iter/s, 6.93519s/10 iters), loss = 1.0463
I1011 15:44:50.044005 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.33345e-13 (* 1 = 1.33345e-13 loss)
I1011 15:44:50.044013 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.2695 (* 1 = 1.2695 loss)
I1011 15:44:50.044021 38966 sgd_solver.cpp:121] Iteration 3280, lr = 0.0005
I1011 15:44:56.154031 38966 solver.cpp:253] Iteration 3290 (1.63675 iter/s, 6.10967s/10 iters), loss = 1.13136
I1011 15:44:56.154109 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.47676e-13 (* 1 = 2.47676e-13 loss)
I1011 15:44:56.154119 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.95778 (* 1 = 0.95778 loss)
I1011 15:44:56.154127 38966 sgd_solver.cpp:121] Iteration 3290, lr = 0.0005
I1011 15:44:58.895408 38966 yolov3_layer.cpp:532] noobj: 0.00172466 obj: 0.641357 iou: 0.570868 cat: 0.999998 recall: 0.707621 recall75: 0.271593 count: 26
I1011 15:45:02.643697 38966 solver.cpp:253] Iteration 3300 (1.54101 iter/s, 6.48923s/10 iters), loss = 1.05575
I1011 15:45:02.643891 38966 solver.cpp:272]     Train net output #0: det_loss1 = 6.73512e-13 (* 1 = 6.73512e-13 loss)
I1011 15:45:02.643903 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.858585 (* 1 = 0.858585 loss)
I1011 15:45:02.643911 38966 sgd_solver.cpp:121] Iteration 3300, lr = 0.0005
I1011 15:45:10.287031 38966 solver.cpp:253] Iteration 3310 (1.30844 iter/s, 7.64271s/10 iters), loss = 0.882406
I1011 15:45:10.287101 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.57863e-13 (* 1 = 3.57863e-13 loss)
I1011 15:45:10.287109 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.84339 (* 1 = 0.84339 loss)
I1011 15:45:10.287117 38966 sgd_solver.cpp:121] Iteration 3310, lr = 0.0005
I1011 15:45:10.523725 38966 yolov3_layer.cpp:532] noobj: 0.00134933 obj: 0.67477 iou: 0.626795 cat: 0.999999 recall: 0.78014 recall75: 0.34422 count: 27
I1011 15:45:16.774765 38966 solver.cpp:253] Iteration 3320 (1.54147 iter/s, 6.4873s/10 iters), loss = 1.00762
I1011 15:45:16.774839 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.81258e-13 (* 1 = 5.81258e-13 loss)
I1011 15:45:16.774848 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.628699 (* 1 = 0.628699 loss)
I1011 15:45:16.774855 38966 sgd_solver.cpp:121] Iteration 3320, lr = 0.0005
I1011 15:45:21.230487 38966 yolov3_layer.cpp:532] noobj: 0.00140082 obj: 0.669154 iou: 0.628114 cat: 0.999998 recall: 0.777751 recall75: 0.35501 count: 26
I1011 15:45:23.935444 38966 solver.cpp:253] Iteration 3330 (1.39661 iter/s, 7.16021s/10 iters), loss = 0.824783
I1011 15:45:23.935528 38966 solver.cpp:272]     Train net output #0: det_loss1 = 6.09667e-13 (* 1 = 6.09667e-13 loss)
I1011 15:45:23.935549 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.945019 (* 1 = 0.945019 loss)
I1011 15:45:23.935556 38966 sgd_solver.cpp:121] Iteration 3330, lr = 0.0005
I1011 15:45:31.303122 38966 solver.cpp:253] Iteration 3340 (1.35737 iter/s, 7.36721s/10 iters), loss = 1.09301
I1011 15:45:31.303186 38966 solver.cpp:272]     Train net output #0: det_loss1 = 7.48972e-14 (* 1 = 7.48972e-14 loss)
I1011 15:45:31.303194 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.35164 (* 1 = 1.35164 loss)
I1011 15:45:31.303201 38966 sgd_solver.cpp:121] Iteration 3340, lr = 0.0005
I1011 15:45:32.627244 38966 yolov3_layer.cpp:532] noobj: 0.00141074 obj: 0.652397 iou: 0.595315 cat: 0.999999 recall: 0.75017 recall75: 0.262221 count: 27
I1011 15:45:36.533540 38966 solver.cpp:253] Iteration 3350 (1.91203 iter/s, 5.23006s/10 iters), loss = 1.36581
I1011 15:45:36.533799 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.04011e-13 (* 1 = 4.04011e-13 loss)
I1011 15:45:36.533812 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.51145 (* 1 = 1.51145 loss)
I1011 15:45:36.533819 38966 sgd_solver.cpp:121] Iteration 3350, lr = 0.0005
I1011 15:45:41.801582 38966 yolov3_layer.cpp:532] noobj: 0.00222934 obj: 0.595397 iou: 0.541494 cat: 0.999998 recall: 0.67837 recall75: 0.216551 count: 27
I1011 15:45:42.970877 38966 solver.cpp:253] Iteration 3360 (1.55358 iter/s, 6.43673s/10 iters), loss = 1.09981
I1011 15:45:42.970945 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.01654e-13 (* 1 = 5.01654e-13 loss)
I1011 15:45:42.970954 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.12304 (* 1 = 1.12304 loss)
I1011 15:45:42.970963 38966 sgd_solver.cpp:121] Iteration 3360, lr = 0.0005
I1011 15:45:49.247251 38966 solver.cpp:253] Iteration 3370 (1.59338 iter/s, 6.27596s/10 iters), loss = 0.879013
I1011 15:45:49.247331 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.14268e-13 (* 1 = 5.14268e-13 loss)
I1011 15:45:49.247341 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.16857 (* 1 = 1.16857 loss)
I1011 15:45:49.247351 38966 sgd_solver.cpp:121] Iteration 3370, lr = 0.0005
I1011 15:45:52.510041 38966 yolov3_layer.cpp:532] noobj: 0.0015201 obj: 0.732538 iou: 0.657726 cat: 0.999995 recall: 0.823588 recall75: 0.381943 count: 28
I1011 15:45:56.659307 38966 solver.cpp:253] Iteration 3380 (1.34924 iter/s, 7.41158s/10 iters), loss = 1.00642
I1011 15:45:56.659392 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.16321e-13 (* 1 = 2.16321e-13 loss)
I1011 15:45:56.659412 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.54122 (* 1 = 1.54122 loss)
I1011 15:45:56.659421 38966 sgd_solver.cpp:121] Iteration 3380, lr = 0.0005
I1011 15:46:03.043121 38966 solver.cpp:253] Iteration 3390 (1.56657 iter/s, 6.38339s/10 iters), loss = 0.996374
I1011 15:46:03.043190 38966 solver.cpp:272]     Train net output #0: det_loss1 = 6.59693e-13 (* 1 = 6.59693e-13 loss)
I1011 15:46:03.043200 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.726748 (* 1 = 0.726748 loss)
I1011 15:46:03.043210 38966 sgd_solver.cpp:121] Iteration 3390, lr = 0.0005
I1011 15:46:03.394312 38966 yolov3_layer.cpp:532] noobj: 0.0014692 obj: 0.662332 iou: 0.623729 cat: 0.999999 recall: 0.779013 recall75: 0.313478 count: 27
I1011 15:46:09.571195 38966 solver.cpp:253] Iteration 3400 (1.53195 iter/s, 6.52762s/10 iters), loss = 0.970454
I1011 15:46:09.571516 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.31988e-13 (* 1 = 3.31988e-13 loss)
I1011 15:46:09.571564 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.973317 (* 1 = 0.973317 loss)
I1011 15:46:09.571617 38966 sgd_solver.cpp:121] Iteration 3400, lr = 0.0005
I1011 15:46:13.390672 38966 yolov3_layer.cpp:532] noobj: 0.00163695 obj: 0.713287 iou: 0.645243 cat: 0.999997 recall: 0.804425 recall75: 0.369456 count: 28
I1011 15:46:15.869354 38966 solver.cpp:253] Iteration 3410 (1.58793 iter/s, 6.2975s/10 iters), loss = 0.933048
I1011 15:46:15.869421 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.58807e-13 (* 1 = 3.58807e-13 loss)
I1011 15:46:15.869431 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.896967 (* 1 = 0.896967 loss)
I1011 15:46:15.869438 38966 sgd_solver.cpp:121] Iteration 3410, lr = 0.0005
I1011 15:46:23.386313 38966 solver.cpp:253] Iteration 3420 (1.33041 iter/s, 7.51649s/10 iters), loss = 0.9507
I1011 15:46:23.386374 38966 solver.cpp:272]     Train net output #0: det_loss1 = 8.19416e-14 (* 1 = 8.19416e-14 loss)
I1011 15:46:23.386382 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.14996 (* 1 = 1.14996 loss)
I1011 15:46:23.386389 38966 sgd_solver.cpp:121] Iteration 3420, lr = 0.0005
I1011 15:46:25.010354 38966 yolov3_layer.cpp:532] noobj: 0.00145441 obj: 0.721262 iou: 0.646493 cat: 0.999999 recall: 0.831893 recall75: 0.352655 count: 28
I1011 15:46:30.273319 38966 solver.cpp:253] Iteration 3430 (1.4521 iter/s, 6.88657s/10 iters), loss = 1.0127
I1011 15:46:30.273391 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.06646e-12 (* 1 = 1.06646e-12 loss)
I1011 15:46:30.273399 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.04125 (* 1 = 1.04125 loss)
I1011 15:46:30.273407 38966 sgd_solver.cpp:121] Iteration 3430, lr = 0.0005
I1011 15:46:36.824633 38966 yolov3_layer.cpp:532] noobj: 0.00143051 obj: 0.669263 iou: 0.609998 cat: 0.999997 recall: 0.751766 recall75: 0.320673 count: 27
I1011 15:46:37.734200 38966 solver.cpp:253] Iteration 3440 (1.34041 iter/s, 7.46041s/10 iters), loss = 0.938502
I1011 15:46:37.734261 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.4546e-13 (* 1 = 2.4546e-13 loss)
I1011 15:46:37.734268 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.636589 (* 1 = 0.636589 loss)
I1011 15:46:37.734275 38966 sgd_solver.cpp:121] Iteration 3440, lr = 0.0005
I1011 15:46:44.014782 38966 solver.cpp:253] Iteration 3450 (1.59231 iter/s, 6.28017s/10 iters), loss = 1.12848
I1011 15:46:44.015033 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.34724e-13 (* 1 = 3.34724e-13 loss)
I1011 15:46:44.015045 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.749195 (* 1 = 0.749195 loss)
I1011 15:46:44.015053 38966 sgd_solver.cpp:121] Iteration 3450, lr = 0.0005
I1011 15:46:47.388335 38966 yolov3_layer.cpp:532] noobj: 0.00197154 obj: 0.654079 iou: 0.557418 cat: 0.999998 recall: 0.667945 recall75: 0.221648 count: 27
I1011 15:46:50.852238 38966 solver.cpp:253] Iteration 3460 (1.46266 iter/s, 6.83684s/10 iters), loss = 0.993591
I1011 15:46:50.852304 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.90161e-12 (* 1 = 3.90161e-12 loss)
I1011 15:46:50.852313 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.82125 (* 1 = 0.82125 loss)
I1011 15:46:50.852319 38966 sgd_solver.cpp:121] Iteration 3460, lr = 0.0005
I1011 15:46:57.037089 38966 solver.cpp:253] Iteration 3470 (1.61696 iter/s, 6.18443s/10 iters), loss = 0.994946
I1011 15:46:57.037261 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.04183e-13 (* 1 = 4.04183e-13 loss)
I1011 15:46:57.037312 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.36404 (* 1 = 1.36404 loss)
I1011 15:46:57.037326 38966 sgd_solver.cpp:121] Iteration 3470, lr = 0.0005
I1011 15:46:57.398119 38966 yolov3_layer.cpp:532] noobj: 0.00176121 obj: 0.700185 iou: 0.617795 cat: 0.999999 recall: 0.768405 recall75: 0.298667 count: 26
I1011 15:47:02.623486 38966 solver.cpp:253] Iteration 3480 (1.79021 iter/s, 5.58593s/10 iters), loss = 1.14492
I1011 15:47:02.623551 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.17181e-13 (* 1 = 2.17181e-13 loss)
I1011 15:47:02.623561 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.48485 (* 1 = 1.48485 loss)
I1011 15:47:02.623569 38966 sgd_solver.cpp:121] Iteration 3480, lr = 0.0005
I1011 15:47:06.114089 38966 yolov3_layer.cpp:532] noobj: 0.00227812 obj: 0.664879 iou: 0.576329 cat: 0.999999 recall: 0.703978 recall75: 0.298097 count: 27
I1011 15:47:08.225685 38966 solver.cpp:253] Iteration 3490 (1.78513 iter/s, 5.60183s/10 iters), loss = 1.17584
I1011 15:47:08.225756 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.20797e-13 (* 1 = 5.20797e-13 loss)
I1011 15:47:08.225766 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.972508 (* 1 = 0.972508 loss)
I1011 15:47:08.225775 38966 sgd_solver.cpp:121] Iteration 3490, lr = 0.0005
I1011 15:47:15.212047 38966 solver.cpp:253] Iteration 3500 (1.43145 iter/s, 6.98591s/10 iters), loss = 0.957848
I1011 15:47:15.212321 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.02503e-13 (* 1 = 4.02503e-13 loss)
I1011 15:47:15.212332 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.16521 (* 1 = 1.16521 loss)
I1011 15:47:15.212340 38966 sgd_solver.cpp:121] Iteration 3500, lr = 0.0005
I1011 15:47:16.663614 38966 yolov3_layer.cpp:532] noobj: 0.00153334 obj: 0.675818 iou: 0.619473 cat: 0.999996 recall: 0.772962 recall75: 0.307656 count: 25
I1011 15:47:21.550664 38966 solver.cpp:253] Iteration 3510 (1.57778 iter/s, 6.338s/10 iters), loss = 1.03353
I1011 15:47:21.550745 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.65119e-13 (* 1 = 3.65119e-13 loss)
I1011 15:47:21.550755 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.908133 (* 1 = 0.908133 loss)
I1011 15:47:21.550763 38966 sgd_solver.cpp:121] Iteration 3510, lr = 0.0005
I1011 15:47:26.779402 38966 yolov3_layer.cpp:532] noobj: 0.00171785 obj: 0.656965 iou: 0.598929 cat: 0.999999 recall: 0.760506 recall75: 0.307786 count: 28
I1011 15:47:27.728422 38966 solver.cpp:253] Iteration 3520 (1.61882 iter/s, 6.17734s/10 iters), loss = 0.998975
I1011 15:47:27.728499 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.43508e-13 (* 1 = 4.43508e-13 loss)
I1011 15:47:27.728534 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.1266 (* 1 = 1.1266 loss)
I1011 15:47:27.728549 38966 sgd_solver.cpp:121] Iteration 3520, lr = 0.0005
I1011 15:47:33.761078 38966 solver.cpp:253] Iteration 3530 (1.65775 iter/s, 6.03226s/10 iters), loss = 0.998848
I1011 15:47:33.761150 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.50348e-13 (* 1 = 3.50348e-13 loss)
I1011 15:47:33.761164 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.12066 (* 1 = 1.12066 loss)
I1011 15:47:33.761176 38966 sgd_solver.cpp:121] Iteration 3530, lr = 0.0005
I1011 15:47:36.380946 38966 yolov3_layer.cpp:532] noobj: 0.00177661 obj: 0.689826 iou: 0.610856 cat: 0.999999 recall: 0.754918 recall75: 0.345205 count: 27
I1011 15:47:40.130266 38966 solver.cpp:253] Iteration 3540 (1.57016 iter/s, 6.36877s/10 iters), loss = 0.94842
I1011 15:47:40.130421 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.67817e-13 (* 1 = 4.67817e-13 loss)
I1011 15:47:40.130465 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.955113 (* 1 = 0.955113 loss)
I1011 15:47:40.130497 38966 sgd_solver.cpp:121] Iteration 3540, lr = 0.0005
I1011 15:47:46.510238 38966 solver.cpp:253] Iteration 3550 (1.56753 iter/s, 6.37948s/10 iters), loss = 1.0984
I1011 15:47:46.510457 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.81652e-13 (* 1 = 1.81652e-13 loss)
I1011 15:47:46.510466 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.04812 (* 1 = 1.04812 loss)
I1011 15:47:46.510474 38966 sgd_solver.cpp:121] Iteration 3550, lr = 0.0005
I1011 15:47:46.678859 38966 yolov3_layer.cpp:532] noobj: 0.00173546 obj: 0.684126 iou: 0.608987 cat: 0.999998 recall: 0.737207 recall75: 0.277772 count: 28
I1011 15:47:52.204638 38966 solver.cpp:253] Iteration 3560 (1.75628 iter/s, 5.69387s/10 iters), loss = 1.01377
I1011 15:47:52.204696 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.85428e-13 (* 1 = 2.85428e-13 loss)
I1011 15:47:52.204705 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.966905 (* 1 = 0.966905 loss)
I1011 15:47:52.204713 38966 sgd_solver.cpp:121] Iteration 3560, lr = 0.0005
I1011 15:47:56.244758 38966 yolov3_layer.cpp:532] noobj: 0.00177406 obj: 0.705401 iou: 0.60786 cat: 0.999998 recall: 0.764702 recall75: 0.298445 count: 27
I1011 15:47:58.346773 38966 solver.cpp:253] Iteration 3570 (1.6282 iter/s, 6.14174s/10 iters), loss = 0.904206
I1011 15:47:58.346843 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.37552e-13 (* 1 = 1.37552e-13 loss)
I1011 15:47:58.346851 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.901196 (* 1 = 0.901196 loss)
I1011 15:47:58.346859 38966 sgd_solver.cpp:121] Iteration 3570, lr = 0.0005
I1011 15:48:04.078758 38966 solver.cpp:253] Iteration 3580 (1.74471 iter/s, 5.73161s/10 iters), loss = 1.07944
I1011 15:48:04.078827 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.2539e-13 (* 1 = 4.2539e-13 loss)
I1011 15:48:04.078838 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.07307 (* 1 = 1.07307 loss)
I1011 15:48:04.078845 38966 sgd_solver.cpp:121] Iteration 3580, lr = 0.0005
I1011 15:48:05.401587 38966 yolov3_layer.cpp:532] noobj: 0.00212916 obj: 0.6679 iou: 0.587633 cat: 0.999998 recall: 0.737593 recall75: 0.293821 count: 28
I1011 15:48:09.583853 38966 solver.cpp:253] Iteration 3590 (1.81662 iter/s, 5.50472s/10 iters), loss = 1.07024
I1011 15:48:09.583937 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.91677e-13 (* 1 = 5.91677e-13 loss)
I1011 15:48:09.583953 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.19993 (* 1 = 1.19993 loss)
I1011 15:48:09.583966 38966 sgd_solver.cpp:121] Iteration 3590, lr = 0.0005
I1011 15:48:15.026672 38966 yolov3_layer.cpp:532] noobj: 0.00214859 obj: 0.701635 iou: 0.595569 cat: 0.999999 recall: 0.74317 recall75: 0.308483 count: 28
I1011 15:48:16.255399 38966 solver.cpp:253] Iteration 3600 (1.499 iter/s, 6.67111s/10 iters), loss = 0.953622
I1011 15:48:16.255456 38966 solver.cpp:272]     Train net output #0: det_loss1 = 9.97901e-13 (* 1 = 9.97901e-13 loss)
I1011 15:48:16.255465 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.01557 (* 1 = 1.01557 loss)
I1011 15:48:16.255486 38966 sgd_solver.cpp:121] Iteration 3600, lr = 0.0005
I1011 15:48:24.076848 38966 solver.cpp:253] Iteration 3610 (1.27861 iter/s, 7.82098s/10 iters), loss = 0.984579
I1011 15:48:24.077112 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.27479e-13 (* 1 = 1.27479e-13 loss)
I1011 15:48:24.077124 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.922089 (* 1 = 0.922089 loss)
I1011 15:48:24.077133 38966 sgd_solver.cpp:121] Iteration 3610, lr = 0.0005
I1011 15:48:27.009285 38966 yolov3_layer.cpp:532] noobj: 0.00118472 obj: 0.694568 iou: 0.644105 cat: 0.999976 recall: 0.848382 recall75: 0.308151 count: 27
I1011 15:48:30.781358 38966 solver.cpp:253] Iteration 3620 (1.49168 iter/s, 6.70387s/10 iters), loss = 0.940536
I1011 15:48:30.781457 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.19778e-13 (* 1 = 2.19778e-13 loss)
I1011 15:48:30.781473 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.21236 (* 1 = 1.21236 loss)
I1011 15:48:30.781489 38966 sgd_solver.cpp:121] Iteration 3620, lr = 0.0005
I1011 15:48:37.355186 38966 solver.cpp:253] Iteration 3630 (1.52129 iter/s, 6.57338s/10 iters), loss = 0.926279
I1011 15:48:37.355274 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.42e-12 (* 1 = 1.42e-12 loss)
I1011 15:48:37.355296 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.731623 (* 1 = 0.731623 loss)
I1011 15:48:37.355305 38966 sgd_solver.cpp:121] Iteration 3630, lr = 0.0005
I1011 15:48:37.585721 38966 yolov3_layer.cpp:532] noobj: 0.00141268 obj: 0.666419 iou: 0.625469 cat: 0.999994 recall: 0.780751 recall75: 0.325797 count: 26
I1011 15:48:44.039851 38966 solver.cpp:253] Iteration 3640 (1.49606 iter/s, 6.68423s/10 iters), loss = 0.907451
I1011 15:48:44.039912 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.30236e-13 (* 1 = 2.30236e-13 loss)
I1011 15:48:44.039932 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.11436 (* 1 = 1.11436 loss)
I1011 15:48:44.039939 38966 sgd_solver.cpp:121] Iteration 3640, lr = 0.0005
I1011 15:48:45.171981 38966 blocking_queue.cpp:50] Waiting for data
I1011 15:48:47.948309 38966 yolov3_layer.cpp:532] noobj: 0.00156157 obj: 0.7011 iou: 0.643072 cat: 0.99999 recall: 0.805856 recall75: 0.380273 count: 27
I1011 15:48:50.162636 38966 solver.cpp:253] Iteration 3650 (1.63335 iter/s, 6.12239s/10 iters), loss = 0.814173
I1011 15:48:50.162724 38966 solver.cpp:272]     Train net output #0: det_loss1 = 9.20896e-13 (* 1 = 9.20896e-13 loss)
I1011 15:48:50.162739 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.47242 (* 1 = 0.47242 loss)
I1011 15:48:50.162752 38966 sgd_solver.cpp:121] Iteration 3650, lr = 0.0005
I1011 15:48:56.371846 38966 solver.cpp:253] Iteration 3660 (1.61062 iter/s, 6.2088s/10 iters), loss = 1.004
I1011 15:48:56.372123 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.84902e-13 (* 1 = 1.84902e-13 loss)
I1011 15:48:56.372133 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.15327 (* 1 = 1.15327 loss)
I1011 15:48:56.372140 38966 sgd_solver.cpp:121] Iteration 3660, lr = 0.0005
I1011 15:48:57.715445 38966 yolov3_layer.cpp:532] noobj: 0.00167271 obj: 0.713763 iou: 0.62226 cat: 0.999998 recall: 0.78181 recall75: 0.30174 count: 27
I1011 15:49:02.645490 38966 solver.cpp:253] Iteration 3670 (1.59413 iter/s, 6.27303s/10 iters), loss = 0.920054
I1011 15:49:02.645577 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.15482e-13 (* 1 = 3.15482e-13 loss)
I1011 15:49:02.645586 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.952788 (* 1 = 0.952788 loss)
I1011 15:49:02.645594 38966 sgd_solver.cpp:121] Iteration 3670, lr = 0.0005
I1011 15:49:08.116650 38966 yolov3_layer.cpp:532] noobj: 0.00160565 obj: 0.7005 iou: 0.623816 cat: 0.999997 recall: 0.790353 recall75: 0.29815 count: 28
I1011 15:49:09.093231 38966 solver.cpp:253] Iteration 3680 (1.55103 iter/s, 6.44732s/10 iters), loss = 1.04085
I1011 15:49:09.093303 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.87062e-13 (* 1 = 2.87062e-13 loss)
I1011 15:49:09.093314 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.995544 (* 1 = 0.995544 loss)
I1011 15:49:09.093322 38966 sgd_solver.cpp:121] Iteration 3680, lr = 0.0005
I1011 15:49:15.241420 38966 solver.cpp:253] Iteration 3690 (1.6266 iter/s, 6.14779s/10 iters), loss = 0.942958
I1011 15:49:15.241487 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.63957e-12 (* 1 = 1.63957e-12 loss)
I1011 15:49:15.241495 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.982008 (* 1 = 0.982008 loss)
I1011 15:49:15.241503 38966 sgd_solver.cpp:121] Iteration 3690, lr = 0.0005
I1011 15:49:18.515635 38966 yolov3_layer.cpp:532] noobj: 0.00154487 obj: 0.692103 iou: 0.607922 cat: 0.999999 recall: 0.756001 recall75: 0.296114 count: 26
I1011 15:49:23.050946 38966 solver.cpp:253] Iteration 3700 (1.28057 iter/s, 7.80905s/10 iters), loss = 0.874963
I1011 15:49:23.051015 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.03771e-13 (* 1 = 4.03771e-13 loss)
I1011 15:49:23.051023 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.768555 (* 1 = 0.768555 loss)
I1011 15:49:23.051031 38966 sgd_solver.cpp:121] Iteration 3700, lr = 0.0005
I1011 15:49:30.571347 38966 solver.cpp:253] Iteration 3710 (1.3298 iter/s, 7.51994s/10 iters), loss = 0.862124
I1011 15:49:30.571548 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.64377e-13 (* 1 = 4.64377e-13 loss)
I1011 15:49:30.571559 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.01026 (* 1 = 1.01026 loss)
I1011 15:49:30.571568 38966 sgd_solver.cpp:121] Iteration 3710, lr = 0.0005
I1011 15:49:30.852540 38966 yolov3_layer.cpp:532] noobj: 0.00124598 obj: 0.722218 iou: 0.658639 cat: 0.999999 recall: 0.833547 recall75: 0.359708 count: 28
I1011 15:49:37.023072 38966 solver.cpp:253] Iteration 3720 (1.5501 iter/s, 6.45118s/10 iters), loss = 1.07811
I1011 15:49:37.023159 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.06457e-13 (* 1 = 4.06457e-13 loss)
I1011 15:49:37.023169 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.502306 (* 1 = 0.502306 loss)
I1011 15:49:37.023180 38966 sgd_solver.cpp:121] Iteration 3720, lr = 0.0005
I1011 15:49:41.453903 38966 yolov3_layer.cpp:532] noobj: 0.00176189 obj: 0.68487 iou: 0.610459 cat: 0.999999 recall: 0.734023 recall75: 0.31458 count: 27
I1011 15:49:44.077313 38966 solver.cpp:253] Iteration 3730 (1.41768 iter/s, 7.05378s/10 iters), loss = 0.873358
I1011 15:49:44.077380 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.74964e-13 (* 1 = 1.74964e-13 loss)
I1011 15:49:44.077389 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.749621 (* 1 = 0.749621 loss)
I1011 15:49:44.077397 38966 sgd_solver.cpp:121] Iteration 3730, lr = 0.0005
I1011 15:49:50.957338 38966 solver.cpp:253] Iteration 3740 (1.45357 iter/s, 6.87959s/10 iters), loss = 0.879456
I1011 15:49:50.957403 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.5038e-13 (* 1 = 2.5038e-13 loss)
I1011 15:49:50.957414 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.948561 (* 1 = 0.948561 loss)
I1011 15:49:50.957422 38966 sgd_solver.cpp:121] Iteration 3740, lr = 0.0005
I1011 15:49:52.490509 38966 yolov3_layer.cpp:532] noobj: 0.00149541 obj: 0.726242 iou: 0.650207 cat: 0.999997 recall: 0.832762 recall75: 0.323892 count: 28
I1011 15:49:57.010921 38966 solver.cpp:253] Iteration 3750 (1.65202 iter/s, 6.05319s/10 iters), loss = 0.905585
I1011 15:49:57.010996 38966 solver.cpp:272]     Train net output #0: det_loss1 = 6.95338e-13 (* 1 = 6.95338e-13 loss)
I1011 15:49:57.011009 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.07204 (* 1 = 1.07204 loss)
I1011 15:49:57.011019 38966 sgd_solver.cpp:121] Iteration 3750, lr = 0.0005
I1011 15:50:03.320657 38966 yolov3_layer.cpp:532] noobj: 0.00154067 obj: 0.729748 iou: 0.642553 cat: 0.999991 recall: 0.840592 recall75: 0.321485 count: 27
I1011 15:50:04.650337 38966 solver.cpp:253] Iteration 3760 (1.30908 iter/s, 7.63894s/10 iters), loss = 0.925458
I1011 15:50:04.650408 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.23527e-13 (* 1 = 3.23527e-13 loss)
I1011 15:50:04.650415 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.0113 (* 1 = 1.0113 loss)
I1011 15:50:04.650424 38966 sgd_solver.cpp:121] Iteration 3760, lr = 0.0005
I1011 15:50:12.435071 38966 solver.cpp:253] Iteration 3770 (1.28464 iter/s, 7.78426s/10 iters), loss = 0.810063
I1011 15:50:12.435137 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.34238e-13 (* 1 = 1.34238e-13 loss)
I1011 15:50:12.435145 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.895913 (* 1 = 0.895913 loss)
I1011 15:50:12.435153 38966 sgd_solver.cpp:121] Iteration 3770, lr = 0.0005
I1011 15:50:15.135740 38966 yolov3_layer.cpp:532] noobj: 0.00132987 obj: 0.706592 iou: 0.666438 cat: 0.999998 recall: 0.840107 recall75: 0.403417 count: 25
I1011 15:50:19.050235 38966 solver.cpp:253] Iteration 3780 (1.51177 iter/s, 6.61475s/10 iters), loss = 0.944598
I1011 15:50:19.050299 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.43704e-13 (* 1 = 2.43704e-13 loss)
I1011 15:50:19.050308 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.698136 (* 1 = 0.698136 loss)
I1011 15:50:19.050315 38966 sgd_solver.cpp:121] Iteration 3780, lr = 0.0005
I1011 15:50:25.469951 38966 solver.cpp:253] Iteration 3790 (1.5578 iter/s, 6.41932s/10 iters), loss = 0.897894
I1011 15:50:25.475384 38966 solver.cpp:272]     Train net output #0: det_loss1 = 6.62222e-13 (* 1 = 6.62222e-13 loss)
I1011 15:50:25.475400 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.07382 (* 1 = 1.07382 loss)
I1011 15:50:25.475419 38966 sgd_solver.cpp:121] Iteration 3790, lr = 0.0005
I1011 15:50:25.681071 38966 yolov3_layer.cpp:532] noobj: 0.00158802 obj: 0.684472 iou: 0.643598 cat: 0.999998 recall: 0.805928 recall75: 0.379046 count: 27
I1011 15:50:32.496006 38966 solver.cpp:253] Iteration 3800 (1.42445 iter/s, 7.02025s/10 iters), loss = 0.852716
I1011 15:50:32.496112 38966 solver.cpp:272]     Train net output #0: det_loss1 = 7.0935e-14 (* 1 = 7.0935e-14 loss)
I1011 15:50:32.496122 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.06678 (* 1 = 1.06678 loss)
I1011 15:50:32.496130 38966 sgd_solver.cpp:121] Iteration 3800, lr = 0.0005
I1011 15:50:36.876142 38966 yolov3_layer.cpp:532] noobj: 0.00143071 obj: 0.712512 iou: 0.666049 cat: 0.999998 recall: 0.844357 recall75: 0.418119 count: 27
I1011 15:50:39.580016 38966 solver.cpp:253] Iteration 3810 (1.41172 iter/s, 7.08354s/10 iters), loss = 0.817633
I1011 15:50:39.580096 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.57003e-13 (* 1 = 3.57003e-13 loss)
I1011 15:50:39.580104 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.807829 (* 1 = 0.807829 loss)
I1011 15:50:39.580112 38966 sgd_solver.cpp:121] Iteration 3810, lr = 0.0005
I1011 15:50:47.378705 38966 solver.cpp:253] Iteration 3820 (1.28235 iter/s, 7.7982s/10 iters), loss = 0.918129
I1011 15:50:47.378795 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.55179e-13 (* 1 = 2.55179e-13 loss)
I1011 15:50:47.378804 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.955255 (* 1 = 0.955255 loss)
I1011 15:50:47.378824 38966 sgd_solver.cpp:121] Iteration 3820, lr = 0.0005
I1011 15:50:49.043478 38966 yolov3_layer.cpp:532] noobj: 0.00127267 obj: 0.723252 iou: 0.655683 cat: 0.999998 recall: 0.831798 recall75: 0.339243 count: 27
I1011 15:50:54.399518 38966 solver.cpp:253] Iteration 3830 (1.42443 iter/s, 7.02036s/10 iters), loss = 0.885428
I1011 15:50:54.399576 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.812e-13 (* 1 = 1.812e-13 loss)
I1011 15:50:54.399585 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.91451 (* 1 = 0.91451 loss)
I1011 15:50:54.399591 38966 sgd_solver.cpp:121] Iteration 3830, lr = 0.0005
I1011 15:51:00.383814 38966 yolov3_layer.cpp:532] noobj: 0.00140741 obj: 0.703472 iou: 0.649607 cat: 0.999997 recall: 0.819572 recall75: 0.361343 count: 27
I1011 15:51:01.654528 38966 solver.cpp:253] Iteration 3840 (1.37844 iter/s, 7.25458s/10 iters), loss = 0.830507
I1011 15:51:01.654590 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.97517e-13 (* 1 = 4.97517e-13 loss)
I1011 15:51:01.654598 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.896281 (* 1 = 0.896281 loss)
I1011 15:51:01.654605 38966 sgd_solver.cpp:121] Iteration 3840, lr = 0.0005
I1011 15:51:09.336139 38966 solver.cpp:253] Iteration 3850 (1.30189 iter/s, 7.68114s/10 iters), loss = 0.72305
I1011 15:51:09.336338 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.96011e-13 (* 1 = 1.96011e-13 loss)
I1011 15:51:09.336349 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.750672 (* 1 = 0.750672 loss)
I1011 15:51:09.336359 38966 sgd_solver.cpp:121] Iteration 3850, lr = 0.0005
I1011 15:51:12.600368 38966 yolov3_layer.cpp:532] noobj: 0.00120736 obj: 0.738412 iou: 0.684783 cat: 0.999998 recall: 0.854939 recall75: 0.436987 count: 26
I1011 15:51:17.028955 38966 solver.cpp:253] Iteration 3860 (1.30002 iter/s, 7.69222s/10 iters), loss = 0.926812
I1011 15:51:17.029034 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.72251e-13 (* 1 = 2.72251e-13 loss)
I1011 15:51:17.029043 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.988724 (* 1 = 0.988724 loss)
I1011 15:51:17.029052 38966 sgd_solver.cpp:121] Iteration 3860, lr = 0.0005
I1011 15:51:24.722090 38966 solver.cpp:253] Iteration 3870 (1.29994 iter/s, 7.69266s/10 iters), loss = 0.774347
I1011 15:51:24.722147 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.1305e-13 (* 1 = 2.1305e-13 loss)
I1011 15:51:24.722156 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.699786 (* 1 = 0.699786 loss)
I1011 15:51:24.722177 38966 sgd_solver.cpp:121] Iteration 3870, lr = 0.0005
I1011 15:51:24.950959 38966 yolov3_layer.cpp:532] noobj: 0.00121045 obj: 0.737073 iou: 0.677343 cat: 0.999987 recall: 0.863954 recall75: 0.402662 count: 27
I1011 15:51:32.305001 38966 solver.cpp:253] Iteration 3880 (1.31883 iter/s, 7.58246s/10 iters), loss = 0.912738
I1011 15:51:32.305066 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.23013e-13 (* 1 = 1.23013e-13 loss)
I1011 15:51:32.305075 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.653 (* 1 = 1.653 loss)
I1011 15:51:32.305083 38966 sgd_solver.cpp:121] Iteration 3880, lr = 0.0005
I1011 15:51:36.033605 38966 yolov3_layer.cpp:532] noobj: 0.00177466 obj: 0.703653 iou: 0.624401 cat: 0.999998 recall: 0.773615 recall75: 0.349377 count: 28
I1011 15:51:38.157830 38966 solver.cpp:253] Iteration 3890 (1.70869 iter/s, 5.85245s/10 iters), loss = 1.00768
I1011 15:51:38.157899 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.23621e-13 (* 1 = 3.23621e-13 loss)
I1011 15:51:38.157912 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.993228 (* 1 = 0.993228 loss)
I1011 15:51:38.157919 38966 sgd_solver.cpp:121] Iteration 3890, lr = 0.0005
I1011 15:51:45.132907 38966 solver.cpp:253] Iteration 3900 (1.43376 iter/s, 6.97465s/10 iters), loss = 1.01679
I1011 15:51:45.133157 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.02063e-13 (* 1 = 3.02063e-13 loss)
I1011 15:51:45.133168 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.715091 (* 1 = 0.715091 loss)
I1011 15:51:45.133177 38966 sgd_solver.cpp:121] Iteration 3900, lr = 0.0005
I1011 15:51:46.847925 38966 yolov3_layer.cpp:532] noobj: 0.00180213 obj: 0.692996 iou: 0.601154 cat: 0.999999 recall: 0.739683 recall75: 0.288258 count: 27
I1011 15:51:52.101891 38966 solver.cpp:253] Iteration 3910 (1.43506 iter/s, 6.96837s/10 iters), loss = 0.764144
I1011 15:51:52.101956 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.71223e-13 (* 1 = 3.71223e-13 loss)
I1011 15:51:52.101965 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.644474 (* 1 = 0.644474 loss)
I1011 15:51:52.101972 38966 sgd_solver.cpp:121] Iteration 3910, lr = 0.0005
I1011 15:51:57.575325 38966 yolov3_layer.cpp:532] noobj: 0.00141735 obj: 0.717202 iou: 0.637308 cat: 0.999994 recall: 0.806499 recall75: 0.345679 count: 25
I1011 15:51:58.575381 38966 solver.cpp:253] Iteration 3920 (1.54486 iter/s, 6.47308s/10 iters), loss = 0.84777
I1011 15:51:58.575453 38966 solver.cpp:272]     Train net output #0: det_loss1 = 6.01583e-13 (* 1 = 6.01583e-13 loss)
I1011 15:51:58.575464 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.455711 (* 1 = 0.455711 loss)
I1011 15:51:58.575479 38966 sgd_solver.cpp:121] Iteration 3920, lr = 0.0005
I1011 15:52:04.828909 38966 solver.cpp:253] Iteration 3930 (1.5992 iter/s, 6.25313s/10 iters), loss = 0.912125
I1011 15:52:04.828974 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.3021e-13 (* 1 = 3.3021e-13 loss)
I1011 15:52:04.828982 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.742621 (* 1 = 0.742621 loss)
I1011 15:52:04.828990 38966 sgd_solver.cpp:121] Iteration 3930, lr = 0.0005
I1011 15:52:07.478860 38966 yolov3_layer.cpp:532] noobj: 0.00175081 obj: 0.704373 iou: 0.632573 cat: 0.999998 recall: 0.807854 recall75: 0.358594 count: 28
I1011 15:52:10.662745 38966 solver.cpp:253] Iteration 3940 (1.71425 iter/s, 5.83347s/10 iters), loss = 0.963575
I1011 15:52:10.662828 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.0391e-13 (* 1 = 2.0391e-13 loss)
I1011 15:52:10.662837 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.29346 (* 1 = 1.29346 loss)
I1011 15:52:10.662856 38966 sgd_solver.cpp:121] Iteration 3940, lr = 0.0005
I1011 15:52:17.224848 38966 solver.cpp:253] Iteration 3950 (1.524 iter/s, 6.56167s/10 iters), loss = 0.891666
I1011 15:52:17.225059 38966 solver.cpp:272]     Train net output #0: det_loss1 = 6.3433e-13 (* 1 = 6.3433e-13 loss)
I1011 15:52:17.225080 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.31012 (* 1 = 1.31012 loss)
I1011 15:52:17.225088 38966 sgd_solver.cpp:121] Iteration 3950, lr = 0.0005
I1011 15:52:17.456310 38966 yolov3_layer.cpp:532] noobj: 0.00160981 obj: 0.708916 iou: 0.660105 cat: 0.999998 recall: 0.842081 recall75: 0.385565 count: 26
I1011 15:52:24.532569 38966 solver.cpp:253] Iteration 3960 (1.36853 iter/s, 7.30713s/10 iters), loss = 0.855597
I1011 15:52:24.532634 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.0716e-13 (* 1 = 2.0716e-13 loss)
I1011 15:52:24.532652 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.641261 (* 1 = 0.641261 loss)
I1011 15:52:24.532670 38966 sgd_solver.cpp:121] Iteration 3960, lr = 0.0005
I1011 15:52:28.624953 38966 yolov3_layer.cpp:532] noobj: 0.00146909 obj: 0.687605 iou: 0.647125 cat: 0.999995 recall: 0.810108 recall75: 0.373124 count: 27
I1011 15:52:30.748381 38966 solver.cpp:253] Iteration 3970 (1.6089 iter/s, 6.21542s/10 iters), loss = 0.886782
I1011 15:52:30.748559 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.52568e-13 (* 1 = 1.52568e-13 loss)
I1011 15:52:30.748615 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.927869 (* 1 = 0.927869 loss)
I1011 15:52:30.748657 38966 sgd_solver.cpp:121] Iteration 3970, lr = 0.0005
I1011 15:52:36.691504 38966 solver.cpp:253] Iteration 3980 (1.68276 iter/s, 5.94263s/10 iters), loss = 0.938698
I1011 15:52:36.691587 38966 solver.cpp:272]     Train net output #0: det_loss1 = 6.87128e-13 (* 1 = 6.87128e-13 loss)
I1011 15:52:36.691601 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.998748 (* 1 = 0.998748 loss)
I1011 15:52:36.691622 38966 sgd_solver.cpp:121] Iteration 3980, lr = 0.0005
I1011 15:52:38.451155 38966 yolov3_layer.cpp:532] noobj: 0.0019733 obj: 0.729654 iou: 0.628336 cat: 0.999998 recall: 0.776538 recall75: 0.322008 count: 27
I1011 15:52:44.205277 38966 solver.cpp:253] Iteration 3990 (1.33097 iter/s, 7.5133s/10 iters), loss = 0.812052
I1011 15:52:44.205351 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.00964e-13 (* 1 = 3.00964e-13 loss)
I1011 15:52:44.205361 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.571982 (* 1 = 0.571982 loss)
I1011 15:52:44.205381 38966 sgd_solver.cpp:121] Iteration 3990, lr = 0.0005
I1011 15:52:50.003842 38966 yolov3_layer.cpp:532] noobj: 0.0012199 obj: 0.724597 iou: 0.658309 cat: 0.999995 recall: 0.82879 recall75: 0.39431 count: 25
I1011 15:52:50.492133 38966 solver.cpp:764] Snapshotting to binary proto file snapshot/yolov3_lite_deploy_iter_4000.caffemodel
I1011 15:52:50.533519 38966 sgd_solver.cpp:293] Snapshotting solver state to binary proto file snapshot/yolov3_lite_deploy_iter_4000.solverstate
I1011 15:52:50.551355 38966 solver.cpp:443] Iteration 4000, Testing net (#0)
I1011 15:52:50.551409 38966 net.cpp:679] Ignoring source layer label_data_1_split
I1011 15:52:50.552068 38966 net.cpp:679] Ignoring source layer Yolov3Loss1
I1011 15:52:50.552119 38966 net.cpp:679] Ignoring source layer Yolov3Loss2
I1011 15:53:02.066463 38966 blocking_queue.cpp:50] Waiting for data
I1011 15:53:15.394474 38966 blocking_queue.cpp:50] Waiting for data
I1011 15:53:28.185369 38966 blocking_queue.cpp:50] Waiting for data
I1011 15:53:42.021656 38966 blocking_queue.cpp:50] Waiting for data
I1011 15:53:52.539763 38966 solver.cpp:550] class1: 0.889581
I1011 15:53:52.539821 38966 solver.cpp:556]     Test net output #0: detection_eval = 0.889581
I1011 15:53:53.365733 38966 solver.cpp:253] Iteration 4000 (0.144597 iter/s, 69.1577s/10 iters), loss = 0.792829
I1011 15:53:53.365806 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.42117e-13 (* 1 = 4.42117e-13 loss)
I1011 15:53:53.365818 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.605537 (* 1 = 0.605537 loss)
I1011 15:53:53.365839 38966 sgd_solver.cpp:121] Iteration 4000, lr = 0.0005
I1011 15:54:00.880517 38966 solver.cpp:253] Iteration 4010 (1.33056 iter/s, 7.51562s/10 iters), loss = 1.05024
I1011 15:54:00.880697 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.604e-13 (* 1 = 3.604e-13 loss)
I1011 15:54:00.880707 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.24148 (* 1 = 2.24148 loss)
I1011 15:54:00.880714 38966 sgd_solver.cpp:121] Iteration 4010, lr = 0.0005
I1011 15:54:03.095845 38966 yolov3_layer.cpp:532] noobj: 0.00140786 obj: 0.697545 iou: 0.633234 cat: 0.999993 recall: 0.810877 recall75: 0.342689 count: 28
I1011 15:54:06.265316 38966 solver.cpp:253] Iteration 4020 (1.85692 iter/s, 5.38525s/10 iters), loss = 0.995445
I1011 15:54:06.265377 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.10194e-13 (* 1 = 3.10194e-13 loss)
I1011 15:54:06.265386 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.769685 (* 1 = 0.769685 loss)
I1011 15:54:06.265394 38966 sgd_solver.cpp:121] Iteration 4020, lr = 0.0005
I1011 15:54:13.698874 38966 solver.cpp:253] Iteration 4030 (1.34511 iter/s, 7.43436s/10 iters), loss = 0.802602
I1011 15:54:13.698946 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.66603e-13 (* 1 = 3.66603e-13 loss)
I1011 15:54:13.698954 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.938763 (* 1 = 0.938763 loss)
I1011 15:54:13.698961 38966 sgd_solver.cpp:121] Iteration 4030, lr = 0.0005
I1011 15:54:13.848106 38966 yolov3_layer.cpp:532] noobj: 1.02821e-06 obj: 1.08154e-07 iou: 0.756069 cat: 0.901052 recall: 1 recall75: 1 count: 1
I1011 15:54:13.883791 38966 yolov3_layer.cpp:532] noobj: 0.00148191 obj: 0.719033 iou: 0.650935 cat: 0.999999 recall: 0.816865 recall75: 0.358149 count: 27
I1011 15:54:19.644809 38966 solver.cpp:253] Iteration 4040 (1.68165 iter/s, 5.94654s/10 iters), loss = 0.754606
I1011 15:54:19.644889 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.37635e-12 (* 1 = 1.37635e-12 loss)
I1011 15:54:19.644898 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.97958 (* 1 = 0.97958 loss)
I1011 15:54:19.644906 38966 sgd_solver.cpp:121] Iteration 4040, lr = 0.0005
I1011 15:54:23.750002 38966 yolov3_layer.cpp:532] noobj: 0.00162393 obj: 0.728893 iou: 0.637929 cat: 0.999999 recall: 0.803655 recall75: 0.372937 count: 24
I1011 15:54:26.341250 38966 solver.cpp:253] Iteration 4050 (1.49318 iter/s, 6.69713s/10 iters), loss = 0.821415
I1011 15:54:26.341316 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.15565e-12 (* 1 = 1.15565e-12 loss)
I1011 15:54:26.341327 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.766078 (* 1 = 0.766078 loss)
I1011 15:54:26.341336 38966 sgd_solver.cpp:121] Iteration 4050, lr = 0.0005
I1011 15:54:34.175773 38966 solver.cpp:253] Iteration 4060 (1.27627 iter/s, 7.83533s/10 iters), loss = 0.794554
I1011 15:54:34.176007 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.42911e-12 (* 1 = 2.42911e-12 loss)
I1011 15:54:34.176018 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.876351 (* 1 = 0.876351 loss)
I1011 15:54:34.176026 38966 sgd_solver.cpp:121] Iteration 4060, lr = 0.0005
I1011 15:54:35.971467 38966 yolov3_layer.cpp:532] noobj: 0.00128134 obj: 0.754267 iou: 0.679654 cat: 0.999994 recall: 0.858474 recall75: 0.432177 count: 29
I1011 15:54:41.875979 38966 solver.cpp:253] Iteration 4070 (1.29857 iter/s, 7.70081s/10 iters), loss = 0.933513
I1011 15:54:41.876044 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.9266e-13 (* 1 = 2.9266e-13 loss)
I1011 15:54:41.876053 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.732927 (* 1 = 0.732927 loss)
I1011 15:54:41.876060 38966 sgd_solver.cpp:121] Iteration 4070, lr = 0.0005
I1011 15:54:47.194716 38966 yolov3_layer.cpp:532] noobj: 0.00148465 obj: 0.721639 iou: 0.668405 cat: 0.999997 recall: 0.833938 recall75: 0.405662 count: 28
I1011 15:54:48.346982 38966 solver.cpp:253] Iteration 4080 (1.54521 iter/s, 6.47163s/10 iters), loss = 0.765354
I1011 15:54:48.347046 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.6821e-12 (* 1 = 1.6821e-12 loss)
I1011 15:54:48.347054 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.598333 (* 1 = 0.598333 loss)
I1011 15:54:48.347062 38966 sgd_solver.cpp:121] Iteration 4080, lr = 0.0005
I1011 15:54:56.006664 38966 solver.cpp:253] Iteration 4090 (1.30541 iter/s, 7.66042s/10 iters), loss = 0.862597
I1011 15:54:56.006731 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.58957e-13 (* 1 = 4.58957e-13 loss)
I1011 15:54:56.006739 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.06385 (* 1 = 1.06385 loss)
I1011 15:54:56.006747 38966 sgd_solver.cpp:121] Iteration 4090, lr = 0.0005
I1011 15:54:58.862998 38966 yolov3_layer.cpp:532] noobj: 0.0014923 obj: 0.737337 iou: 0.6495 cat: 0.999999 recall: 0.817876 recall75: 0.406372 count: 29
I1011 15:55:03.037452 38966 solver.cpp:253] Iteration 4100 (1.42218 iter/s, 7.03144s/10 iters), loss = 0.983632
I1011 15:55:03.037519 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.61618e-13 (* 1 = 5.61618e-13 loss)
I1011 15:55:03.037529 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.636995 (* 1 = 0.636995 loss)
I1011 15:55:03.037539 38966 sgd_solver.cpp:121] Iteration 4100, lr = 0.0005
I1011 15:55:10.485963 38966 solver.cpp:253] Iteration 4110 (1.34243 iter/s, 7.44919s/10 iters), loss = 0.862679
I1011 15:55:10.486204 38966 solver.cpp:272]     Train net output #0: det_loss1 = 9.90682e-14 (* 1 = 9.90682e-14 loss)
I1011 15:55:10.486218 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.71876 (* 1 = 1.71876 loss)
I1011 15:55:10.486227 38966 sgd_solver.cpp:121] Iteration 4110, lr = 0.0005
I1011 15:55:10.854781 38966 yolov3_layer.cpp:532] noobj: 0.00126875 obj: 0.685422 iou: 0.641989 cat: 0.999998 recall: 0.806233 recall75: 0.3561 count: 25
I1011 15:55:16.618736 38966 solver.cpp:253] Iteration 4120 (1.63049 iter/s, 6.13314s/10 iters), loss = 1.01946
I1011 15:55:16.618808 38966 solver.cpp:272]     Train net output #0: det_loss1 = 8.6701e-13 (* 1 = 8.6701e-13 loss)
I1011 15:55:16.618818 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.663469 (* 1 = 0.663469 loss)
I1011 15:55:16.618837 38966 sgd_solver.cpp:121] Iteration 4120, lr = 0.0005
I1011 15:55:21.562513 38966 yolov3_layer.cpp:532] noobj: 0.00179558 obj: 0.674188 iou: 0.624374 cat: 0.999998 recall: 0.766704 recall75: 0.374113 count: 28
I1011 15:55:24.217934 38966 solver.cpp:253] Iteration 4130 (1.31581 iter/s, 7.59986s/10 iters), loss = 0.916332
I1011 15:55:24.218004 38966 solver.cpp:272]     Train net output #0: det_loss1 = 7.13975e-13 (* 1 = 7.13975e-13 loss)
I1011 15:55:24.218014 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.996239 (* 1 = 0.996239 loss)
I1011 15:55:24.218021 38966 sgd_solver.cpp:121] Iteration 4130, lr = 0.0005
I1011 15:55:30.478981 38966 solver.cpp:253] Iteration 4140 (1.59704 iter/s, 6.26157s/10 iters), loss = 0.800082
I1011 15:55:30.479056 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.11142e-13 (* 1 = 3.11142e-13 loss)
I1011 15:55:30.479070 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.795565 (* 1 = 0.795565 loss)
I1011 15:55:30.479081 38966 sgd_solver.cpp:121] Iteration 4140, lr = 0.0005
I1011 15:55:31.909777 38966 yolov3_layer.cpp:532] noobj: 0.00152436 obj: 0.716412 iou: 0.629555 cat: 0.999999 recall: 0.795758 recall75: 0.361385 count: 27
I1011 15:55:36.633111 38966 solver.cpp:253] Iteration 4150 (1.62479 iter/s, 6.15464s/10 iters), loss = 0.845843
I1011 15:55:36.633178 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.30571e-12 (* 1 = 1.30571e-12 loss)
I1011 15:55:36.633188 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.724662 (* 1 = 0.724662 loss)
I1011 15:55:36.633196 38966 sgd_solver.cpp:121] Iteration 4150, lr = 0.0005
I1011 15:55:43.190173 38966 yolov3_layer.cpp:532] noobj: 0.00151944 obj: 0.730957 iou: 0.643366 cat: 0.999994 recall: 0.81748 recall75: 0.366022 count: 26
I1011 15:55:44.266288 38966 solver.cpp:253] Iteration 4160 (1.30996 iter/s, 7.63381s/10 iters), loss = 0.934503
I1011 15:55:44.266439 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.9257e-13 (* 1 = 4.9257e-13 loss)
I1011 15:55:44.266482 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.06088 (* 1 = 1.06088 loss)
I1011 15:55:44.266518 38966 sgd_solver.cpp:121] Iteration 4160, lr = 0.0005
I1011 15:55:50.712013 38966 solver.cpp:253] Iteration 4170 (1.55131 iter/s, 6.44615s/10 iters), loss = 1.08959
I1011 15:55:50.712090 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.88698e-13 (* 1 = 3.88698e-13 loss)
I1011 15:55:50.712100 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.19378 (* 1 = 1.19378 loss)
I1011 15:55:50.712110 38966 sgd_solver.cpp:121] Iteration 4170, lr = 0.0005
I1011 15:55:53.736416 38966 yolov3_layer.cpp:532] noobj: 0.00172088 obj: 0.695598 iou: 0.616348 cat: 0.999998 recall: 0.753329 recall75: 0.333752 count: 27
I1011 15:55:57.576124 38966 solver.cpp:253] Iteration 4180 (1.45674 iter/s, 6.86464s/10 iters), loss = 0.741952
I1011 15:55:57.576197 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.36372e-13 (* 1 = 4.36372e-13 loss)
I1011 15:55:57.576208 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.541462 (* 1 = 0.541462 loss)
I1011 15:55:57.576217 38966 sgd_solver.cpp:121] Iteration 4180, lr = 0.0005
I1011 15:56:03.885277 38966 solver.cpp:253] Iteration 4190 (1.58488 iter/s, 6.30963s/10 iters), loss = 0.786476
I1011 15:56:03.885349 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.05953e-12 (* 1 = 1.05953e-12 loss)
I1011 15:56:03.885358 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.53843 (* 1 = 0.53843 loss)
I1011 15:56:03.885367 38966 sgd_solver.cpp:121] Iteration 4190, lr = 0.0005
I1011 15:56:04.104594 38966 yolov3_layer.cpp:532] noobj: 0.00145808 obj: 0.741134 iou: 0.664888 cat: 0.999998 recall: 0.840968 recall75: 0.387233 count: 26
I1011 15:56:10.554136 38966 solver.cpp:253] Iteration 4200 (1.49939 iter/s, 6.66936s/10 iters), loss = 0.906449
I1011 15:56:10.554209 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.15994e-13 (* 1 = 2.15994e-13 loss)
I1011 15:56:10.554219 38966 solver.cpp:272]     Train net output #1: det_loss2 = 2.11462 (* 1 = 2.11462 loss)
I1011 15:56:10.554227 38966 sgd_solver.cpp:121] Iteration 4200, lr = 0.0005
I1011 15:56:13.924046 38966 yolov3_layer.cpp:532] noobj: 1.67077e-07 obj: 3.94747e-09 iou: 0.717815 cat: 0.5 recall: 1 recall75: 0 count: 1
I1011 15:56:13.947244 38966 yolov3_layer.cpp:532] noobj: 0.00186974 obj: 0.723102 iou: 0.642574 cat: 0.999997 recall: 0.801776 recall75: 0.391084 count: 28
I1011 15:56:16.043049 38966 solver.cpp:253] Iteration 4210 (1.82172 iter/s, 5.4893s/10 iters), loss = 0.893872
I1011 15:56:16.043118 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.86174e-13 (* 1 = 3.86174e-13 loss)
I1011 15:56:16.043128 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.40277 (* 1 = 1.40277 loss)
I1011 15:56:16.043135 38966 sgd_solver.cpp:121] Iteration 4210, lr = 0.0005
I1011 15:56:22.450486 38966 solver.cpp:253] Iteration 4220 (1.56057 iter/s, 6.4079s/10 iters), loss = 0.876514
I1011 15:56:22.450553 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.17357e-12 (* 1 = 1.17357e-12 loss)
I1011 15:56:22.450565 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.520048 (* 1 = 0.520048 loss)
I1011 15:56:22.450578 38966 sgd_solver.cpp:121] Iteration 4220, lr = 0.0005
I1011 15:56:24.081423 38966 yolov3_layer.cpp:532] noobj: 0.0018223 obj: 0.723371 iou: 0.60701 cat: 0.999995 recall: 0.746258 recall75: 0.335902 count: 26
I1011 15:56:29.231657 38966 solver.cpp:253] Iteration 4230 (1.47457 iter/s, 6.78163s/10 iters), loss = 0.83289
I1011 15:56:29.231776 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.31907e-13 (* 1 = 2.31907e-13 loss)
I1011 15:56:29.231796 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.804415 (* 1 = 0.804415 loss)
I1011 15:56:29.231820 38966 sgd_solver.cpp:121] Iteration 4230, lr = 0.0005
I1011 15:56:34.412674 38966 yolov3_layer.cpp:532] noobj: 0.00184896 obj: 0.686726 iou: 0.613895 cat: 0.999999 recall: 0.734925 recall75: 0.35434 count: 27
I1011 15:56:35.330485 38966 solver.cpp:253] Iteration 4240 (1.63956 iter/s, 6.0992s/10 iters), loss = 1.03168
I1011 15:56:35.330560 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.23335e-13 (* 1 = 4.23335e-13 loss)
I1011 15:56:35.330570 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.997472 (* 1 = 0.997472 loss)
I1011 15:56:35.330579 38966 sgd_solver.cpp:121] Iteration 4240, lr = 0.0005
I1011 15:56:41.376539 38966 solver.cpp:253] Iteration 4250 (1.65386 iter/s, 6.04646s/10 iters), loss = 1.02529
I1011 15:56:41.376591 38966 solver.cpp:272]     Train net output #0: det_loss1 = 8.16886e-12 (* 1 = 8.16886e-12 loss)
I1011 15:56:41.376600 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.41684 (* 1 = 1.41684 loss)
I1011 15:56:41.376617 38966 sgd_solver.cpp:121] Iteration 4250, lr = 0.0005
I1011 15:56:44.698930 38966 yolov3_layer.cpp:532] noobj: 0.00190336 obj: 0.692311 iou: 0.611321 cat: 0.999998 recall: 0.784464 recall75: 0.304679 count: 27
I1011 15:56:49.115711 38966 solver.cpp:253] Iteration 4260 (1.29204 iter/s, 7.73973s/10 iters), loss = 0.936936
I1011 15:56:49.115777 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.15153e-13 (* 1 = 2.15153e-13 loss)
I1011 15:56:49.115785 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.15236 (* 1 = 1.15236 loss)
I1011 15:56:49.115793 38966 sgd_solver.cpp:121] Iteration 4260, lr = 0.0005
I1011 15:56:55.873334 38966 solver.cpp:253] Iteration 4270 (1.47971 iter/s, 6.75807s/10 iters), loss = 0.808114
I1011 15:56:55.873404 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.83537e-13 (* 1 = 2.83537e-13 loss)
I1011 15:56:55.873415 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.34675 (* 1 = 1.34675 loss)
I1011 15:56:55.873422 38966 sgd_solver.cpp:121] Iteration 4270, lr = 0.0005
I1011 15:56:56.116077 38966 yolov3_layer.cpp:532] noobj: 0.00148745 obj: 0.716314 iou: 0.661005 cat: 0.999999 recall: 0.818836 recall75: 0.3957 count: 29
I1011 15:57:01.342741 38966 solver.cpp:253] Iteration 4280 (1.82824 iter/s, 5.46973s/10 iters), loss = 0.783758
I1011 15:57:01.342834 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.18215e-12 (* 1 = 2.18215e-12 loss)
I1011 15:57:01.342852 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.651469 (* 1 = 0.651469 loss)
I1011 15:57:01.342865 38966 sgd_solver.cpp:121] Iteration 4280, lr = 0.0005
I1011 15:57:05.680398 38966 yolov3_layer.cpp:532] noobj: 0.00173758 obj: 0.731936 iou: 0.628529 cat: 0.999999 recall: 0.802619 recall75: 0.342906 count: 26
I1011 15:57:08.055871 38966 solver.cpp:253] Iteration 4290 (1.48953 iter/s, 6.71354s/10 iters), loss = 0.755764
I1011 15:57:08.055941 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.71206e-12 (* 1 = 1.71206e-12 loss)
I1011 15:57:08.055950 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.660103 (* 1 = 0.660103 loss)
I1011 15:57:08.055958 38966 sgd_solver.cpp:121] Iteration 4290, lr = 0.0005
I1011 15:57:13.727464 38966 solver.cpp:253] Iteration 4300 (1.76307 iter/s, 5.67193s/10 iters), loss = 0.86493
I1011 15:57:13.727533 38966 solver.cpp:272]     Train net output #0: det_loss1 = 8.15619e-13 (* 1 = 8.15619e-13 loss)
I1011 15:57:13.727541 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.665793 (* 1 = 0.665793 loss)
I1011 15:57:13.727550 38966 sgd_solver.cpp:121] Iteration 4300, lr = 0.0005
I1011 15:57:15.131644 38966 yolov3_layer.cpp:532] noobj: 0.00180648 obj: 0.725543 iou: 0.644186 cat: 0.999995 recall: 0.807909 recall75: 0.348872 count: 27
I1011 15:57:19.535049 38966 solver.cpp:253] Iteration 4310 (1.72178 iter/s, 5.80793s/10 iters), loss = 0.787483
I1011 15:57:19.535112 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.21061e-13 (* 1 = 3.21061e-13 loss)
I1011 15:57:19.535120 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.827535 (* 1 = 0.827535 loss)
I1011 15:57:19.535128 38966 sgd_solver.cpp:121] Iteration 4310, lr = 0.0005
I1011 15:57:24.154718 38966 yolov3_layer.cpp:532] noobj: 0.00206673 obj: 0.707808 iou: 0.611015 cat: 0.999998 recall: 0.748984 recall75: 0.338765 count: 26
I1011 15:57:25.315547 38966 solver.cpp:253] Iteration 4320 (1.72985 iter/s, 5.78084s/10 iters), loss = 1.00359
I1011 15:57:25.315610 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.85406e-13 (* 1 = 3.85406e-13 loss)
I1011 15:57:25.315619 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.0185 (* 1 = 1.0185 loss)
I1011 15:57:25.315626 38966 sgd_solver.cpp:121] Iteration 4320, lr = 0.0005
I1011 15:57:31.545457 38966 solver.cpp:253] Iteration 4330 (1.60507 iter/s, 6.23026s/10 iters), loss = 0.84311
I1011 15:57:31.545542 38966 solver.cpp:272]     Train net output #0: det_loss1 = 9.89007e-13 (* 1 = 9.89007e-13 loss)
I1011 15:57:31.545553 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.926916 (* 1 = 0.926916 loss)
I1011 15:57:31.545572 38966 sgd_solver.cpp:121] Iteration 4330, lr = 0.0005
I1011 15:57:34.883414 38966 yolov3_layer.cpp:532] noobj: 0.00170934 obj: 0.733075 iou: 0.649518 cat: 0.999999 recall: 0.819209 recall75: 0.377229 count: 27
I1011 15:57:39.152864 38966 solver.cpp:253] Iteration 4340 (1.31444 iter/s, 7.60783s/10 iters), loss = 0.737677
I1011 15:57:39.152952 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.89976e-12 (* 1 = 5.89976e-12 loss)
I1011 15:57:39.152974 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.463509 (* 1 = 0.463509 loss)
I1011 15:57:39.152983 38966 sgd_solver.cpp:121] Iteration 4340, lr = 0.0005
I1011 15:57:46.335196 38966 solver.cpp:253] Iteration 4350 (1.39223 iter/s, 7.18272s/10 iters), loss = 0.780069
I1011 15:57:46.335433 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.68687e-13 (* 1 = 5.68687e-13 loss)
I1011 15:57:46.335454 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.915181 (* 1 = 0.915181 loss)
I1011 15:57:46.335463 38966 sgd_solver.cpp:121] Iteration 4350, lr = 0.0005
I1011 15:57:46.527318 38966 yolov3_layer.cpp:532] noobj: 0.00132608 obj: 0.713545 iou: 0.689794 cat: 0.999999 recall: 0.887586 recall75: 0.40832 count: 26
I1011 15:57:52.628114 38966 solver.cpp:253] Iteration 4360 (1.58905 iter/s, 6.29309s/10 iters), loss = 0.836603
I1011 15:57:52.628185 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.69271e-12 (* 1 = 5.69271e-12 loss)
I1011 15:57:52.628193 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.514526 (* 1 = 0.514526 loss)
I1011 15:57:52.628201 38966 sgd_solver.cpp:121] Iteration 4360, lr = 0.0005
I1011 15:57:56.750577 38966 yolov3_layer.cpp:532] noobj: 0.00163719 obj: 0.741355 iou: 0.643408 cat: 0.999997 recall: 0.824453 recall75: 0.338595 count: 28
I1011 15:57:58.818092 38966 solver.cpp:253] Iteration 4370 (1.61543 iter/s, 6.1903s/10 iters), loss = 0.85556
I1011 15:57:58.818164 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.90987e-13 (* 1 = 1.90987e-13 loss)
I1011 15:57:58.818176 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.774476 (* 1 = 0.774476 loss)
I1011 15:57:58.818182 38966 sgd_solver.cpp:121] Iteration 4370, lr = 0.0005
I1011 15:58:04.813745 38966 solver.cpp:253] Iteration 4380 (1.66779 iter/s, 5.99596s/10 iters), loss = 0.916463
I1011 15:58:04.813807 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.15575e-13 (* 1 = 5.15575e-13 loss)
I1011 15:58:04.813817 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.778754 (* 1 = 0.778754 loss)
I1011 15:58:04.813825 38966 sgd_solver.cpp:121] Iteration 4380, lr = 0.0005
I1011 15:58:06.484294 38966 yolov3_layer.cpp:532] noobj: 0.00194455 obj: 0.727302 iou: 0.607797 cat: 0.999998 recall: 0.758163 recall75: 0.290399 count: 26
I1011 15:58:11.648674 38966 solver.cpp:253] Iteration 4390 (1.463 iter/s, 6.83527s/10 iters), loss = 0.817857
I1011 15:58:11.648762 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.9376e-13 (* 1 = 2.9376e-13 loss)
I1011 15:58:11.648787 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.835375 (* 1 = 0.835375 loss)
I1011 15:58:11.648802 38966 sgd_solver.cpp:121] Iteration 4390, lr = 0.0005
I1011 15:58:16.490567 38966 yolov3_layer.cpp:532] noobj: 0.00190276 obj: 0.724186 iou: 0.626653 cat: 0.999992 recall: 0.797308 recall75: 0.315042 count: 27
I1011 15:58:17.637558 38966 solver.cpp:253] Iteration 4400 (1.66968 iter/s, 5.98916s/10 iters), loss = 0.919877
I1011 15:58:17.637646 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.06757e-12 (* 1 = 1.06757e-12 loss)
I1011 15:58:17.637668 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.46265 (* 1 = 1.46265 loss)
I1011 15:58:17.637676 38966 sgd_solver.cpp:121] Iteration 4400, lr = 0.0005
I1011 15:58:23.773532 38966 solver.cpp:253] Iteration 4410 (1.62966 iter/s, 6.13625s/10 iters), loss = 0.889548
I1011 15:58:23.773597 38966 solver.cpp:272]     Train net output #0: det_loss1 = 6.37399e-13 (* 1 = 6.37399e-13 loss)
I1011 15:58:23.773607 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.751346 (* 1 = 0.751346 loss)
I1011 15:58:23.773614 38966 sgd_solver.cpp:121] Iteration 4410, lr = 0.0005
I1011 15:58:26.437216 38966 yolov3_layer.cpp:532] noobj: 0.00167744 obj: 0.726668 iou: 0.636936 cat: 0.999998 recall: 0.802677 recall75: 0.376864 count: 27
I1011 15:58:30.212944 38966 solver.cpp:253] Iteration 4420 (1.55286 iter/s, 6.43972s/10 iters), loss = 0.813275
I1011 15:58:30.213017 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.59781e-12 (* 1 = 1.59781e-12 loss)
I1011 15:58:30.213027 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.589524 (* 1 = 0.589524 loss)
I1011 15:58:30.213047 38966 sgd_solver.cpp:121] Iteration 4420, lr = 0.0005
I1011 15:58:37.402148 38966 solver.cpp:253] Iteration 4430 (1.39091 iter/s, 7.18954s/10 iters), loss = 0.80851
I1011 15:58:37.402220 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.03437e-12 (* 1 = 1.03437e-12 loss)
I1011 15:58:37.402230 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.57857 (* 1 = 0.57857 loss)
I1011 15:58:37.402237 38966 sgd_solver.cpp:121] Iteration 4430, lr = 0.0005
I1011 15:58:37.838547 38966 yolov3_layer.cpp:532] noobj: 0.00154456 obj: 0.755292 iou: 0.658391 cat: 0.999997 recall: 0.827579 recall75: 0.36032 count: 29
I1011 15:58:44.458602 38966 solver.cpp:253] Iteration 4440 (1.41708 iter/s, 7.05678s/10 iters), loss = 0.73687
I1011 15:58:44.458660 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.31032e-13 (* 1 = 1.31032e-13 loss)
I1011 15:58:44.458669 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.675502 (* 1 = 0.675502 loss)
I1011 15:58:44.458678 38966 sgd_solver.cpp:121] Iteration 4440, lr = 0.0005
I1011 15:58:48.294427 38966 yolov3_layer.cpp:532] noobj: 0.00165176 obj: 0.743983 iou: 0.607873 cat: 0.999999 recall: 0.765918 recall75: 0.296402 count: 26
I1011 15:58:50.104835 38966 solver.cpp:253] Iteration 4450 (1.77102 iter/s, 5.64647s/10 iters), loss = 0.941483
I1011 15:58:50.104928 38966 solver.cpp:272]     Train net output #0: det_loss1 = 9.46295e-13 (* 1 = 9.46295e-13 loss)
I1011 15:58:50.104944 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.942105 (* 1 = 0.942105 loss)
I1011 15:58:50.104956 38966 sgd_solver.cpp:121] Iteration 4450, lr = 0.0005
I1011 15:58:55.449105 38966 blocking_queue.cpp:50] Waiting for data
I1011 15:58:55.999821 38966 solver.cpp:253] Iteration 4460 (1.69629 iter/s, 5.8952s/10 iters), loss = 0.891123
I1011 15:58:55.999893 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.67768e-13 (* 1 = 2.67768e-13 loss)
I1011 15:58:55.999903 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.873075 (* 1 = 0.873075 loss)
I1011 15:58:55.999912 38966 sgd_solver.cpp:121] Iteration 4460, lr = 0.0005
I1011 15:58:57.507218 38966 yolov3_layer.cpp:532] noobj: 0.00220355 obj: 0.692996 iou: 0.578862 cat: 0.999998 recall: 0.710369 recall75: 0.284817 count: 27
I1011 15:59:02.111346 38966 solver.cpp:253] Iteration 4470 (1.63619 iter/s, 6.11176s/10 iters), loss = 1.03704
I1011 15:59:02.111420 38966 solver.cpp:272]     Train net output #0: det_loss1 = 8.54338e-12 (* 1 = 8.54338e-12 loss)
I1011 15:59:02.111438 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.963772 (* 1 = 0.963772 loss)
I1011 15:59:02.111449 38966 sgd_solver.cpp:121] Iteration 4470, lr = 0.0005
I1011 15:59:07.401901 38966 yolov3_layer.cpp:532] noobj: 0.00184623 obj: 0.709737 iou: 0.604884 cat: 0.999999 recall: 0.762687 recall75: 0.300495 count: 26
I1011 15:59:08.572496 38966 solver.cpp:253] Iteration 4480 (1.54765 iter/s, 6.4614s/10 iters), loss = 0.885841
I1011 15:59:08.572571 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.04534e-13 (* 1 = 3.04534e-13 loss)
I1011 15:59:08.572593 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.740714 (* 1 = 0.740714 loss)
I1011 15:59:08.572602 38966 sgd_solver.cpp:121] Iteration 4480, lr = 0.0005
I1011 15:59:15.130136 38966 solver.cpp:253] Iteration 4490 (1.52488 iter/s, 6.5579s/10 iters), loss = 0.876259
I1011 15:59:15.130203 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.50844e-13 (* 1 = 1.50844e-13 loss)
I1011 15:59:15.130213 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.14636 (* 1 = 1.14636 loss)
I1011 15:59:15.130221 38966 sgd_solver.cpp:121] Iteration 4490, lr = 0.0005
I1011 15:59:17.517726 38966 yolov3_layer.cpp:532] noobj: 0.00176246 obj: 0.734855 iou: 0.655659 cat: 0.999998 recall: 0.821815 recall75: 0.379531 count: 28
I1011 15:59:20.710806 38966 solver.cpp:253] Iteration 4500 (1.79183 iter/s, 5.58087s/10 iters), loss = 0.933199
I1011 15:59:20.711745 38966 solver.cpp:272]     Train net output #0: det_loss1 = 6.43274e-13 (* 1 = 6.43274e-13 loss)
I1011 15:59:20.711803 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.556308 (* 1 = 0.556308 loss)
I1011 15:59:20.711848 38966 sgd_solver.cpp:121] Iteration 4500, lr = 0.0005
I1011 15:59:27.043090 38966 solver.cpp:253] Iteration 4510 (1.57936 iter/s, 6.33167s/10 iters), loss = 0.862101
I1011 15:59:27.043148 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.46527e-13 (* 1 = 4.46527e-13 loss)
I1011 15:59:27.043157 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.665689 (* 1 = 0.665689 loss)
I1011 15:59:27.043176 38966 sgd_solver.cpp:121] Iteration 4510, lr = 0.0005
I1011 15:59:27.288530 38966 yolov3_layer.cpp:532] noobj: 0.00178076 obj: 0.719599 iou: 0.638681 cat: 0.999999 recall: 0.80623 recall75: 0.354909 count: 27
I1011 15:59:33.022784 38966 solver.cpp:253] Iteration 4520 (1.67226 iter/s, 5.97992s/10 iters), loss = 0.675055
I1011 15:59:33.022850 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.65162e-13 (* 1 = 3.65162e-13 loss)
I1011 15:59:33.022859 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.847431 (* 1 = 0.847431 loss)
I1011 15:59:33.022866 38966 sgd_solver.cpp:121] Iteration 4520, lr = 0.0005
I1011 15:59:36.837556 38966 yolov3_layer.cpp:532] noobj: 0.00184487 obj: 0.719707 iou: 0.62438 cat: 0.999999 recall: 0.78874 recall75: 0.374885 count: 25
I1011 15:59:38.983839 38966 solver.cpp:253] Iteration 4530 (1.6775 iter/s, 5.96127s/10 iters), loss = 0.90403
I1011 15:59:38.983906 38966 solver.cpp:272]     Train net output #0: det_loss1 = 6.68776e-13 (* 1 = 6.68776e-13 loss)
I1011 15:59:38.983914 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.875432 (* 1 = 0.875432 loss)
I1011 15:59:38.983922 38966 sgd_solver.cpp:121] Iteration 4530, lr = 0.0005
I1011 15:59:45.799180 38966 solver.cpp:253] Iteration 4540 (1.46723 iter/s, 6.81558s/10 iters), loss = 0.757281
I1011 15:59:45.799329 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.43989e-12 (* 1 = 1.43989e-12 loss)
I1011 15:59:45.799367 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.814792 (* 1 = 0.814792 loss)
I1011 15:59:45.799398 38966 sgd_solver.cpp:121] Iteration 4540, lr = 0.0005
I1011 15:59:47.659032 38966 yolov3_layer.cpp:532] noobj: 0.0016382 obj: 0.757486 iou: 0.655023 cat: 0.999999 recall: 0.837858 recall75: 0.350101 count: 27
I1011 15:59:53.791105 38966 solver.cpp:253] Iteration 4550 (1.25123 iter/s, 7.99215s/10 iters), loss = 0.771934
I1011 15:59:53.791327 38966 solver.cpp:272]     Train net output #0: det_loss1 = 7.33335e-13 (* 1 = 7.33335e-13 loss)
I1011 15:59:53.791338 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.361445 (* 1 = 0.361445 loss)
I1011 15:59:53.791347 38966 sgd_solver.cpp:121] Iteration 4550, lr = 0.0005
I1011 15:59:59.531582 38966 yolov3_layer.cpp:532] noobj: 0.00134641 obj: 0.75732 iou: 0.683521 cat: 0.999998 recall: 0.860109 recall75: 0.434212 count: 27
I1011 16:00:00.765033 38966 solver.cpp:253] Iteration 4560 (1.43389 iter/s, 6.97401s/10 iters), loss = 0.786675
I1011 16:00:00.765103 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.37559e-13 (* 1 = 2.37559e-13 loss)
I1011 16:00:00.765111 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.622622 (* 1 = 0.622622 loss)
I1011 16:00:00.765120 38966 sgd_solver.cpp:121] Iteration 4560, lr = 0.0005
I1011 16:00:08.586607 38966 solver.cpp:253] Iteration 4570 (1.27847 iter/s, 7.82184s/10 iters), loss = 0.859748
I1011 16:00:08.586690 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.96729e-13 (* 1 = 4.96729e-13 loss)
I1011 16:00:08.586702 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.727195 (* 1 = 0.727195 loss)
I1011 16:00:08.586721 38966 sgd_solver.cpp:121] Iteration 4570, lr = 0.0005
I1011 16:00:11.610790 38966 yolov3_layer.cpp:532] noobj: 0.00121786 obj: 0.721915 iou: 0.670879 cat: 0.999997 recall: 0.868407 recall75: 0.359954 count: 27
I1011 16:00:15.366906 38966 solver.cpp:253] Iteration 4580 (1.47482 iter/s, 6.7805s/10 iters), loss = 0.841931
I1011 16:00:15.366971 38966 solver.cpp:272]     Train net output #0: det_loss1 = 8.21925e-13 (* 1 = 8.21925e-13 loss)
I1011 16:00:15.366979 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.736661 (* 1 = 0.736661 loss)
I1011 16:00:15.366987 38966 sgd_solver.cpp:121] Iteration 4580, lr = 0.0005
I1011 16:00:21.667518 38966 solver.cpp:253] Iteration 4590 (1.5871 iter/s, 6.3008s/10 iters), loss = 0.835267
I1011 16:00:21.667578 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.67581e-12 (* 1 = 1.67581e-12 loss)
I1011 16:00:21.667587 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.738275 (* 1 = 0.738275 loss)
I1011 16:00:21.667595 38966 sgd_solver.cpp:121] Iteration 4590, lr = 0.0005
I1011 16:00:21.921376 38966 yolov3_layer.cpp:532] noobj: 0.00166724 obj: 0.735704 iou: 0.654936 cat: 0.999996 recall: 0.820593 recall75: 0.376614 count: 27
I1011 16:00:29.396602 38966 solver.cpp:253] Iteration 4600 (1.29377 iter/s, 7.72933s/10 iters), loss = 0.693323
I1011 16:00:29.396836 38966 solver.cpp:272]     Train net output #0: det_loss1 = 5.83646e-12 (* 1 = 5.83646e-12 loss)
I1011 16:00:29.396847 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.693424 (* 1 = 0.693424 loss)
I1011 16:00:29.396854 38966 sgd_solver.cpp:121] Iteration 4600, lr = 0.0005
I1011 16:00:33.147734 38966 yolov3_layer.cpp:532] noobj: 4.34901e-07 obj: 3.94032e-06 iou: 0.386256 cat: 0.910793 recall: 0 recall75: 0 count: 1
I1011 16:00:33.187045 38966 yolov3_layer.cpp:532] noobj: 0.00154524 obj: 0.768301 iou: 0.707493 cat: 0.999999 recall: 0.892386 recall75: 0.491194 count: 27
I1011 16:00:35.394871 38966 solver.cpp:253] Iteration 4610 (1.66715 iter/s, 5.99827s/10 iters), loss = 0.683404
I1011 16:00:35.394930 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.17769e-12 (* 1 = 1.17769e-12 loss)
I1011 16:00:35.394940 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.683199 (* 1 = 0.683199 loss)
I1011 16:00:35.394950 38966 sgd_solver.cpp:121] Iteration 4610, lr = 0.0005
I1011 16:00:41.486207 38966 solver.cpp:253] Iteration 4620 (1.64163 iter/s, 6.09151s/10 iters), loss = 0.778693
I1011 16:00:41.486272 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.34683e-12 (* 1 = 4.34683e-12 loss)
I1011 16:00:41.486280 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.661527 (* 1 = 0.661527 loss)
I1011 16:00:41.486287 38966 sgd_solver.cpp:121] Iteration 4620, lr = 0.0005
I1011 16:00:43.495486 38966 yolov3_layer.cpp:532] noobj: 0.00168811 obj: 0.748404 iou: 0.638673 cat: 0.999998 recall: 0.821223 recall75: 0.349586 count: 26
I1011 16:00:48.199812 38966 solver.cpp:253] Iteration 4630 (1.48947 iter/s, 6.71378s/10 iters), loss = 0.80317
I1011 16:00:48.199882 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.56034e-13 (* 1 = 4.56034e-13 loss)
I1011 16:00:48.199892 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.976677 (* 1 = 0.976677 loss)
I1011 16:00:48.199899 38966 sgd_solver.cpp:121] Iteration 4630, lr = 0.0005
I1011 16:00:52.989104 38966 yolov3_layer.cpp:532] noobj: 0.00197984 obj: 0.726428 iou: 0.622 cat: 0.999999 recall: 0.771895 recall75: 0.326762 count: 27
I1011 16:00:54.095337 38966 solver.cpp:253] Iteration 4640 (1.69616 iter/s, 5.89566s/10 iters), loss = 0.920332
I1011 16:00:54.095412 38966 solver.cpp:272]     Train net output #0: det_loss1 = 6.22695e-12 (* 1 = 6.22695e-12 loss)
I1011 16:00:54.095424 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.651666 (* 1 = 0.651666 loss)
I1011 16:00:54.095433 38966 sgd_solver.cpp:121] Iteration 4640, lr = 0.0005
I1011 16:01:01.414875 38966 solver.cpp:253] Iteration 4650 (1.36617 iter/s, 7.31973s/10 iters), loss = 0.847052
I1011 16:01:01.415146 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.54137e-12 (* 1 = 4.54137e-12 loss)
I1011 16:01:01.415158 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.01893 (* 1 = 1.01893 loss)
I1011 16:01:01.415165 38966 sgd_solver.cpp:121] Iteration 4650, lr = 0.0005
I1011 16:01:04.667023 38966 yolov3_layer.cpp:532] noobj: 0.00134673 obj: 0.748657 iou: 0.688289 cat: 0.999993 recall: 0.874978 recall75: 0.448599 count: 28
I1011 16:01:09.092996 38966 solver.cpp:253] Iteration 4660 (1.3024 iter/s, 7.67811s/10 iters), loss = 0.68965
I1011 16:01:09.093082 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.30731e-12 (* 1 = 2.30731e-12 loss)
I1011 16:01:09.093094 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.629375 (* 1 = 0.629375 loss)
I1011 16:01:09.093111 38966 sgd_solver.cpp:121] Iteration 4660, lr = 0.0005
I1011 16:01:16.172205 38966 solver.cpp:253] Iteration 4670 (1.41256 iter/s, 7.07936s/10 iters), loss = 0.815119
I1011 16:01:16.172274 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.60214e-12 (* 1 = 2.60214e-12 loss)
I1011 16:01:16.172283 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.752128 (* 1 = 0.752128 loss)
I1011 16:01:16.172291 38966 sgd_solver.cpp:121] Iteration 4670, lr = 0.0005
I1011 16:01:16.506490 38966 yolov3_layer.cpp:532] noobj: 0.00137014 obj: 0.761835 iou: 0.681255 cat: 0.999996 recall: 0.858977 recall75: 0.455576 count: 28
I1011 16:01:22.485226 38966 solver.cpp:253] Iteration 4680 (1.58399 iter/s, 6.31316s/10 iters), loss = 0.831484
I1011 16:01:22.485285 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.23002e-12 (* 1 = 1.23002e-12 loss)
I1011 16:01:22.485296 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.88515 (* 1 = 0.88515 loss)
I1011 16:01:22.485302 38966 sgd_solver.cpp:121] Iteration 4680, lr = 0.0005
I1011 16:01:26.410583 38966 yolov3_layer.cpp:532] noobj: 0.00181159 obj: 0.740169 iou: 0.617636 cat: 0.999999 recall: 0.764186 recall75: 0.345899 count: 26
I1011 16:01:28.456287 38966 solver.cpp:253] Iteration 4690 (1.67471 iter/s, 5.97119s/10 iters), loss = 0.754627
I1011 16:01:28.456362 38966 solver.cpp:272]     Train net output #0: det_loss1 = 3.3693e-12 (* 1 = 3.3693e-12 loss)
I1011 16:01:28.456370 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.89312 (* 1 = 0.89312 loss)
I1011 16:01:28.456378 38966 sgd_solver.cpp:121] Iteration 4690, lr = 0.0005
I1011 16:01:35.575449 38966 solver.cpp:253] Iteration 4700 (1.40463 iter/s, 7.11931s/10 iters), loss = 0.716897
I1011 16:01:35.575665 38966 solver.cpp:272]     Train net output #0: det_loss1 = 4.95989e-13 (* 1 = 4.95989e-13 loss)
I1011 16:01:35.575676 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.744308 (* 1 = 0.744308 loss)
I1011 16:01:35.575686 38966 sgd_solver.cpp:121] Iteration 4700, lr = 0.0005
I1011 16:01:37.472405 38966 yolov3_layer.cpp:532] noobj: 0.00142924 obj: 0.756777 iou: 0.666035 cat: 0.99999 recall: 0.85469 recall75: 0.377484 count: 27
I1011 16:01:42.939266 38966 solver.cpp:253] Iteration 4710 (1.35799 iter/s, 7.36382s/10 iters), loss = 0.773224
I1011 16:01:42.939330 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.51773e-13 (* 1 = 2.51773e-13 loss)
I1011 16:01:42.939342 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.584627 (* 1 = 0.584627 loss)
I1011 16:01:42.939348 38966 sgd_solver.cpp:121] Iteration 4710, lr = 0.0005
I1011 16:01:47.336402 38966 yolov3_layer.cpp:532] noobj: 0.00190643 obj: 0.769633 iou: 0.673246 cat: 0.999998 recall: 0.850335 recall75: 0.43729 count: 27
I1011 16:01:48.516209 38966 solver.cpp:253] Iteration 4720 (1.79307 iter/s, 5.57704s/10 iters), loss = 0.748387
I1011 16:01:48.516288 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.50254e-12 (* 1 = 1.50254e-12 loss)
I1011 16:01:48.516297 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.930658 (* 1 = 0.930658 loss)
I1011 16:01:48.516306 38966 sgd_solver.cpp:121] Iteration 4720, lr = 0.0005
I1011 16:01:56.255933 38966 solver.cpp:253] Iteration 4730 (1.29201 iter/s, 7.73988s/10 iters), loss = 0.822578
I1011 16:01:56.255993 38966 solver.cpp:272]     Train net output #0: det_loss1 = 1.59505e-13 (* 1 = 1.59505e-13 loss)
I1011 16:01:56.256002 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.04885 (* 1 = 1.04885 loss)
I1011 16:01:56.256009 38966 sgd_solver.cpp:121] Iteration 4730, lr = 0.0005
I1011 16:01:58.719043 38966 yolov3_layer.cpp:532] noobj: 0.00155169 obj: 0.750104 iou: 0.65455 cat: 0.999997 recall: 0.823736 recall75: 0.379969 count: 28
I1011 16:02:01.888111 38966 solver.cpp:253] Iteration 4740 (1.77548 iter/s, 5.63227s/10 iters), loss = 0.92938
I1011 16:02:01.888178 38966 solver.cpp:272]     Train net output #0: det_loss1 = 8.84076e-13 (* 1 = 8.84076e-13 loss)
I1011 16:02:01.888188 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.901551 (* 1 = 0.901551 loss)
I1011 16:02:01.888195 38966 sgd_solver.cpp:121] Iteration 4740, lr = 0.0005
I1011 16:02:08.374763 38966 solver.cpp:253] Iteration 4750 (1.5416 iter/s, 6.48676s/10 iters), loss = 0.911339
I1011 16:02:08.375005 38966 solver.cpp:272]     Train net output #0: det_loss1 = 2.06224e-12 (* 1 = 2.06224e-12 loss)
I1011 16:02:08.375016 38966 solver.cpp:272]     Train net output #1: det_loss2 = 0.787216 (* 1 = 0.787216 loss)
I1011 16:02:08.375025 38966 sgd_solver.cpp:121] Iteration 4750, lr = 0.0005
I1011 16:02:08.581686 38966 yolov3_layer.cpp:532] noobj: 0.00240724 obj: 0.734763 iou: 0.603291 cat: 0.999999 recall: 0.752117 recall75: 0.298169 count: 29
I1011 16:02:14.965662 38966 solver.cpp:253] Iteration 4760 (1.51726 iter/s, 6.59083s/10 iters), loss = 0.793668
I1011 16:02:14.965729 38966 solver.cpp:272]     Train net output #0: det_loss1 = 9.66353e-13 (* 1 = 9.66353e-13 loss)
I1011 16:02:14.965737 38966 solver.cpp:272]     Train net output #1: det_loss2 = 1.06724 (* 1 = 1.06724 loss)
I1011 16:02:14.965744 38966 sgd_solver.cpp:121] Iteration 4760, lr = 0.0005
I1011 16:02:18.723573 38966 yolov3_layer.cpp:532] noobj: 0.00168042 obj: 0.74214 iou: 0.669869 cat: 0.999999 recall: 0.848949 recall75: 0.416927 count: 28
